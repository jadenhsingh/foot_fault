2025-08-21 17:17:37 Training with configuration:
2025-08-21 17:17:37 data:
2025-08-21 17:17:37   colormode: RGB
2025-08-21 17:17:37   inference:
2025-08-21 17:17:37     normalize_images: True
2025-08-21 17:17:37   train:
2025-08-21 17:17:37     affine:
2025-08-21 17:17:37       p: 0.5
2025-08-21 17:17:37       rotation: 30
2025-08-21 17:17:37       scaling: [1.0, 1.0]
2025-08-21 17:17:37       translation: 0
2025-08-21 17:17:37     collate:
2025-08-21 17:17:37       type: ResizeFromDataSizeCollate
2025-08-21 17:17:37       min_scale: 0.4
2025-08-21 17:17:37       max_scale: 1.0
2025-08-21 17:17:37       min_short_side: 128
2025-08-21 17:17:37       max_short_side: 1152
2025-08-21 17:17:37       multiple_of: 32
2025-08-21 17:17:37       to_square: False
2025-08-21 17:17:37     covering: False
2025-08-21 17:17:37     gaussian_noise: 12.75
2025-08-21 17:17:37     hist_eq: False
2025-08-21 17:17:37     motion_blur: False
2025-08-21 17:17:37     normalize_images: True
2025-08-21 17:17:37 device: auto
2025-08-21 17:17:37 metadata:
2025-08-21 17:17:37   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-21 17:17:37   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-21 17:17:37   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-21 17:17:37   unique_bodyparts: []
2025-08-21 17:17:37   individuals: ['animal']
2025-08-21 17:17:37   with_identity: None
2025-08-21 17:17:37 method: bu
2025-08-21 17:17:37 model:
2025-08-21 17:17:37   backbone:
2025-08-21 17:17:37     type: ResNet
2025-08-21 17:17:37     model_name: resnet50_gn
2025-08-21 17:17:37     output_stride: 16
2025-08-21 17:17:37     freeze_bn_stats: True
2025-08-21 17:17:37     freeze_bn_weights: False
2025-08-21 17:17:37   backbone_output_channels: 2048
2025-08-21 17:17:37   heads:
2025-08-21 17:17:37     bodypart:
2025-08-21 17:17:37       type: HeatmapHead
2025-08-21 17:17:37       weight_init: normal
2025-08-21 17:17:37       predictor:
2025-08-21 17:17:37         type: HeatmapPredictor
2025-08-21 17:17:37         apply_sigmoid: False
2025-08-21 17:17:37         clip_scores: True
2025-08-21 17:17:37         location_refinement: True
2025-08-21 17:17:37         locref_std: 7.2801
2025-08-21 17:17:37       target_generator:
2025-08-21 17:17:37         type: HeatmapGaussianGenerator
2025-08-21 17:17:37         num_heatmaps: 9
2025-08-21 17:17:37         pos_dist_thresh: 17
2025-08-21 17:17:37         heatmap_mode: KEYPOINT
2025-08-21 17:17:37         generate_locref: True
2025-08-21 17:17:37         locref_std: 7.2801
2025-08-21 17:17:37       criterion:
2025-08-21 17:17:37         heatmap:
2025-08-21 17:17:37           type: WeightedMSECriterion
2025-08-21 17:17:37           weight: 1.0
2025-08-21 17:17:37         locref:
2025-08-21 17:17:37           type: WeightedHuberCriterion
2025-08-21 17:17:37           weight: 0.05
2025-08-21 17:17:37       heatmap_config:
2025-08-21 17:17:37         channels: [2048, 9]
2025-08-21 17:17:37         kernel_size: [3]
2025-08-21 17:17:37         strides: [2]
2025-08-21 17:17:37       locref_config:
2025-08-21 17:17:37         channels: [2048, 18]
2025-08-21 17:17:37         kernel_size: [3]
2025-08-21 17:17:37         strides: [2]
2025-08-21 17:17:37 net_type: resnet_50
2025-08-21 17:17:37 runner:
2025-08-21 17:17:37   type: PoseTrainingRunner
2025-08-21 17:17:37   gpus: None
2025-08-21 17:17:37   key_metric: test.mAP
2025-08-21 17:17:37   key_metric_asc: True
2025-08-21 17:17:37   eval_interval: 10
2025-08-21 17:17:37   optimizer:
2025-08-21 17:17:37     type: AdamW
2025-08-21 17:17:37     params:
2025-08-21 17:17:37       lr: 0.0001
2025-08-21 17:17:37   scheduler:
2025-08-21 17:17:37     type: LRListScheduler
2025-08-21 17:17:37     params:
2025-08-21 17:17:37       lr_list: [[1e-05], [1e-06]]
2025-08-21 17:17:37       milestones: [160, 190]
2025-08-21 17:17:37   snapshots:
2025-08-21 17:17:37     max_snapshots: 5
2025-08-21 17:17:37     save_epochs: 25
2025-08-21 17:17:37     save_optimizer_state: False
2025-08-21 17:17:37 train_settings:
2025-08-21 17:17:37   batch_size: 1
2025-08-21 17:17:37   dataloader_workers: 0
2025-08-21 17:17:37   dataloader_pin_memory: True
2025-08-21 17:17:37   display_iters: 500
2025-08-21 17:17:37   epochs: 200
2025-08-21 17:17:37   seed: 42
2025-08-21 17:17:37 init_weights: custom
2025-08-21 17:17:37 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-21 17:17:37 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-21 17:17:37 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-21 17:17:39 Data Transforms:
2025-08-21 17:17:39   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-21 17:17:39   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-21 17:18:07 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-21 17:18:07 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-21 17:18:07 Using 1127 images and 60 for testing
2025-08-21 17:18:07 
Starting pose model training...
--------------------------------------------------
2025-08-21 17:20:37 Number of iterations: 500, loss: 0.00639, lr: 0.0001
2025-08-21 17:23:00 Number of iterations: 1000, loss: 0.00451, lr: 0.0001
2025-08-21 17:23:36 Epoch 1/200 (lr=0.0001), train loss 0.00756
2025-08-21 17:25:57 Number of iterations: 500, loss: 0.00371, lr: 0.0001
2025-08-21 17:28:10 Number of iterations: 1000, loss: 0.00551, lr: 0.0001
2025-08-21 17:28:46 Epoch 2/200 (lr=0.0001), train loss 0.00445
2025-08-21 17:31:08 Number of iterations: 500, loss: 0.00509, lr: 0.0001
2025-08-21 17:33:27 Number of iterations: 1000, loss: 0.00365, lr: 0.0001
2025-08-21 17:34:04 Epoch 3/200 (lr=0.0001), train loss 0.00378
2025-08-21 17:37:09 Training with configuration:
2025-08-21 17:37:09 data:
2025-08-21 17:37:09   colormode: RGB
2025-08-21 17:37:09   inference:
2025-08-21 17:37:09     normalize_images: True
2025-08-21 17:37:09   train:
2025-08-21 17:37:09     affine:
2025-08-21 17:37:09       p: 0.5
2025-08-21 17:37:09       rotation: 30
2025-08-21 17:37:09       scaling: [1.0, 1.0]
2025-08-21 17:37:09       translation: 0
2025-08-21 17:37:09     collate:
2025-08-21 17:37:09       type: ResizeFromDataSizeCollate
2025-08-21 17:37:09       min_scale: 0.4
2025-08-21 17:37:09       max_scale: 1.0
2025-08-21 17:37:09       min_short_side: 128
2025-08-21 17:37:09       max_short_side: 1152
2025-08-21 17:37:09       multiple_of: 32
2025-08-21 17:37:09       to_square: False
2025-08-21 17:37:09     covering: False
2025-08-21 17:37:09     gaussian_noise: 12.75
2025-08-21 17:37:09     hist_eq: False
2025-08-21 17:37:09     motion_blur: False
2025-08-21 17:37:09     normalize_images: True
2025-08-21 17:37:09 device: auto
2025-08-21 17:37:09 metadata:
2025-08-21 17:37:09   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-21 17:37:09   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-21 17:37:09   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-21 17:37:09   unique_bodyparts: []
2025-08-21 17:37:09   individuals: ['animal']
2025-08-21 17:37:09   with_identity: None
2025-08-21 17:37:09 method: bu
2025-08-21 17:37:09 model:
2025-08-21 17:37:09   backbone:
2025-08-21 17:37:09     type: ResNet
2025-08-21 17:37:09     model_name: resnet50_gn
2025-08-21 17:37:09     output_stride: 16
2025-08-21 17:37:09     freeze_bn_stats: True
2025-08-21 17:37:09     freeze_bn_weights: False
2025-08-21 17:37:09   backbone_output_channels: 2048
2025-08-21 17:37:09   heads:
2025-08-21 17:37:09     bodypart:
2025-08-21 17:37:09       type: HeatmapHead
2025-08-21 17:37:09       weight_init: normal
2025-08-21 17:37:09       predictor:
2025-08-21 17:37:09         type: HeatmapPredictor
2025-08-21 17:37:09         apply_sigmoid: False
2025-08-21 17:37:09         clip_scores: True
2025-08-21 17:37:09         location_refinement: True
2025-08-21 17:37:09         locref_std: 7.2801
2025-08-21 17:37:09       target_generator:
2025-08-21 17:37:09         type: HeatmapGaussianGenerator
2025-08-21 17:37:09         num_heatmaps: 9
2025-08-21 17:37:09         pos_dist_thresh: 17
2025-08-21 17:37:09         heatmap_mode: KEYPOINT
2025-08-21 17:37:09         generate_locref: True
2025-08-21 17:37:09         locref_std: 7.2801
2025-08-21 17:37:09       criterion:
2025-08-21 17:37:09         heatmap:
2025-08-21 17:37:09           type: WeightedMSECriterion
2025-08-21 17:37:09           weight: 1.0
2025-08-21 17:37:09         locref:
2025-08-21 17:37:09           type: WeightedHuberCriterion
2025-08-21 17:37:09           weight: 0.05
2025-08-21 17:37:09       heatmap_config:
2025-08-21 17:37:09         channels: [2048, 9]
2025-08-21 17:37:09         kernel_size: [3]
2025-08-21 17:37:09         strides: [2]
2025-08-21 17:37:09       locref_config:
2025-08-21 17:37:09         channels: [2048, 18]
2025-08-21 17:37:09         kernel_size: [3]
2025-08-21 17:37:09         strides: [2]
2025-08-21 17:37:09 net_type: resnet_50
2025-08-21 17:37:09 runner:
2025-08-21 17:37:09   type: PoseTrainingRunner
2025-08-21 17:37:09   gpus: None
2025-08-21 17:37:09   key_metric: test.mAP
2025-08-21 17:37:09   key_metric_asc: True
2025-08-21 17:37:09   eval_interval: 10
2025-08-21 17:37:09   optimizer:
2025-08-21 17:37:09     type: AdamW
2025-08-21 17:37:09     params:
2025-08-21 17:37:09       lr: 0.0001
2025-08-21 17:37:09   scheduler:
2025-08-21 17:37:09     type: LRListScheduler
2025-08-21 17:37:09     params:
2025-08-21 17:37:09       lr_list: [[1e-05], [1e-06]]
2025-08-21 17:37:09       milestones: [160, 190]
2025-08-21 17:37:09   snapshots:
2025-08-21 17:37:09     max_snapshots: 5
2025-08-21 17:37:09     save_epochs: 25
2025-08-21 17:37:09     save_optimizer_state: False
2025-08-21 17:37:09 train_settings:
2025-08-21 17:37:09   batch_size: 64
2025-08-21 17:37:09   dataloader_workers: 0
2025-08-21 17:37:09   dataloader_pin_memory: True
2025-08-21 17:37:09   display_iters: 500
2025-08-21 17:37:09   epochs: 200
2025-08-21 17:37:09   seed: 42
2025-08-21 17:37:09 init_weights: custom
2025-08-21 17:37:09 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-21 17:37:10 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-21 17:37:10 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-21 17:37:12 Data Transforms:
2025-08-21 17:37:12   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-21 17:37:12   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-21 17:37:14 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-21 17:37:14 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-21 17:37:14 Using 1127 images and 60 for testing
2025-08-21 17:37:14 
Starting pose model training...
--------------------------------------------------
2025-08-21 17:39:33 Training with configuration:
2025-08-21 17:39:33 data:
2025-08-21 17:39:33   colormode: RGB
2025-08-21 17:39:33   inference:
2025-08-21 17:39:33     normalize_images: True
2025-08-21 17:39:33   train:
2025-08-21 17:39:33     affine:
2025-08-21 17:39:33       p: 0.5
2025-08-21 17:39:33       rotation: 30
2025-08-21 17:39:33       scaling: [1.0, 1.0]
2025-08-21 17:39:33       translation: 0
2025-08-21 17:39:33     collate:
2025-08-21 17:39:33       type: ResizeFromDataSizeCollate
2025-08-21 17:39:33       min_scale: 0.4
2025-08-21 17:39:33       max_scale: 1.0
2025-08-21 17:39:33       min_short_side: 128
2025-08-21 17:39:33       max_short_side: 1152
2025-08-21 17:39:33       multiple_of: 32
2025-08-21 17:39:33       to_square: False
2025-08-21 17:39:33     covering: False
2025-08-21 17:39:33     gaussian_noise: 12.75
2025-08-21 17:39:33     hist_eq: False
2025-08-21 17:39:33     motion_blur: False
2025-08-21 17:39:33     normalize_images: True
2025-08-21 17:39:33 device: auto
2025-08-21 17:39:33 metadata:
2025-08-21 17:39:33   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-21 17:39:33   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-21 17:39:33   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-21 17:39:33   unique_bodyparts: []
2025-08-21 17:39:33   individuals: ['animal']
2025-08-21 17:39:33   with_identity: None
2025-08-21 17:39:33 method: bu
2025-08-21 17:39:33 model:
2025-08-21 17:39:33   backbone:
2025-08-21 17:39:33     type: ResNet
2025-08-21 17:39:33     model_name: resnet50_gn
2025-08-21 17:39:33     output_stride: 16
2025-08-21 17:39:33     freeze_bn_stats: True
2025-08-21 17:39:33     freeze_bn_weights: False
2025-08-21 17:39:33   backbone_output_channels: 2048
2025-08-21 17:39:33   heads:
2025-08-21 17:39:33     bodypart:
2025-08-21 17:39:33       type: HeatmapHead
2025-08-21 17:39:33       weight_init: normal
2025-08-21 17:39:33       predictor:
2025-08-21 17:39:33         type: HeatmapPredictor
2025-08-21 17:39:33         apply_sigmoid: False
2025-08-21 17:39:33         clip_scores: True
2025-08-21 17:39:33         location_refinement: True
2025-08-21 17:39:33         locref_std: 7.2801
2025-08-21 17:39:33       target_generator:
2025-08-21 17:39:33         type: HeatmapGaussianGenerator
2025-08-21 17:39:33         num_heatmaps: 9
2025-08-21 17:39:33         pos_dist_thresh: 17
2025-08-21 17:39:33         heatmap_mode: KEYPOINT
2025-08-21 17:39:33         generate_locref: True
2025-08-21 17:39:33         locref_std: 7.2801
2025-08-21 17:39:33       criterion:
2025-08-21 17:39:33         heatmap:
2025-08-21 17:39:33           type: WeightedMSECriterion
2025-08-21 17:39:33           weight: 1.0
2025-08-21 17:39:33         locref:
2025-08-21 17:39:33           type: WeightedHuberCriterion
2025-08-21 17:39:33           weight: 0.05
2025-08-21 17:39:33       heatmap_config:
2025-08-21 17:39:33         channels: [2048, 9]
2025-08-21 17:39:33         kernel_size: [3]
2025-08-21 17:39:33         strides: [2]
2025-08-21 17:39:33       locref_config:
2025-08-21 17:39:33         channels: [2048, 18]
2025-08-21 17:39:33         kernel_size: [3]
2025-08-21 17:39:33         strides: [2]
2025-08-21 17:39:33 net_type: resnet_50
2025-08-21 17:39:33 runner:
2025-08-21 17:39:33   type: PoseTrainingRunner
2025-08-21 17:39:33   gpus: None
2025-08-21 17:39:33   key_metric: test.mAP
2025-08-21 17:39:33   key_metric_asc: True
2025-08-21 17:39:33   eval_interval: 10
2025-08-21 17:39:33   optimizer:
2025-08-21 17:39:33     type: AdamW
2025-08-21 17:39:33     params:
2025-08-21 17:39:33       lr: 0.0001
2025-08-21 17:39:33   scheduler:
2025-08-21 17:39:33     type: LRListScheduler
2025-08-21 17:39:33     params:
2025-08-21 17:39:33       lr_list: [[1e-05], [1e-06]]
2025-08-21 17:39:33       milestones: [160, 190]
2025-08-21 17:39:33   snapshots:
2025-08-21 17:39:33     max_snapshots: 5
2025-08-21 17:39:33     save_epochs: 25
2025-08-21 17:39:33     save_optimizer_state: False
2025-08-21 17:39:33 train_settings:
2025-08-21 17:39:33   batch_size: 16
2025-08-21 17:39:33   dataloader_workers: 0
2025-08-21 17:39:33   dataloader_pin_memory: True
2025-08-21 17:39:33   display_iters: 500
2025-08-21 17:39:33   epochs: 200
2025-08-21 17:39:33   seed: 42
2025-08-21 17:39:33 init_weights: custom
2025-08-21 17:39:33 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-21 17:39:33 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-21 17:39:34 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-21 17:39:35 Data Transforms:
2025-08-21 17:39:35   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-21 17:39:35   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-21 17:39:37 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-21 17:39:37 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-21 17:39:37 Using 1127 images and 60 for testing
2025-08-21 17:39:37 
Starting pose model training...
--------------------------------------------------
2025-08-21 17:44:37 Epoch 1/200 (lr=0.0001), train loss 0.01209
2025-08-21 17:49:33 Epoch 2/200 (lr=0.0001), train loss 0.00654
2025-08-21 17:54:33 Epoch 3/200 (lr=0.0001), train loss 0.00518
2025-08-21 17:59:05 Epoch 4/200 (lr=0.0001), train loss 0.00433
2025-08-21 18:03:35 Epoch 5/200 (lr=0.0001), train loss 0.00385
2025-08-21 18:08:09 Epoch 6/200 (lr=0.0001), train loss 0.00360
2025-08-21 18:12:46 Epoch 7/200 (lr=0.0001), train loss 0.00323
2025-08-21 18:17:11 Epoch 8/200 (lr=0.0001), train loss 0.00310
2025-08-21 18:21:32 Epoch 9/200 (lr=0.0001), train loss 0.00300
2025-08-21 18:26:06 Training for epoch 10 done, starting evaluation
2025-08-21 18:26:15 Epoch 10 performance:
2025-08-21 18:26:15 metrics/test.rmse:  29.144
2025-08-21 18:26:15 metrics/test.rmse_pcutoff:4.242
2025-08-21 18:26:15 metrics/test.mAP:   71.958
2025-08-21 18:26:15 metrics/test.mAR:   78.833
2025-08-21 18:26:15 metrics/test.rmse_detections:29.144
2025-08-21 18:26:15 metrics/test.rmse_detections_pcutoff:4.242
2025-08-21 18:26:15 Epoch 10/200 (lr=0.0001), train loss 0.00285, valid loss 0.00389
2025-08-21 18:30:55 Epoch 11/200 (lr=0.0001), train loss 0.00270
2025-08-21 18:35:27 Epoch 12/200 (lr=0.0001), train loss 0.00259
2025-08-21 18:40:05 Epoch 13/200 (lr=0.0001), train loss 0.00245
2025-08-21 18:44:24 Epoch 14/200 (lr=0.0001), train loss 0.00237
2025-08-21 18:49:02 Epoch 15/200 (lr=0.0001), train loss 0.00229
2025-08-21 18:53:27 Epoch 16/200 (lr=0.0001), train loss 0.00229
2025-08-21 18:57:51 Epoch 17/200 (lr=0.0001), train loss 0.00223
2025-08-21 19:02:08 Epoch 18/200 (lr=0.0001), train loss 0.00209
2025-08-21 19:06:41 Epoch 19/200 (lr=0.0001), train loss 0.00206
2025-08-21 19:11:23 Training for epoch 20 done, starting evaluation
2025-08-21 19:11:31 Epoch 20 performance:
2025-08-21 19:11:31 metrics/test.rmse:  15.962
2025-08-21 19:11:31 metrics/test.rmse_pcutoff:4.767
2025-08-21 19:11:31 metrics/test.mAP:   84.332
2025-08-21 19:11:31 metrics/test.mAR:   89.000
2025-08-21 19:11:31 metrics/test.rmse_detections:15.962
2025-08-21 19:11:31 metrics/test.rmse_detections_pcutoff:4.767
2025-08-21 19:11:31 Epoch 20/200 (lr=0.0001), train loss 0.00209, valid loss 0.00348
2025-08-21 19:16:07 Epoch 21/200 (lr=0.0001), train loss 0.00201
2025-08-21 19:20:38 Epoch 22/200 (lr=0.0001), train loss 0.00201
2025-08-21 19:25:10 Epoch 23/200 (lr=0.0001), train loss 0.00186
2025-08-21 19:29:35 Epoch 24/200 (lr=0.0001), train loss 0.00182
2025-08-21 19:34:02 Epoch 25/200 (lr=0.0001), train loss 0.00182
2025-08-21 19:38:25 Epoch 26/200 (lr=0.0001), train loss 0.00171
2025-08-21 19:42:53 Epoch 27/200 (lr=0.0001), train loss 0.00167
2025-08-21 19:47:03 Epoch 28/200 (lr=0.0001), train loss 0.00164
2025-08-21 19:51:32 Epoch 29/200 (lr=0.0001), train loss 0.00164
2025-08-21 19:56:12 Training for epoch 30 done, starting evaluation
2025-08-21 19:56:20 Epoch 30 performance:
2025-08-21 19:56:20 metrics/test.rmse:  15.576
2025-08-21 19:56:20 metrics/test.rmse_pcutoff:5.125
2025-08-21 19:56:20 metrics/test.mAP:   85.680
2025-08-21 19:56:20 metrics/test.mAR:   88.833
2025-08-21 19:56:20 metrics/test.rmse_detections:15.576
2025-08-21 19:56:20 metrics/test.rmse_detections_pcutoff:5.125
2025-08-21 19:56:20 Epoch 30/200 (lr=0.0001), train loss 0.00157, valid loss 0.00338
2025-08-21 20:01:08 Epoch 31/200 (lr=0.0001), train loss 0.00156
2025-08-21 20:05:44 Epoch 32/200 (lr=0.0001), train loss 0.00148
2025-08-21 20:10:17 Epoch 33/200 (lr=0.0001), train loss 0.00146
2025-08-21 20:15:21 Epoch 34/200 (lr=0.0001), train loss 0.00151
2025-08-21 20:20:03 Epoch 35/200 (lr=0.0001), train loss 0.00146
2025-08-21 20:24:39 Epoch 36/200 (lr=0.0001), train loss 0.00149
2025-08-21 20:29:09 Epoch 37/200 (lr=0.0001), train loss 0.00136
2025-08-21 20:33:39 Epoch 38/200 (lr=0.0001), train loss 0.00135
2025-08-21 20:38:51 Epoch 39/200 (lr=0.0001), train loss 0.00131
2025-08-21 20:43:59 Training for epoch 40 done, starting evaluation
2025-08-21 20:44:08 Epoch 40 performance:
2025-08-21 20:44:08 metrics/test.rmse:  12.811
2025-08-21 20:44:08 metrics/test.rmse_pcutoff:5.803
2025-08-21 20:44:08 metrics/test.mAP:   90.010
2025-08-21 20:44:08 metrics/test.mAR:   92.333
2025-08-21 20:44:08 metrics/test.rmse_detections:12.811
2025-08-21 20:44:08 metrics/test.rmse_detections_pcutoff:5.803
2025-08-21 20:44:08 Epoch 40/200 (lr=0.0001), train loss 0.00135, valid loss 0.00316
2025-08-21 20:48:55 Epoch 41/200 (lr=0.0001), train loss 0.00134
2025-08-21 20:53:24 Epoch 42/200 (lr=0.0001), train loss 0.00129
2025-08-21 20:57:55 Epoch 43/200 (lr=0.0001), train loss 0.00125
2025-08-21 21:02:16 Epoch 44/200 (lr=0.0001), train loss 0.00120
2025-08-21 21:06:40 Epoch 45/200 (lr=0.0001), train loss 0.00124
2025-08-21 21:11:16 Epoch 46/200 (lr=0.0001), train loss 0.00122
2025-08-21 21:15:41 Epoch 47/200 (lr=0.0001), train loss 0.00125
2025-08-21 21:20:07 Epoch 48/200 (lr=0.0001), train loss 0.00125
2025-08-21 21:24:34 Epoch 49/200 (lr=0.0001), train loss 0.00119
2025-08-21 21:29:01 Training for epoch 50 done, starting evaluation
2025-08-21 21:29:09 Epoch 50 performance:
2025-08-21 21:29:09 metrics/test.rmse:  11.947
2025-08-21 21:29:09 metrics/test.rmse_pcutoff:4.887
2025-08-21 21:29:09 metrics/test.mAP:   91.284
2025-08-21 21:29:09 metrics/test.mAR:   93.333
2025-08-21 21:29:09 metrics/test.rmse_detections:11.947
2025-08-21 21:29:09 metrics/test.rmse_detections_pcutoff:4.887
2025-08-21 21:29:09 Epoch 50/200 (lr=0.0001), train loss 0.00122, valid loss 0.00311
2025-08-21 21:33:31 Epoch 51/200 (lr=0.0001), train loss 0.00112
2025-08-21 21:37:51 Epoch 52/200 (lr=0.0001), train loss 0.00106
2025-08-21 21:42:24 Epoch 53/200 (lr=0.0001), train loss 0.00108
2025-08-21 21:47:09 Epoch 54/200 (lr=0.0001), train loss 0.00106
2025-08-21 21:51:23 Epoch 55/200 (lr=0.0001), train loss 0.00109
2025-08-21 21:55:49 Epoch 56/200 (lr=0.0001), train loss 0.00103
2025-08-21 22:00:13 Epoch 57/200 (lr=0.0001), train loss 0.00106
2025-08-21 22:04:24 Epoch 58/200 (lr=0.0001), train loss 0.00101
2025-08-21 22:08:41 Epoch 59/200 (lr=0.0001), train loss 0.00103
2025-08-21 22:13:15 Training for epoch 60 done, starting evaluation
2025-08-21 22:13:23 Epoch 60 performance:
2025-08-21 22:13:23 metrics/test.rmse:  9.681
2025-08-21 22:13:23 metrics/test.rmse_pcutoff:4.271
2025-08-21 22:13:23 metrics/test.mAP:   93.315
2025-08-21 22:13:23 metrics/test.mAR:   94.833
2025-08-21 22:13:23 metrics/test.rmse_detections:9.681
2025-08-21 22:13:23 metrics/test.rmse_detections_pcutoff:4.271
2025-08-21 22:13:23 Epoch 60/200 (lr=0.0001), train loss 0.00100, valid loss 0.00328
2025-08-21 22:17:47 Epoch 61/200 (lr=0.0001), train loss 0.00108
2025-08-21 22:22:10 Epoch 62/200 (lr=0.0001), train loss 0.00102
2025-08-21 22:26:30 Epoch 63/200 (lr=0.0001), train loss 0.00097
2025-08-21 22:30:47 Epoch 64/200 (lr=0.0001), train loss 0.00099
2025-08-21 22:35:17 Epoch 65/200 (lr=0.0001), train loss 0.00099
2025-08-21 22:39:41 Epoch 66/200 (lr=0.0001), train loss 0.00091
2025-08-21 22:44:05 Epoch 67/200 (lr=0.0001), train loss 0.00092
2025-08-21 22:48:29 Epoch 68/200 (lr=0.0001), train loss 0.00093
2025-08-21 22:52:47 Epoch 69/200 (lr=0.0001), train loss 0.00093
2025-08-21 22:57:16 Training for epoch 70 done, starting evaluation
2025-08-21 22:57:24 Epoch 70 performance:
2025-08-21 22:57:24 metrics/test.rmse:  9.941
2025-08-21 22:57:24 metrics/test.rmse_pcutoff:4.731
2025-08-21 22:57:24 metrics/test.mAP:   92.167
2025-08-21 22:57:24 metrics/test.mAR:   94.167
2025-08-21 22:57:24 metrics/test.rmse_detections:9.941
2025-08-21 22:57:24 metrics/test.rmse_detections_pcutoff:4.731
2025-08-21 22:57:24 Epoch 70/200 (lr=0.0001), train loss 0.00095, valid loss 0.00316
2025-08-21 23:01:45 Epoch 71/200 (lr=0.0001), train loss 0.00090
2025-08-21 23:06:30 Epoch 72/200 (lr=0.0001), train loss 0.00086
2025-08-21 23:11:02 Epoch 73/200 (lr=0.0001), train loss 0.00085
2025-08-21 23:15:19 Epoch 74/200 (lr=0.0001), train loss 0.00086
2025-08-21 23:20:05 Epoch 75/200 (lr=0.0001), train loss 0.00087
2025-08-21 23:24:33 Epoch 76/200 (lr=0.0001), train loss 0.00083
2025-08-21 23:28:53 Epoch 77/200 (lr=0.0001), train loss 0.00084
2025-08-21 23:33:14 Epoch 78/200 (lr=0.0001), train loss 0.00087
2025-08-21 23:37:34 Epoch 79/200 (lr=0.0001), train loss 0.00082
2025-08-21 23:41:55 Training for epoch 80 done, starting evaluation
2025-08-21 23:42:03 Epoch 80 performance:
2025-08-21 23:42:03 metrics/test.rmse:  8.544
2025-08-21 23:42:03 metrics/test.rmse_pcutoff:5.365
2025-08-21 23:42:03 metrics/test.mAP:   94.364
2025-08-21 23:42:03 metrics/test.mAR:   95.667
2025-08-21 23:42:03 metrics/test.rmse_detections:8.544
2025-08-21 23:42:03 metrics/test.rmse_detections_pcutoff:5.365
2025-08-21 23:42:03 Epoch 80/200 (lr=0.0001), train loss 0.00086, valid loss 0.00315
2025-08-21 23:46:43 Epoch 81/200 (lr=0.0001), train loss 0.00074
2025-08-21 23:51:15 Epoch 82/200 (lr=0.0001), train loss 0.00076
2025-08-21 23:55:34 Epoch 83/200 (lr=0.0001), train loss 0.00076
2025-08-22 00:00:05 Epoch 84/200 (lr=0.0001), train loss 0.00079
2025-08-22 00:04:38 Epoch 85/200 (lr=0.0001), train loss 0.00079
2025-08-22 00:09:03 Epoch 86/200 (lr=0.0001), train loss 0.00082
2025-08-22 00:13:21 Epoch 87/200 (lr=0.0001), train loss 0.00078
2025-08-22 00:17:43 Epoch 88/200 (lr=0.0001), train loss 0.00076
2025-08-22 00:21:58 Epoch 89/200 (lr=0.0001), train loss 0.00077
2025-08-22 00:26:08 Training for epoch 90 done, starting evaluation
2025-08-22 00:26:16 Epoch 90 performance:
2025-08-22 00:26:16 metrics/test.rmse:  10.198
2025-08-22 00:26:16 metrics/test.rmse_pcutoff:4.446
2025-08-22 00:26:16 metrics/test.mAP:   93.140
2025-08-22 00:26:16 metrics/test.mAR:   95.333
2025-08-22 00:26:16 metrics/test.rmse_detections:10.198
2025-08-22 00:26:16 metrics/test.rmse_detections_pcutoff:4.446
2025-08-22 00:26:16 Epoch 90/200 (lr=0.0001), train loss 0.00073, valid loss 0.00315
2025-08-22 00:30:32 Epoch 91/200 (lr=0.0001), train loss 0.00075
2025-08-22 00:34:51 Epoch 92/200 (lr=0.0001), train loss 0.00070
2025-08-22 00:38:58 Training with configuration:
2025-08-22 00:38:58 data:
2025-08-22 00:38:58   colormode: RGB
2025-08-22 00:38:58   inference:
2025-08-22 00:38:58     normalize_images: True
2025-08-22 00:38:58   train:
2025-08-22 00:38:58     affine:
2025-08-22 00:38:58       p: 0.5
2025-08-22 00:38:58       rotation: 30
2025-08-22 00:38:58       scaling: [1.0, 1.0]
2025-08-22 00:38:58       translation: 0
2025-08-22 00:38:58     collate:
2025-08-22 00:38:58       type: ResizeFromDataSizeCollate
2025-08-22 00:38:58       min_scale: 0.4
2025-08-22 00:38:58       max_scale: 1.0
2025-08-22 00:38:58       min_short_side: 128
2025-08-22 00:38:58       max_short_side: 1152
2025-08-22 00:38:58       multiple_of: 32
2025-08-22 00:38:58       to_square: False
2025-08-22 00:38:58     covering: False
2025-08-22 00:38:58     gaussian_noise: 12.75
2025-08-22 00:38:58     hist_eq: False
2025-08-22 00:38:58     motion_blur: False
2025-08-22 00:38:58     normalize_images: True
2025-08-22 00:38:58 device: auto
2025-08-22 00:38:58 metadata:
2025-08-22 00:38:58   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 00:38:58   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 00:38:58   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 00:38:58   unique_bodyparts: []
2025-08-22 00:38:58   individuals: ['animal']
2025-08-22 00:38:58   with_identity: None
2025-08-22 00:38:58 method: bu
2025-08-22 00:38:58 model:
2025-08-22 00:38:58   backbone:
2025-08-22 00:38:58     type: ResNet
2025-08-22 00:38:58     model_name: resnet50_gn
2025-08-22 00:38:58     output_stride: 16
2025-08-22 00:38:58     freeze_bn_stats: True
2025-08-22 00:38:58     freeze_bn_weights: False
2025-08-22 00:38:58   backbone_output_channels: 2048
2025-08-22 00:38:58   heads:
2025-08-22 00:38:58     bodypart:
2025-08-22 00:38:58       type: HeatmapHead
2025-08-22 00:38:58       weight_init: normal
2025-08-22 00:38:58       predictor:
2025-08-22 00:38:58         type: HeatmapPredictor
2025-08-22 00:38:58         apply_sigmoid: False
2025-08-22 00:38:58         clip_scores: True
2025-08-22 00:38:58         location_refinement: True
2025-08-22 00:38:58         locref_std: 7.2801
2025-08-22 00:38:58       target_generator:
2025-08-22 00:38:58         type: HeatmapGaussianGenerator
2025-08-22 00:38:58         num_heatmaps: 9
2025-08-22 00:38:58         pos_dist_thresh: 17
2025-08-22 00:38:58         heatmap_mode: KEYPOINT
2025-08-22 00:38:58         generate_locref: True
2025-08-22 00:38:58         locref_std: 7.2801
2025-08-22 00:38:58       criterion:
2025-08-22 00:38:58         heatmap:
2025-08-22 00:38:58           type: WeightedMSECriterion
2025-08-22 00:38:58           weight: 1.0
2025-08-22 00:38:58         locref:
2025-08-22 00:38:58           type: WeightedHuberCriterion
2025-08-22 00:38:58           weight: 0.05
2025-08-22 00:38:58       heatmap_config:
2025-08-22 00:38:58         channels: [2048, 9]
2025-08-22 00:38:58         kernel_size: [3]
2025-08-22 00:38:58         strides: [2]
2025-08-22 00:38:58       locref_config:
2025-08-22 00:38:58         channels: [2048, 18]
2025-08-22 00:38:58         kernel_size: [3]
2025-08-22 00:38:58         strides: [2]
2025-08-22 00:38:58 net_type: resnet_50
2025-08-22 00:38:58 runner:
2025-08-22 00:38:58   type: PoseTrainingRunner
2025-08-22 00:38:58   gpus: None
2025-08-22 00:38:58   key_metric: test.mAP
2025-08-22 00:38:58   key_metric_asc: True
2025-08-22 00:38:58   eval_interval: 10
2025-08-22 00:38:58   optimizer:
2025-08-22 00:38:58     type: AdamW
2025-08-22 00:38:58     params:
2025-08-22 00:38:58       lr: 0.0001
2025-08-22 00:38:58   scheduler:
2025-08-22 00:38:58     type: LRListScheduler
2025-08-22 00:38:58     params:
2025-08-22 00:38:58       lr_list: [[1e-05], [1e-06]]
2025-08-22 00:38:58       milestones: [160, 190]
2025-08-22 00:38:58   snapshots:
2025-08-22 00:38:58     max_snapshots: 5
2025-08-22 00:38:58     save_epochs: 25
2025-08-22 00:38:58     save_optimizer_state: False
2025-08-22 00:38:58 train_settings:
2025-08-22 00:38:58   batch_size: 16
2025-08-22 00:38:58   dataloader_workers: 0
2025-08-22 00:38:58   dataloader_pin_memory: True
2025-08-22 00:38:58   display_iters: 500
2025-08-22 00:38:58   epochs: 200
2025-08-22 00:38:58   seed: 42
2025-08-22 00:38:58 init_weights: custom
2025-08-22 00:38:58 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 00:38:58 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 00:38:58 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 00:39:00 Data Transforms:
2025-08-22 00:39:00   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:39:00   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:39:02 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 00:39:02 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 00:39:02 Using 1127 images and 60 for testing
2025-08-22 00:39:02 
Starting pose model training...
--------------------------------------------------
2025-08-22 00:41:06 Training with configuration:
2025-08-22 00:41:06 data:
2025-08-22 00:41:06   colormode: RGB
2025-08-22 00:41:06   inference:
2025-08-22 00:41:06     normalize_images: True
2025-08-22 00:41:06   train:
2025-08-22 00:41:06     affine:
2025-08-22 00:41:06       p: 0.5
2025-08-22 00:41:06       rotation: 30
2025-08-22 00:41:06       scaling: [1.0, 1.0]
2025-08-22 00:41:06       translation: 0
2025-08-22 00:41:06     collate:
2025-08-22 00:41:06       type: ResizeFromDataSizeCollate
2025-08-22 00:41:06       min_scale: 0.4
2025-08-22 00:41:06       max_scale: 1.0
2025-08-22 00:41:06       min_short_side: 128
2025-08-22 00:41:06       max_short_side: 1152
2025-08-22 00:41:06       multiple_of: 32
2025-08-22 00:41:06       to_square: False
2025-08-22 00:41:06     covering: False
2025-08-22 00:41:06     gaussian_noise: 12.75
2025-08-22 00:41:06     hist_eq: False
2025-08-22 00:41:06     motion_blur: False
2025-08-22 00:41:06     normalize_images: True
2025-08-22 00:41:06 device: auto
2025-08-22 00:41:06 metadata:
2025-08-22 00:41:06   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 00:41:06   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 00:41:06   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 00:41:06   unique_bodyparts: []
2025-08-22 00:41:06   individuals: ['animal']
2025-08-22 00:41:06   with_identity: None
2025-08-22 00:41:06 method: bu
2025-08-22 00:41:06 model:
2025-08-22 00:41:06   backbone:
2025-08-22 00:41:06     type: ResNet
2025-08-22 00:41:06     model_name: resnet50_gn
2025-08-22 00:41:06     output_stride: 16
2025-08-22 00:41:06     freeze_bn_stats: True
2025-08-22 00:41:06     freeze_bn_weights: False
2025-08-22 00:41:06   backbone_output_channels: 2048
2025-08-22 00:41:06   heads:
2025-08-22 00:41:06     bodypart:
2025-08-22 00:41:06       type: HeatmapHead
2025-08-22 00:41:06       weight_init: normal
2025-08-22 00:41:06       predictor:
2025-08-22 00:41:06         type: HeatmapPredictor
2025-08-22 00:41:06         apply_sigmoid: False
2025-08-22 00:41:06         clip_scores: True
2025-08-22 00:41:06         location_refinement: True
2025-08-22 00:41:06         locref_std: 7.2801
2025-08-22 00:41:06       target_generator:
2025-08-22 00:41:06         type: HeatmapGaussianGenerator
2025-08-22 00:41:06         num_heatmaps: 9
2025-08-22 00:41:06         pos_dist_thresh: 17
2025-08-22 00:41:06         heatmap_mode: KEYPOINT
2025-08-22 00:41:06         generate_locref: True
2025-08-22 00:41:06         locref_std: 7.2801
2025-08-22 00:41:06       criterion:
2025-08-22 00:41:06         heatmap:
2025-08-22 00:41:06           type: WeightedMSECriterion
2025-08-22 00:41:06           weight: 1.0
2025-08-22 00:41:06         locref:
2025-08-22 00:41:06           type: WeightedHuberCriterion
2025-08-22 00:41:06           weight: 0.05
2025-08-22 00:41:06       heatmap_config:
2025-08-22 00:41:06         channels: [2048, 9]
2025-08-22 00:41:06         kernel_size: [3]
2025-08-22 00:41:06         strides: [2]
2025-08-22 00:41:06       locref_config:
2025-08-22 00:41:06         channels: [2048, 18]
2025-08-22 00:41:06         kernel_size: [3]
2025-08-22 00:41:06         strides: [2]
2025-08-22 00:41:06 net_type: resnet_50
2025-08-22 00:41:06 runner:
2025-08-22 00:41:06   type: PoseTrainingRunner
2025-08-22 00:41:06   gpus: None
2025-08-22 00:41:06   key_metric: test.mAP
2025-08-22 00:41:06   key_metric_asc: True
2025-08-22 00:41:06   eval_interval: 10
2025-08-22 00:41:06   optimizer:
2025-08-22 00:41:06     type: AdamW
2025-08-22 00:41:06     params:
2025-08-22 00:41:06       lr: 0.0001
2025-08-22 00:41:06   scheduler:
2025-08-22 00:41:06     type: LRListScheduler
2025-08-22 00:41:06     params:
2025-08-22 00:41:06       lr_list: [[1e-05], [1e-06]]
2025-08-22 00:41:06       milestones: [160, 190]
2025-08-22 00:41:06   snapshots:
2025-08-22 00:41:06     max_snapshots: 5
2025-08-22 00:41:06     save_epochs: 25
2025-08-22 00:41:06     save_optimizer_state: False
2025-08-22 00:41:06 train_settings:
2025-08-22 00:41:06   batch_size: 16
2025-08-22 00:41:06   dataloader_workers: 0
2025-08-22 00:41:06   dataloader_pin_memory: True
2025-08-22 00:41:06   display_iters: 500
2025-08-22 00:41:06   epochs: 200
2025-08-22 00:41:06   seed: 42
2025-08-22 00:41:06 init_weights: custom
2025-08-22 00:41:06 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 00:41:06 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 00:41:06 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 00:42:38 Training with configuration:
2025-08-22 00:42:38 data:
2025-08-22 00:42:38   colormode: RGB
2025-08-22 00:42:38   inference:
2025-08-22 00:42:38     normalize_images: True
2025-08-22 00:42:38   train:
2025-08-22 00:42:38     affine:
2025-08-22 00:42:38       p: 0.5
2025-08-22 00:42:38       rotation: 30
2025-08-22 00:42:38       scaling: [1.0, 1.0]
2025-08-22 00:42:38       translation: 0
2025-08-22 00:42:38     collate:
2025-08-22 00:42:38       type: ResizeFromDataSizeCollate
2025-08-22 00:42:38       min_scale: 0.4
2025-08-22 00:42:38       max_scale: 1.0
2025-08-22 00:42:38       min_short_side: 128
2025-08-22 00:42:38       max_short_side: 1152
2025-08-22 00:42:38       multiple_of: 32
2025-08-22 00:42:38       to_square: False
2025-08-22 00:42:38     covering: False
2025-08-22 00:42:38     gaussian_noise: 12.75
2025-08-22 00:42:38     hist_eq: False
2025-08-22 00:42:38     motion_blur: False
2025-08-22 00:42:38     normalize_images: True
2025-08-22 00:42:38 device: auto
2025-08-22 00:42:38 metadata:
2025-08-22 00:42:38   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 00:42:38   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 00:42:38   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 00:42:38   unique_bodyparts: []
2025-08-22 00:42:38   individuals: ['animal']
2025-08-22 00:42:38   with_identity: None
2025-08-22 00:42:38 method: bu
2025-08-22 00:42:38 model:
2025-08-22 00:42:38   backbone:
2025-08-22 00:42:38     type: ResNet
2025-08-22 00:42:38     model_name: resnet50_gn
2025-08-22 00:42:38     output_stride: 16
2025-08-22 00:42:38     freeze_bn_stats: True
2025-08-22 00:42:38     freeze_bn_weights: False
2025-08-22 00:42:38   backbone_output_channels: 2048
2025-08-22 00:42:38   heads:
2025-08-22 00:42:38     bodypart:
2025-08-22 00:42:38       type: HeatmapHead
2025-08-22 00:42:38       weight_init: normal
2025-08-22 00:42:38       predictor:
2025-08-22 00:42:38         type: HeatmapPredictor
2025-08-22 00:42:38         apply_sigmoid: False
2025-08-22 00:42:38         clip_scores: True
2025-08-22 00:42:38         location_refinement: True
2025-08-22 00:42:38         locref_std: 7.2801
2025-08-22 00:42:38       target_generator:
2025-08-22 00:42:38         type: HeatmapGaussianGenerator
2025-08-22 00:42:38         num_heatmaps: 9
2025-08-22 00:42:38         pos_dist_thresh: 17
2025-08-22 00:42:38         heatmap_mode: KEYPOINT
2025-08-22 00:42:38         generate_locref: True
2025-08-22 00:42:38         locref_std: 7.2801
2025-08-22 00:42:38       criterion:
2025-08-22 00:42:38         heatmap:
2025-08-22 00:42:38           type: WeightedMSECriterion
2025-08-22 00:42:38           weight: 1.0
2025-08-22 00:42:38         locref:
2025-08-22 00:42:38           type: WeightedHuberCriterion
2025-08-22 00:42:38           weight: 0.05
2025-08-22 00:42:38       heatmap_config:
2025-08-22 00:42:38         channels: [2048, 9]
2025-08-22 00:42:38         kernel_size: [3]
2025-08-22 00:42:38         strides: [2]
2025-08-22 00:42:38       locref_config:
2025-08-22 00:42:38         channels: [2048, 18]
2025-08-22 00:42:38         kernel_size: [3]
2025-08-22 00:42:38         strides: [2]
2025-08-22 00:42:38 net_type: resnet_50
2025-08-22 00:42:38 runner:
2025-08-22 00:42:38   type: PoseTrainingRunner
2025-08-22 00:42:38   gpus: None
2025-08-22 00:42:38   key_metric: test.mAP
2025-08-22 00:42:38   key_metric_asc: True
2025-08-22 00:42:38   eval_interval: 10
2025-08-22 00:42:38   optimizer:
2025-08-22 00:42:38     type: AdamW
2025-08-22 00:42:38     params:
2025-08-22 00:42:38       lr: 0.0001
2025-08-22 00:42:38   scheduler:
2025-08-22 00:42:38     type: LRListScheduler
2025-08-22 00:42:38     params:
2025-08-22 00:42:38       lr_list: [[1e-05], [1e-06]]
2025-08-22 00:42:38       milestones: [160, 190]
2025-08-22 00:42:38   snapshots:
2025-08-22 00:42:38     max_snapshots: 5
2025-08-22 00:42:38     save_epochs: 25
2025-08-22 00:42:38     save_optimizer_state: False
2025-08-22 00:42:38 train_settings:
2025-08-22 00:42:38   batch_size: 16
2025-08-22 00:42:38   dataloader_workers: 0
2025-08-22 00:42:38   dataloader_pin_memory: True
2025-08-22 00:42:38   display_iters: 500
2025-08-22 00:42:38   epochs: 200
2025-08-22 00:42:38   seed: 42
2025-08-22 00:42:38 init_weights: custom
2025-08-22 00:42:38 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 00:42:38 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 00:42:38 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 00:42:59 Training with configuration:
2025-08-22 00:42:59 data:
2025-08-22 00:42:59   colormode: RGB
2025-08-22 00:42:59   inference:
2025-08-22 00:42:59     normalize_images: True
2025-08-22 00:42:59   train:
2025-08-22 00:42:59     affine:
2025-08-22 00:42:59       p: 0.5
2025-08-22 00:42:59       rotation: 30
2025-08-22 00:42:59       scaling: [1.0, 1.0]
2025-08-22 00:42:59       translation: 0
2025-08-22 00:42:59     collate:
2025-08-22 00:42:59       type: ResizeFromDataSizeCollate
2025-08-22 00:42:59       min_scale: 0.4
2025-08-22 00:42:59       max_scale: 1.0
2025-08-22 00:42:59       min_short_side: 128
2025-08-22 00:42:59       max_short_side: 1152
2025-08-22 00:42:59       multiple_of: 32
2025-08-22 00:42:59       to_square: False
2025-08-22 00:42:59     covering: False
2025-08-22 00:42:59     gaussian_noise: 12.75
2025-08-22 00:42:59     hist_eq: False
2025-08-22 00:42:59     motion_blur: False
2025-08-22 00:42:59     normalize_images: True
2025-08-22 00:42:59 device: auto
2025-08-22 00:42:59 metadata:
2025-08-22 00:42:59   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 00:42:59   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 00:42:59   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 00:42:59   unique_bodyparts: []
2025-08-22 00:42:59   individuals: ['animal']
2025-08-22 00:42:59   with_identity: None
2025-08-22 00:42:59 method: bu
2025-08-22 00:42:59 model:
2025-08-22 00:42:59   backbone:
2025-08-22 00:42:59     type: ResNet
2025-08-22 00:42:59     model_name: resnet50_gn
2025-08-22 00:42:59     output_stride: 16
2025-08-22 00:42:59     freeze_bn_stats: True
2025-08-22 00:42:59     freeze_bn_weights: False
2025-08-22 00:42:59   backbone_output_channels: 2048
2025-08-22 00:42:59   heads:
2025-08-22 00:42:59     bodypart:
2025-08-22 00:42:59       type: HeatmapHead
2025-08-22 00:42:59       weight_init: normal
2025-08-22 00:42:59       predictor:
2025-08-22 00:42:59         type: HeatmapPredictor
2025-08-22 00:42:59         apply_sigmoid: False
2025-08-22 00:42:59         clip_scores: True
2025-08-22 00:42:59         location_refinement: True
2025-08-22 00:42:59         locref_std: 7.2801
2025-08-22 00:42:59       target_generator:
2025-08-22 00:42:59         type: HeatmapGaussianGenerator
2025-08-22 00:42:59         num_heatmaps: 9
2025-08-22 00:42:59         pos_dist_thresh: 17
2025-08-22 00:42:59         heatmap_mode: KEYPOINT
2025-08-22 00:42:59         generate_locref: True
2025-08-22 00:42:59         locref_std: 7.2801
2025-08-22 00:42:59       criterion:
2025-08-22 00:42:59         heatmap:
2025-08-22 00:42:59           type: WeightedMSECriterion
2025-08-22 00:42:59           weight: 1.0
2025-08-22 00:42:59         locref:
2025-08-22 00:42:59           type: WeightedHuberCriterion
2025-08-22 00:42:59           weight: 0.05
2025-08-22 00:42:59       heatmap_config:
2025-08-22 00:42:59         channels: [2048, 9]
2025-08-22 00:42:59         kernel_size: [3]
2025-08-22 00:42:59         strides: [2]
2025-08-22 00:42:59       locref_config:
2025-08-22 00:42:59         channels: [2048, 18]
2025-08-22 00:42:59         kernel_size: [3]
2025-08-22 00:42:59         strides: [2]
2025-08-22 00:42:59 net_type: resnet_50
2025-08-22 00:42:59 runner:
2025-08-22 00:42:59   type: PoseTrainingRunner
2025-08-22 00:42:59   gpus: None
2025-08-22 00:42:59   key_metric: test.mAP
2025-08-22 00:42:59   key_metric_asc: True
2025-08-22 00:42:59   eval_interval: 10
2025-08-22 00:42:59   optimizer:
2025-08-22 00:42:59     type: AdamW
2025-08-22 00:42:59     params:
2025-08-22 00:42:59       lr: 0.0001
2025-08-22 00:42:59   scheduler:
2025-08-22 00:42:59     type: LRListScheduler
2025-08-22 00:42:59     params:
2025-08-22 00:42:59       lr_list: [[1e-05], [1e-06]]
2025-08-22 00:42:59       milestones: [160, 190]
2025-08-22 00:42:59   snapshots:
2025-08-22 00:42:59     max_snapshots: 5
2025-08-22 00:42:59     save_epochs: 25
2025-08-22 00:42:59     save_optimizer_state: False
2025-08-22 00:42:59 train_settings:
2025-08-22 00:42:59   batch_size: 16
2025-08-22 00:42:59   dataloader_workers: 0
2025-08-22 00:42:59   dataloader_pin_memory: True
2025-08-22 00:42:59   display_iters: 500
2025-08-22 00:42:59   epochs: 200
2025-08-22 00:42:59   seed: 42
2025-08-22 00:42:59 init_weights: custom
2025-08-22 00:42:59 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 00:43:00 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 00:43:00 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 00:43:01 Data Transforms:
2025-08-22 00:43:01   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:43:01   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:43:05 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 00:43:05 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 00:43:05 Using 1127 images and 60 for testing
2025-08-22 00:43:05 
Starting pose model training...
--------------------------------------------------
2025-08-22 00:45:15 Training with configuration:
2025-08-22 00:45:15 data:
2025-08-22 00:45:15   colormode: RGB
2025-08-22 00:45:15   inference:
2025-08-22 00:45:15     normalize_images: True
2025-08-22 00:45:15   train:
2025-08-22 00:45:15     affine:
2025-08-22 00:45:15       p: 0.5
2025-08-22 00:45:15       rotation: 30
2025-08-22 00:45:15       scaling: [1.0, 1.0]
2025-08-22 00:45:15       translation: 0
2025-08-22 00:45:15     collate:
2025-08-22 00:45:15       type: ResizeFromDataSizeCollate
2025-08-22 00:45:15       min_scale: 0.4
2025-08-22 00:45:15       max_scale: 1.0
2025-08-22 00:45:15       min_short_side: 128
2025-08-22 00:45:15       max_short_side: 1152
2025-08-22 00:45:15       multiple_of: 32
2025-08-22 00:45:15       to_square: False
2025-08-22 00:45:15     covering: False
2025-08-22 00:45:15     gaussian_noise: 12.75
2025-08-22 00:45:15     hist_eq: False
2025-08-22 00:45:15     motion_blur: False
2025-08-22 00:45:15     normalize_images: True
2025-08-22 00:45:15 device: auto
2025-08-22 00:45:15 metadata:
2025-08-22 00:45:15   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 00:45:15   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 00:45:15   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 00:45:15   unique_bodyparts: []
2025-08-22 00:45:15   individuals: ['animal']
2025-08-22 00:45:15   with_identity: None
2025-08-22 00:45:15 method: bu
2025-08-22 00:45:15 model:
2025-08-22 00:45:15   backbone:
2025-08-22 00:45:15     type: ResNet
2025-08-22 00:45:15     model_name: resnet50_gn
2025-08-22 00:45:15     output_stride: 16
2025-08-22 00:45:15     freeze_bn_stats: True
2025-08-22 00:45:15     freeze_bn_weights: False
2025-08-22 00:45:15   backbone_output_channels: 2048
2025-08-22 00:45:15   heads:
2025-08-22 00:45:15     bodypart:
2025-08-22 00:45:15       type: HeatmapHead
2025-08-22 00:45:15       weight_init: normal
2025-08-22 00:45:15       predictor:
2025-08-22 00:45:15         type: HeatmapPredictor
2025-08-22 00:45:15         apply_sigmoid: False
2025-08-22 00:45:15         clip_scores: True
2025-08-22 00:45:15         location_refinement: True
2025-08-22 00:45:15         locref_std: 7.2801
2025-08-22 00:45:15       target_generator:
2025-08-22 00:45:15         type: HeatmapGaussianGenerator
2025-08-22 00:45:15         num_heatmaps: 9
2025-08-22 00:45:15         pos_dist_thresh: 17
2025-08-22 00:45:15         heatmap_mode: KEYPOINT
2025-08-22 00:45:15         generate_locref: True
2025-08-22 00:45:15         locref_std: 7.2801
2025-08-22 00:45:15       criterion:
2025-08-22 00:45:15         heatmap:
2025-08-22 00:45:15           type: WeightedMSECriterion
2025-08-22 00:45:15           weight: 1.0
2025-08-22 00:45:15         locref:
2025-08-22 00:45:15           type: WeightedHuberCriterion
2025-08-22 00:45:15           weight: 0.05
2025-08-22 00:45:15       heatmap_config:
2025-08-22 00:45:15         channels: [2048, 9]
2025-08-22 00:45:15         kernel_size: [3]
2025-08-22 00:45:15         strides: [2]
2025-08-22 00:45:15       locref_config:
2025-08-22 00:45:15         channels: [2048, 18]
2025-08-22 00:45:15         kernel_size: [3]
2025-08-22 00:45:15         strides: [2]
2025-08-22 00:45:15 net_type: resnet_50
2025-08-22 00:45:15 runner:
2025-08-22 00:45:15   type: PoseTrainingRunner
2025-08-22 00:45:15   gpus: None
2025-08-22 00:45:15   key_metric: test.mAP
2025-08-22 00:45:15   key_metric_asc: True
2025-08-22 00:45:15   eval_interval: 10
2025-08-22 00:45:15   optimizer:
2025-08-22 00:45:15     type: AdamW
2025-08-22 00:45:15     params:
2025-08-22 00:45:15       lr: 0.0001
2025-08-22 00:45:15   scheduler:
2025-08-22 00:45:15     type: LRListScheduler
2025-08-22 00:45:15     params:
2025-08-22 00:45:15       lr_list: [[1e-05], [1e-06]]
2025-08-22 00:45:15       milestones: [160, 190]
2025-08-22 00:45:15   snapshots:
2025-08-22 00:45:15     max_snapshots: 5
2025-08-22 00:45:15     save_epochs: 25
2025-08-22 00:45:15     save_optimizer_state: False
2025-08-22 00:45:15 train_settings:
2025-08-22 00:45:15   batch_size: 16
2025-08-22 00:45:15   dataloader_workers: 0
2025-08-22 00:45:15   dataloader_pin_memory: True
2025-08-22 00:45:15   display_iters: 500
2025-08-22 00:45:15   epochs: 200
2025-08-22 00:45:15   seed: 42
2025-08-22 00:45:15 init_weights: custom
2025-08-22 00:45:15 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 00:45:16 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 00:45:16 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 00:45:17 Data Transforms:
2025-08-22 00:45:17   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:45:17   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:45:26 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 00:45:26 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 00:45:26 Using 1127 images and 60 for testing
2025-08-22 00:45:26 
Starting pose model training...
--------------------------------------------------
2025-08-22 00:47:24 Training with configuration:
2025-08-22 00:47:24 data:
2025-08-22 00:47:24   colormode: RGB
2025-08-22 00:47:24   inference:
2025-08-22 00:47:24     normalize_images: True
2025-08-22 00:47:24   train:
2025-08-22 00:47:24     affine:
2025-08-22 00:47:24       p: 0.5
2025-08-22 00:47:24       rotation: 30
2025-08-22 00:47:24       scaling: [1.0, 1.0]
2025-08-22 00:47:24       translation: 0
2025-08-22 00:47:24     collate:
2025-08-22 00:47:24       type: ResizeFromDataSizeCollate
2025-08-22 00:47:24       min_scale: 0.4
2025-08-22 00:47:24       max_scale: 1.0
2025-08-22 00:47:24       min_short_side: 128
2025-08-22 00:47:24       max_short_side: 1152
2025-08-22 00:47:24       multiple_of: 32
2025-08-22 00:47:24       to_square: False
2025-08-22 00:47:24     covering: False
2025-08-22 00:47:24     gaussian_noise: 12.75
2025-08-22 00:47:24     hist_eq: False
2025-08-22 00:47:24     motion_blur: False
2025-08-22 00:47:24     normalize_images: True
2025-08-22 00:47:24 device: auto
2025-08-22 00:47:24 metadata:
2025-08-22 00:47:24   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 00:47:24   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 00:47:24   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 00:47:24   unique_bodyparts: []
2025-08-22 00:47:24   individuals: ['animal']
2025-08-22 00:47:24   with_identity: None
2025-08-22 00:47:24 method: bu
2025-08-22 00:47:24 model:
2025-08-22 00:47:24   backbone:
2025-08-22 00:47:24     type: ResNet
2025-08-22 00:47:24     model_name: resnet50_gn
2025-08-22 00:47:24     output_stride: 16
2025-08-22 00:47:24     freeze_bn_stats: True
2025-08-22 00:47:24     freeze_bn_weights: False
2025-08-22 00:47:24   backbone_output_channels: 2048
2025-08-22 00:47:24   heads:
2025-08-22 00:47:24     bodypart:
2025-08-22 00:47:24       type: HeatmapHead
2025-08-22 00:47:24       weight_init: normal
2025-08-22 00:47:24       predictor:
2025-08-22 00:47:24         type: HeatmapPredictor
2025-08-22 00:47:24         apply_sigmoid: False
2025-08-22 00:47:24         clip_scores: True
2025-08-22 00:47:24         location_refinement: True
2025-08-22 00:47:24         locref_std: 7.2801
2025-08-22 00:47:24       target_generator:
2025-08-22 00:47:24         type: HeatmapGaussianGenerator
2025-08-22 00:47:24         num_heatmaps: 9
2025-08-22 00:47:24         pos_dist_thresh: 17
2025-08-22 00:47:24         heatmap_mode: KEYPOINT
2025-08-22 00:47:24         generate_locref: True
2025-08-22 00:47:24         locref_std: 7.2801
2025-08-22 00:47:24       criterion:
2025-08-22 00:47:24         heatmap:
2025-08-22 00:47:24           type: WeightedMSECriterion
2025-08-22 00:47:24           weight: 1.0
2025-08-22 00:47:24         locref:
2025-08-22 00:47:24           type: WeightedHuberCriterion
2025-08-22 00:47:24           weight: 0.05
2025-08-22 00:47:24       heatmap_config:
2025-08-22 00:47:24         channels: [2048, 9]
2025-08-22 00:47:24         kernel_size: [3]
2025-08-22 00:47:24         strides: [2]
2025-08-22 00:47:24       locref_config:
2025-08-22 00:47:24         channels: [2048, 18]
2025-08-22 00:47:24         kernel_size: [3]
2025-08-22 00:47:24         strides: [2]
2025-08-22 00:47:24 net_type: resnet_50
2025-08-22 00:47:24 runner:
2025-08-22 00:47:24   type: PoseTrainingRunner
2025-08-22 00:47:24   gpus: None
2025-08-22 00:47:24   key_metric: test.mAP
2025-08-22 00:47:24   key_metric_asc: True
2025-08-22 00:47:24   eval_interval: 10
2025-08-22 00:47:24   optimizer:
2025-08-22 00:47:24     type: AdamW
2025-08-22 00:47:24     params:
2025-08-22 00:47:24       lr: 0.0001
2025-08-22 00:47:24   scheduler:
2025-08-22 00:47:24     type: LRListScheduler
2025-08-22 00:47:24     params:
2025-08-22 00:47:24       lr_list: [[1e-05], [1e-06]]
2025-08-22 00:47:24       milestones: [160, 190]
2025-08-22 00:47:24   snapshots:
2025-08-22 00:47:24     max_snapshots: 5
2025-08-22 00:47:24     save_epochs: 25
2025-08-22 00:47:24     save_optimizer_state: False
2025-08-22 00:47:24 train_settings:
2025-08-22 00:47:24   batch_size: 8
2025-08-22 00:47:24   dataloader_workers: 0
2025-08-22 00:47:24   dataloader_pin_memory: True
2025-08-22 00:47:24   display_iters: 500
2025-08-22 00:47:24   epochs: 200
2025-08-22 00:47:24   seed: 42
2025-08-22 00:47:24 init_weights: custom
2025-08-22 00:47:24 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 00:47:25 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 00:47:25 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 00:47:26 Data Transforms:
2025-08-22 00:47:26   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:47:26   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:47:28 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 00:47:28 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 00:47:28 Using 1127 images and 60 for testing
2025-08-22 00:47:28 
Starting pose model training...
--------------------------------------------------
2025-08-22 00:51:10 Training with configuration:
2025-08-22 00:51:10 data:
2025-08-22 00:51:10   colormode: RGB
2025-08-22 00:51:10   inference:
2025-08-22 00:51:10     normalize_images: True
2025-08-22 00:51:10   train:
2025-08-22 00:51:10     affine:
2025-08-22 00:51:10       p: 0.5
2025-08-22 00:51:10       rotation: 30
2025-08-22 00:51:10       scaling: [1.0, 1.0]
2025-08-22 00:51:10       translation: 0
2025-08-22 00:51:10     collate:
2025-08-22 00:51:10       type: ResizeFromDataSizeCollate
2025-08-22 00:51:10       min_scale: 0.4
2025-08-22 00:51:10       max_scale: 1.0
2025-08-22 00:51:10       min_short_side: 128
2025-08-22 00:51:10       max_short_side: 1152
2025-08-22 00:51:10       multiple_of: 32
2025-08-22 00:51:10       to_square: False
2025-08-22 00:51:10     covering: False
2025-08-22 00:51:10     gaussian_noise: 12.75
2025-08-22 00:51:10     hist_eq: False
2025-08-22 00:51:10     motion_blur: False
2025-08-22 00:51:10     normalize_images: True
2025-08-22 00:51:10 device: auto
2025-08-22 00:51:10 metadata:
2025-08-22 00:51:10   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 00:51:10   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 00:51:10   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 00:51:10   unique_bodyparts: []
2025-08-22 00:51:10   individuals: ['animal']
2025-08-22 00:51:10   with_identity: None
2025-08-22 00:51:10 method: bu
2025-08-22 00:51:10 model:
2025-08-22 00:51:10   backbone:
2025-08-22 00:51:10     type: ResNet
2025-08-22 00:51:10     model_name: resnet50_gn
2025-08-22 00:51:10     output_stride: 16
2025-08-22 00:51:10     freeze_bn_stats: True
2025-08-22 00:51:10     freeze_bn_weights: False
2025-08-22 00:51:10   backbone_output_channels: 2048
2025-08-22 00:51:10   heads:
2025-08-22 00:51:10     bodypart:
2025-08-22 00:51:10       type: HeatmapHead
2025-08-22 00:51:10       weight_init: normal
2025-08-22 00:51:10       predictor:
2025-08-22 00:51:10         type: HeatmapPredictor
2025-08-22 00:51:10         apply_sigmoid: False
2025-08-22 00:51:10         clip_scores: True
2025-08-22 00:51:10         location_refinement: True
2025-08-22 00:51:10         locref_std: 7.2801
2025-08-22 00:51:10       target_generator:
2025-08-22 00:51:10         type: HeatmapGaussianGenerator
2025-08-22 00:51:10         num_heatmaps: 9
2025-08-22 00:51:10         pos_dist_thresh: 17
2025-08-22 00:51:10         heatmap_mode: KEYPOINT
2025-08-22 00:51:10         generate_locref: True
2025-08-22 00:51:10         locref_std: 7.2801
2025-08-22 00:51:10       criterion:
2025-08-22 00:51:10         heatmap:
2025-08-22 00:51:10           type: WeightedMSECriterion
2025-08-22 00:51:10           weight: 1.0
2025-08-22 00:51:10         locref:
2025-08-22 00:51:10           type: WeightedHuberCriterion
2025-08-22 00:51:10           weight: 0.05
2025-08-22 00:51:10       heatmap_config:
2025-08-22 00:51:10         channels: [2048, 9]
2025-08-22 00:51:10         kernel_size: [3]
2025-08-22 00:51:10         strides: [2]
2025-08-22 00:51:10       locref_config:
2025-08-22 00:51:10         channels: [2048, 18]
2025-08-22 00:51:10         kernel_size: [3]
2025-08-22 00:51:10         strides: [2]
2025-08-22 00:51:10 net_type: resnet_50
2025-08-22 00:51:10 runner:
2025-08-22 00:51:10   type: PoseTrainingRunner
2025-08-22 00:51:10   gpus: None
2025-08-22 00:51:10   key_metric: test.mAP
2025-08-22 00:51:10   key_metric_asc: True
2025-08-22 00:51:10   eval_interval: 10
2025-08-22 00:51:10   optimizer:
2025-08-22 00:51:10     type: AdamW
2025-08-22 00:51:10     params:
2025-08-22 00:51:10       lr: 0.0001
2025-08-22 00:51:10   scheduler:
2025-08-22 00:51:10     type: LRListScheduler
2025-08-22 00:51:10     params:
2025-08-22 00:51:10       lr_list: [[1e-05], [1e-06]]
2025-08-22 00:51:10       milestones: [160, 190]
2025-08-22 00:51:10   snapshots:
2025-08-22 00:51:10     max_snapshots: 5
2025-08-22 00:51:10     save_epochs: 25
2025-08-22 00:51:10     save_optimizer_state: False
2025-08-22 00:51:10 train_settings:
2025-08-22 00:51:10   batch_size: 64
2025-08-22 00:51:10   dataloader_workers: 0
2025-08-22 00:51:10   dataloader_pin_memory: True
2025-08-22 00:51:10   display_iters: 500
2025-08-22 00:51:10   epochs: 200
2025-08-22 00:51:10   seed: 42
2025-08-22 00:51:10 init_weights: custom
2025-08-22 00:51:10 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 00:51:10 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 00:51:10 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 00:51:12 Data Transforms:
2025-08-22 00:51:12   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:51:12   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:51:14 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 00:51:14 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 00:51:14 Using 1127 images and 60 for testing
2025-08-22 00:51:14 
Starting pose model training...
--------------------------------------------------
2025-08-22 00:56:25 Training with configuration:
2025-08-22 00:56:25 data:
2025-08-22 00:56:25   colormode: RGB
2025-08-22 00:56:25   inference:
2025-08-22 00:56:25     normalize_images: True
2025-08-22 00:56:25   train:
2025-08-22 00:56:25     affine:
2025-08-22 00:56:25       p: 0.5
2025-08-22 00:56:25       rotation: 30
2025-08-22 00:56:25       scaling: [1.0, 1.0]
2025-08-22 00:56:25       translation: 0
2025-08-22 00:56:25     collate:
2025-08-22 00:56:25       type: ResizeFromDataSizeCollate
2025-08-22 00:56:25       min_scale: 0.4
2025-08-22 00:56:25       max_scale: 1.0
2025-08-22 00:56:25       min_short_side: 128
2025-08-22 00:56:25       max_short_side: 1152
2025-08-22 00:56:25       multiple_of: 32
2025-08-22 00:56:25       to_square: False
2025-08-22 00:56:25     covering: False
2025-08-22 00:56:25     gaussian_noise: 12.75
2025-08-22 00:56:25     hist_eq: False
2025-08-22 00:56:25     motion_blur: False
2025-08-22 00:56:25     normalize_images: True
2025-08-22 00:56:25 device: auto
2025-08-22 00:56:25 metadata:
2025-08-22 00:56:25   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 00:56:25   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 00:56:25   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 00:56:25   unique_bodyparts: []
2025-08-22 00:56:25   individuals: ['animal']
2025-08-22 00:56:25   with_identity: None
2025-08-22 00:56:25 method: bu
2025-08-22 00:56:25 model:
2025-08-22 00:56:25   backbone:
2025-08-22 00:56:25     type: ResNet
2025-08-22 00:56:25     model_name: resnet50_gn
2025-08-22 00:56:25     output_stride: 16
2025-08-22 00:56:25     freeze_bn_stats: True
2025-08-22 00:56:25     freeze_bn_weights: False
2025-08-22 00:56:25   backbone_output_channels: 2048
2025-08-22 00:56:25   heads:
2025-08-22 00:56:25     bodypart:
2025-08-22 00:56:25       type: HeatmapHead
2025-08-22 00:56:25       weight_init: normal
2025-08-22 00:56:25       predictor:
2025-08-22 00:56:25         type: HeatmapPredictor
2025-08-22 00:56:25         apply_sigmoid: False
2025-08-22 00:56:25         clip_scores: True
2025-08-22 00:56:25         location_refinement: True
2025-08-22 00:56:25         locref_std: 7.2801
2025-08-22 00:56:25       target_generator:
2025-08-22 00:56:25         type: HeatmapGaussianGenerator
2025-08-22 00:56:25         num_heatmaps: 9
2025-08-22 00:56:25         pos_dist_thresh: 17
2025-08-22 00:56:25         heatmap_mode: KEYPOINT
2025-08-22 00:56:25         generate_locref: True
2025-08-22 00:56:25         locref_std: 7.2801
2025-08-22 00:56:25       criterion:
2025-08-22 00:56:25         heatmap:
2025-08-22 00:56:25           type: WeightedMSECriterion
2025-08-22 00:56:25           weight: 1.0
2025-08-22 00:56:25         locref:
2025-08-22 00:56:25           type: WeightedHuberCriterion
2025-08-22 00:56:25           weight: 0.05
2025-08-22 00:56:25       heatmap_config:
2025-08-22 00:56:25         channels: [2048, 9]
2025-08-22 00:56:25         kernel_size: [3]
2025-08-22 00:56:25         strides: [2]
2025-08-22 00:56:25       locref_config:
2025-08-22 00:56:25         channels: [2048, 18]
2025-08-22 00:56:25         kernel_size: [3]
2025-08-22 00:56:25         strides: [2]
2025-08-22 00:56:25 net_type: resnet_50
2025-08-22 00:56:25 runner:
2025-08-22 00:56:25   type: PoseTrainingRunner
2025-08-22 00:56:25   gpus: None
2025-08-22 00:56:25   key_metric: test.mAP
2025-08-22 00:56:25   key_metric_asc: True
2025-08-22 00:56:25   eval_interval: 10
2025-08-22 00:56:25   optimizer:
2025-08-22 00:56:25     type: AdamW
2025-08-22 00:56:25     params:
2025-08-22 00:56:25       lr: 0.0001
2025-08-22 00:56:25   scheduler:
2025-08-22 00:56:25     type: LRListScheduler
2025-08-22 00:56:25     params:
2025-08-22 00:56:25       lr_list: [[1e-05], [1e-06]]
2025-08-22 00:56:25       milestones: [160, 190]
2025-08-22 00:56:25   snapshots:
2025-08-22 00:56:25     max_snapshots: 5
2025-08-22 00:56:25     save_epochs: 25
2025-08-22 00:56:25     save_optimizer_state: False
2025-08-22 00:56:25 train_settings:
2025-08-22 00:56:25   batch_size: 64
2025-08-22 00:56:25   dataloader_workers: 0
2025-08-22 00:56:25   dataloader_pin_memory: True
2025-08-22 00:56:25   display_iters: 500
2025-08-22 00:56:25   epochs: 200
2025-08-22 00:56:25   seed: 42
2025-08-22 00:56:25 init_weights: custom
2025-08-22 00:56:25 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 00:56:25 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 00:56:25 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 00:56:27 Data Transforms:
2025-08-22 00:56:27   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:56:27   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:56:28 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 00:56:28 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 00:56:28 Using 1127 images and 60 for testing
2025-08-22 00:56:28 
Starting pose model training...
--------------------------------------------------
2025-08-22 00:57:54 Training with configuration:
2025-08-22 00:57:54 data:
2025-08-22 00:57:54   colormode: RGB
2025-08-22 00:57:54   inference:
2025-08-22 00:57:54     normalize_images: True
2025-08-22 00:57:54   train:
2025-08-22 00:57:54     affine:
2025-08-22 00:57:54       p: 0.5
2025-08-22 00:57:54       rotation: 30
2025-08-22 00:57:54       scaling: [1.0, 1.0]
2025-08-22 00:57:54       translation: 0
2025-08-22 00:57:54     collate:
2025-08-22 00:57:54       type: ResizeFromDataSizeCollate
2025-08-22 00:57:54       min_scale: 0.4
2025-08-22 00:57:54       max_scale: 1.0
2025-08-22 00:57:54       min_short_side: 128
2025-08-22 00:57:54       max_short_side: 1152
2025-08-22 00:57:54       multiple_of: 32
2025-08-22 00:57:54       to_square: False
2025-08-22 00:57:54     covering: False
2025-08-22 00:57:54     gaussian_noise: 12.75
2025-08-22 00:57:54     hist_eq: False
2025-08-22 00:57:54     motion_blur: False
2025-08-22 00:57:54     normalize_images: True
2025-08-22 00:57:54 device: auto
2025-08-22 00:57:54 metadata:
2025-08-22 00:57:54   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 00:57:54   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 00:57:54   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 00:57:54   unique_bodyparts: []
2025-08-22 00:57:54   individuals: ['animal']
2025-08-22 00:57:54   with_identity: None
2025-08-22 00:57:54 method: bu
2025-08-22 00:57:54 model:
2025-08-22 00:57:54   backbone:
2025-08-22 00:57:54     type: ResNet
2025-08-22 00:57:54     model_name: resnet50_gn
2025-08-22 00:57:54     output_stride: 16
2025-08-22 00:57:54     freeze_bn_stats: True
2025-08-22 00:57:54     freeze_bn_weights: False
2025-08-22 00:57:54   backbone_output_channels: 2048
2025-08-22 00:57:54   heads:
2025-08-22 00:57:54     bodypart:
2025-08-22 00:57:54       type: HeatmapHead
2025-08-22 00:57:54       weight_init: normal
2025-08-22 00:57:54       predictor:
2025-08-22 00:57:54         type: HeatmapPredictor
2025-08-22 00:57:54         apply_sigmoid: False
2025-08-22 00:57:54         clip_scores: True
2025-08-22 00:57:54         location_refinement: True
2025-08-22 00:57:54         locref_std: 7.2801
2025-08-22 00:57:54       target_generator:
2025-08-22 00:57:54         type: HeatmapGaussianGenerator
2025-08-22 00:57:54         num_heatmaps: 9
2025-08-22 00:57:54         pos_dist_thresh: 17
2025-08-22 00:57:54         heatmap_mode: KEYPOINT
2025-08-22 00:57:54         generate_locref: True
2025-08-22 00:57:54         locref_std: 7.2801
2025-08-22 00:57:54       criterion:
2025-08-22 00:57:54         heatmap:
2025-08-22 00:57:54           type: WeightedMSECriterion
2025-08-22 00:57:54           weight: 1.0
2025-08-22 00:57:54         locref:
2025-08-22 00:57:54           type: WeightedHuberCriterion
2025-08-22 00:57:54           weight: 0.05
2025-08-22 00:57:54       heatmap_config:
2025-08-22 00:57:54         channels: [2048, 9]
2025-08-22 00:57:54         kernel_size: [3]
2025-08-22 00:57:54         strides: [2]
2025-08-22 00:57:54       locref_config:
2025-08-22 00:57:54         channels: [2048, 18]
2025-08-22 00:57:54         kernel_size: [3]
2025-08-22 00:57:54         strides: [2]
2025-08-22 00:57:54 net_type: resnet_50
2025-08-22 00:57:54 runner:
2025-08-22 00:57:54   type: PoseTrainingRunner
2025-08-22 00:57:54   gpus: None
2025-08-22 00:57:54   key_metric: test.mAP
2025-08-22 00:57:54   key_metric_asc: True
2025-08-22 00:57:54   eval_interval: 10
2025-08-22 00:57:54   optimizer:
2025-08-22 00:57:54     type: AdamW
2025-08-22 00:57:54     params:
2025-08-22 00:57:54       lr: 0.0001
2025-08-22 00:57:54   scheduler:
2025-08-22 00:57:54     type: LRListScheduler
2025-08-22 00:57:54     params:
2025-08-22 00:57:54       lr_list: [[1e-05], [1e-06]]
2025-08-22 00:57:54       milestones: [160, 190]
2025-08-22 00:57:54   snapshots:
2025-08-22 00:57:54     max_snapshots: 5
2025-08-22 00:57:54     save_epochs: 25
2025-08-22 00:57:54     save_optimizer_state: False
2025-08-22 00:57:54 train_settings:
2025-08-22 00:57:54   batch_size: 64
2025-08-22 00:57:54   dataloader_workers: 0
2025-08-22 00:57:54   dataloader_pin_memory: True
2025-08-22 00:57:54   display_iters: 500
2025-08-22 00:57:54   epochs: 200
2025-08-22 00:57:54   seed: 42
2025-08-22 00:57:54 init_weights: custom
2025-08-22 00:57:54 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 00:57:54 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 00:57:54 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 00:57:56 Data Transforms:
2025-08-22 00:57:56   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:57:56   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:57:57 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 00:57:57 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 00:57:57 Using 1127 images and 60 for testing
2025-08-22 00:57:57 
Starting pose model training...
--------------------------------------------------
2025-08-22 00:59:22 Training with configuration:
2025-08-22 00:59:22 data:
2025-08-22 00:59:22   colormode: RGB
2025-08-22 00:59:22   inference:
2025-08-22 00:59:22     normalize_images: True
2025-08-22 00:59:22   train:
2025-08-22 00:59:22     affine:
2025-08-22 00:59:22       p: 0.5
2025-08-22 00:59:22       rotation: 30
2025-08-22 00:59:22       scaling: [1.0, 1.0]
2025-08-22 00:59:22       translation: 0
2025-08-22 00:59:22     collate:
2025-08-22 00:59:22       type: ResizeFromDataSizeCollate
2025-08-22 00:59:22       min_scale: 0.4
2025-08-22 00:59:22       max_scale: 1.0
2025-08-22 00:59:22       min_short_side: 128
2025-08-22 00:59:22       max_short_side: 1152
2025-08-22 00:59:22       multiple_of: 32
2025-08-22 00:59:22       to_square: False
2025-08-22 00:59:22     covering: False
2025-08-22 00:59:22     gaussian_noise: 12.75
2025-08-22 00:59:22     hist_eq: False
2025-08-22 00:59:22     motion_blur: False
2025-08-22 00:59:22     normalize_images: True
2025-08-22 00:59:22 device: auto
2025-08-22 00:59:22 metadata:
2025-08-22 00:59:22   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 00:59:22   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 00:59:22   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 00:59:22   unique_bodyparts: []
2025-08-22 00:59:22   individuals: ['animal']
2025-08-22 00:59:22   with_identity: None
2025-08-22 00:59:22 method: bu
2025-08-22 00:59:22 model:
2025-08-22 00:59:22   backbone:
2025-08-22 00:59:22     type: ResNet
2025-08-22 00:59:22     model_name: resnet50_gn
2025-08-22 00:59:22     output_stride: 16
2025-08-22 00:59:22     freeze_bn_stats: True
2025-08-22 00:59:22     freeze_bn_weights: False
2025-08-22 00:59:22   backbone_output_channels: 2048
2025-08-22 00:59:22   heads:
2025-08-22 00:59:22     bodypart:
2025-08-22 00:59:22       type: HeatmapHead
2025-08-22 00:59:22       weight_init: normal
2025-08-22 00:59:22       predictor:
2025-08-22 00:59:22         type: HeatmapPredictor
2025-08-22 00:59:22         apply_sigmoid: False
2025-08-22 00:59:22         clip_scores: True
2025-08-22 00:59:22         location_refinement: True
2025-08-22 00:59:22         locref_std: 7.2801
2025-08-22 00:59:22       target_generator:
2025-08-22 00:59:22         type: HeatmapGaussianGenerator
2025-08-22 00:59:22         num_heatmaps: 9
2025-08-22 00:59:22         pos_dist_thresh: 17
2025-08-22 00:59:22         heatmap_mode: KEYPOINT
2025-08-22 00:59:22         generate_locref: True
2025-08-22 00:59:22         locref_std: 7.2801
2025-08-22 00:59:22       criterion:
2025-08-22 00:59:22         heatmap:
2025-08-22 00:59:22           type: WeightedMSECriterion
2025-08-22 00:59:22           weight: 1.0
2025-08-22 00:59:22         locref:
2025-08-22 00:59:22           type: WeightedHuberCriterion
2025-08-22 00:59:22           weight: 0.05
2025-08-22 00:59:22       heatmap_config:
2025-08-22 00:59:22         channels: [2048, 9]
2025-08-22 00:59:22         kernel_size: [3]
2025-08-22 00:59:22         strides: [2]
2025-08-22 00:59:22       locref_config:
2025-08-22 00:59:22         channels: [2048, 18]
2025-08-22 00:59:22         kernel_size: [3]
2025-08-22 00:59:22         strides: [2]
2025-08-22 00:59:22 net_type: resnet_50
2025-08-22 00:59:22 runner:
2025-08-22 00:59:22   type: PoseTrainingRunner
2025-08-22 00:59:22   gpus: None
2025-08-22 00:59:22   key_metric: test.mAP
2025-08-22 00:59:22   key_metric_asc: True
2025-08-22 00:59:22   eval_interval: 10
2025-08-22 00:59:22   optimizer:
2025-08-22 00:59:22     type: AdamW
2025-08-22 00:59:22     params:
2025-08-22 00:59:22       lr: 0.0001
2025-08-22 00:59:22   scheduler:
2025-08-22 00:59:22     type: LRListScheduler
2025-08-22 00:59:22     params:
2025-08-22 00:59:22       lr_list: [[1e-05], [1e-06]]
2025-08-22 00:59:22       milestones: [160, 190]
2025-08-22 00:59:22   snapshots:
2025-08-22 00:59:22     max_snapshots: 5
2025-08-22 00:59:22     save_epochs: 25
2025-08-22 00:59:22     save_optimizer_state: False
2025-08-22 00:59:22 train_settings:
2025-08-22 00:59:22   batch_size: 16
2025-08-22 00:59:22   dataloader_workers: 0
2025-08-22 00:59:22   dataloader_pin_memory: True
2025-08-22 00:59:22   display_iters: 500
2025-08-22 00:59:22   epochs: 200
2025-08-22 00:59:22   seed: 42
2025-08-22 00:59:22 init_weights: custom
2025-08-22 00:59:22 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 00:59:22 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 00:59:22 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 00:59:24 Data Transforms:
2025-08-22 00:59:24   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:59:24   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 00:59:26 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 00:59:26 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 00:59:26 Using 1127 images and 60 for testing
2025-08-22 00:59:26 
Starting pose model training...
--------------------------------------------------
2025-08-22 01:03:14 Training with configuration:
2025-08-22 01:03:14 data:
2025-08-22 01:03:14   colormode: RGB
2025-08-22 01:03:14   inference:
2025-08-22 01:03:14     normalize_images: True
2025-08-22 01:03:14   train:
2025-08-22 01:03:14     affine:
2025-08-22 01:03:14       p: 0.5
2025-08-22 01:03:14       rotation: 30
2025-08-22 01:03:14       scaling: [1.0, 1.0]
2025-08-22 01:03:14       translation: 0
2025-08-22 01:03:14     collate:
2025-08-22 01:03:14       type: ResizeFromDataSizeCollate
2025-08-22 01:03:14       min_scale: 0.4
2025-08-22 01:03:14       max_scale: 1.0
2025-08-22 01:03:14       min_short_side: 128
2025-08-22 01:03:14       max_short_side: 1152
2025-08-22 01:03:14       multiple_of: 32
2025-08-22 01:03:14       to_square: False
2025-08-22 01:03:14     covering: False
2025-08-22 01:03:14     gaussian_noise: 12.75
2025-08-22 01:03:14     hist_eq: False
2025-08-22 01:03:14     motion_blur: False
2025-08-22 01:03:14     normalize_images: True
2025-08-22 01:03:14 device: auto
2025-08-22 01:03:14 metadata:
2025-08-22 01:03:14   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 01:03:14   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 01:03:14   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 01:03:14   unique_bodyparts: []
2025-08-22 01:03:14   individuals: ['animal']
2025-08-22 01:03:14   with_identity: None
2025-08-22 01:03:14 method: bu
2025-08-22 01:03:14 model:
2025-08-22 01:03:14   backbone:
2025-08-22 01:03:14     type: ResNet
2025-08-22 01:03:14     model_name: resnet50_gn
2025-08-22 01:03:14     output_stride: 16
2025-08-22 01:03:14     freeze_bn_stats: True
2025-08-22 01:03:14     freeze_bn_weights: False
2025-08-22 01:03:14   backbone_output_channels: 2048
2025-08-22 01:03:14   heads:
2025-08-22 01:03:14     bodypart:
2025-08-22 01:03:14       type: HeatmapHead
2025-08-22 01:03:14       weight_init: normal
2025-08-22 01:03:14       predictor:
2025-08-22 01:03:14         type: HeatmapPredictor
2025-08-22 01:03:14         apply_sigmoid: False
2025-08-22 01:03:14         clip_scores: True
2025-08-22 01:03:14         location_refinement: True
2025-08-22 01:03:14         locref_std: 7.2801
2025-08-22 01:03:14       target_generator:
2025-08-22 01:03:14         type: HeatmapGaussianGenerator
2025-08-22 01:03:14         num_heatmaps: 9
2025-08-22 01:03:14         pos_dist_thresh: 17
2025-08-22 01:03:14         heatmap_mode: KEYPOINT
2025-08-22 01:03:14         generate_locref: True
2025-08-22 01:03:14         locref_std: 7.2801
2025-08-22 01:03:14       criterion:
2025-08-22 01:03:14         heatmap:
2025-08-22 01:03:14           type: WeightedMSECriterion
2025-08-22 01:03:14           weight: 1.0
2025-08-22 01:03:14         locref:
2025-08-22 01:03:14           type: WeightedHuberCriterion
2025-08-22 01:03:14           weight: 0.05
2025-08-22 01:03:14       heatmap_config:
2025-08-22 01:03:14         channels: [2048, 9]
2025-08-22 01:03:14         kernel_size: [3]
2025-08-22 01:03:14         strides: [2]
2025-08-22 01:03:14       locref_config:
2025-08-22 01:03:14         channels: [2048, 18]
2025-08-22 01:03:14         kernel_size: [3]
2025-08-22 01:03:14         strides: [2]
2025-08-22 01:03:14 net_type: resnet_50
2025-08-22 01:03:14 runner:
2025-08-22 01:03:14   type: PoseTrainingRunner
2025-08-22 01:03:14   gpus: None
2025-08-22 01:03:14   key_metric: test.mAP
2025-08-22 01:03:14   key_metric_asc: True
2025-08-22 01:03:14   eval_interval: 10
2025-08-22 01:03:14   optimizer:
2025-08-22 01:03:14     type: AdamW
2025-08-22 01:03:14     params:
2025-08-22 01:03:14       lr: 0.0001
2025-08-22 01:03:14   scheduler:
2025-08-22 01:03:14     type: LRListScheduler
2025-08-22 01:03:14     params:
2025-08-22 01:03:14       lr_list: [[1e-05], [1e-06]]
2025-08-22 01:03:14       milestones: [160, 190]
2025-08-22 01:03:14   snapshots:
2025-08-22 01:03:14     max_snapshots: 5
2025-08-22 01:03:14     save_epochs: 25
2025-08-22 01:03:14     save_optimizer_state: False
2025-08-22 01:03:14 train_settings:
2025-08-22 01:03:14   batch_size: 16
2025-08-22 01:03:14   dataloader_workers: 0
2025-08-22 01:03:14   dataloader_pin_memory: True
2025-08-22 01:03:14   display_iters: 500
2025-08-22 01:03:14   epochs: 200
2025-08-22 01:03:14   seed: 42
2025-08-22 01:03:14 init_weights: custom
2025-08-22 01:03:14 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/snapshots/snapshot-075.pt
2025-08-22 01:03:15 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 01:03:15 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 01:03:16 Data Transforms:
2025-08-22 01:03:16   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 01:03:16   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 01:03:18 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 01:03:18 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 01:03:18 Using 1127 images and 60 for testing
2025-08-22 01:03:18 
Starting pose model training...
--------------------------------------------------
2025-08-22 01:08:08 Epoch 1/200 (lr=0.0001), train loss 0.01209
2025-08-22 01:15:24 Training with configuration:
2025-08-22 01:15:24 data:
2025-08-22 01:15:24   colormode: RGB
2025-08-22 01:15:24   inference:
2025-08-22 01:15:24     normalize_images: True
2025-08-22 01:15:24   train:
2025-08-22 01:15:24     affine:
2025-08-22 01:15:24       p: 0.5
2025-08-22 01:15:24       rotation: 30
2025-08-22 01:15:24       scaling: [1.0, 1.0]
2025-08-22 01:15:24       translation: 0
2025-08-22 01:15:24     collate:
2025-08-22 01:15:24       type: ResizeFromDataSizeCollate
2025-08-22 01:15:24       min_scale: 0.4
2025-08-22 01:15:24       max_scale: 1.0
2025-08-22 01:15:24       min_short_side: 128
2025-08-22 01:15:24       max_short_side: 1152
2025-08-22 01:15:24       multiple_of: 32
2025-08-22 01:15:24       to_square: False
2025-08-22 01:15:24     covering: False
2025-08-22 01:15:24     gaussian_noise: 12.75
2025-08-22 01:15:24     hist_eq: False
2025-08-22 01:15:24     motion_blur: False
2025-08-22 01:15:24     normalize_images: True
2025-08-22 01:15:24 device: auto
2025-08-22 01:15:24 metadata:
2025-08-22 01:15:24   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 01:15:24   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 01:15:24   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 01:15:24   unique_bodyparts: []
2025-08-22 01:15:24   individuals: ['animal']
2025-08-22 01:15:24   with_identity: None
2025-08-22 01:15:24 method: bu
2025-08-22 01:15:24 model:
2025-08-22 01:15:24   backbone:
2025-08-22 01:15:24     type: ResNet
2025-08-22 01:15:24     model_name: resnet50_gn
2025-08-22 01:15:24     output_stride: 16
2025-08-22 01:15:24     freeze_bn_stats: True
2025-08-22 01:15:24     freeze_bn_weights: False
2025-08-22 01:15:24   backbone_output_channels: 2048
2025-08-22 01:15:24   heads:
2025-08-22 01:15:24     bodypart:
2025-08-22 01:15:24       type: HeatmapHead
2025-08-22 01:15:24       weight_init: normal
2025-08-22 01:15:24       predictor:
2025-08-22 01:15:24         type: HeatmapPredictor
2025-08-22 01:15:24         apply_sigmoid: False
2025-08-22 01:15:24         clip_scores: True
2025-08-22 01:15:24         location_refinement: True
2025-08-22 01:15:24         locref_std: 7.2801
2025-08-22 01:15:24       target_generator:
2025-08-22 01:15:24         type: HeatmapGaussianGenerator
2025-08-22 01:15:24         num_heatmaps: 9
2025-08-22 01:15:24         pos_dist_thresh: 17
2025-08-22 01:15:24         heatmap_mode: KEYPOINT
2025-08-22 01:15:24         generate_locref: True
2025-08-22 01:15:24         locref_std: 7.2801
2025-08-22 01:15:24       criterion:
2025-08-22 01:15:24         heatmap:
2025-08-22 01:15:24           type: WeightedMSECriterion
2025-08-22 01:15:24           weight: 1.0
2025-08-22 01:15:24         locref:
2025-08-22 01:15:24           type: WeightedHuberCriterion
2025-08-22 01:15:24           weight: 0.05
2025-08-22 01:15:24       heatmap_config:
2025-08-22 01:15:24         channels: [2048, 9]
2025-08-22 01:15:24         kernel_size: [3]
2025-08-22 01:15:24         strides: [2]
2025-08-22 01:15:24       locref_config:
2025-08-22 01:15:24         channels: [2048, 18]
2025-08-22 01:15:24         kernel_size: [3]
2025-08-22 01:15:24         strides: [2]
2025-08-22 01:15:24 net_type: resnet_50
2025-08-22 01:15:24 runner:
2025-08-22 01:15:24   type: PoseTrainingRunner
2025-08-22 01:15:24   gpus: None
2025-08-22 01:15:24   key_metric: test.mAP
2025-08-22 01:15:24   key_metric_asc: True
2025-08-22 01:15:24   eval_interval: 10
2025-08-22 01:15:24   optimizer:
2025-08-22 01:15:24     type: AdamW
2025-08-22 01:15:24     params:
2025-08-22 01:15:24       lr: 0.0001
2025-08-22 01:15:24   scheduler:
2025-08-22 01:15:24     type: LRListScheduler
2025-08-22 01:15:24     params:
2025-08-22 01:15:24       lr_list: [[1e-05], [1e-06]]
2025-08-22 01:15:24       milestones: [160, 190]
2025-08-22 01:15:24   snapshots:
2025-08-22 01:15:24     max_snapshots: 5
2025-08-22 01:15:24     save_epochs: 25
2025-08-22 01:15:24     save_optimizer_state: False
2025-08-22 01:15:24 train_settings:
2025-08-22 01:15:24   batch_size: 64
2025-08-22 01:15:24   dataloader_workers: 0
2025-08-22 01:15:24   dataloader_pin_memory: True
2025-08-22 01:15:24   display_iters: 500
2025-08-22 01:15:24   epochs: 200
2025-08-22 01:15:24   seed: 42
2025-08-22 01:15:24 init_weights: custom
2025-08-22 01:15:24 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 01:15:24 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 01:15:24 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 01:15:26 Data Transforms:
2025-08-22 01:15:26   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 01:15:26   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 01:15:29 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 01:15:29 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 01:15:29 Using 1127 images and 60 for testing
2025-08-22 01:15:29 
Starting pose model training...
--------------------------------------------------
2025-08-22 01:18:40 Training with configuration:
2025-08-22 01:18:40 data:
2025-08-22 01:18:40   colormode: RGB
2025-08-22 01:18:40   inference:
2025-08-22 01:18:40     normalize_images: True
2025-08-22 01:18:40   train:
2025-08-22 01:18:40     affine:
2025-08-22 01:18:40       p: 0.5
2025-08-22 01:18:40       rotation: 30
2025-08-22 01:18:40       scaling: [1.0, 1.0]
2025-08-22 01:18:40       translation: 0
2025-08-22 01:18:40     collate:
2025-08-22 01:18:40       type: ResizeFromDataSizeCollate
2025-08-22 01:18:40       min_scale: 0.4
2025-08-22 01:18:40       max_scale: 1.0
2025-08-22 01:18:40       min_short_side: 128
2025-08-22 01:18:40       max_short_side: 1152
2025-08-22 01:18:40       multiple_of: 32
2025-08-22 01:18:40       to_square: False
2025-08-22 01:18:40     covering: False
2025-08-22 01:18:40     gaussian_noise: 12.75
2025-08-22 01:18:40     hist_eq: False
2025-08-22 01:18:40     motion_blur: False
2025-08-22 01:18:40     normalize_images: True
2025-08-22 01:18:40 device: auto
2025-08-22 01:18:40 metadata:
2025-08-22 01:18:40   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 01:18:40   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 01:18:40   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 01:18:40   unique_bodyparts: []
2025-08-22 01:18:40   individuals: ['animal']
2025-08-22 01:18:40   with_identity: None
2025-08-22 01:18:40 method: bu
2025-08-22 01:18:40 model:
2025-08-22 01:18:40   backbone:
2025-08-22 01:18:40     type: ResNet
2025-08-22 01:18:40     model_name: resnet50_gn
2025-08-22 01:18:40     output_stride: 16
2025-08-22 01:18:40     freeze_bn_stats: True
2025-08-22 01:18:40     freeze_bn_weights: False
2025-08-22 01:18:40   backbone_output_channels: 2048
2025-08-22 01:18:40   heads:
2025-08-22 01:18:40     bodypart:
2025-08-22 01:18:40       type: HeatmapHead
2025-08-22 01:18:40       weight_init: normal
2025-08-22 01:18:40       predictor:
2025-08-22 01:18:40         type: HeatmapPredictor
2025-08-22 01:18:40         apply_sigmoid: False
2025-08-22 01:18:40         clip_scores: True
2025-08-22 01:18:40         location_refinement: True
2025-08-22 01:18:40         locref_std: 7.2801
2025-08-22 01:18:40       target_generator:
2025-08-22 01:18:40         type: HeatmapGaussianGenerator
2025-08-22 01:18:40         num_heatmaps: 9
2025-08-22 01:18:40         pos_dist_thresh: 17
2025-08-22 01:18:40         heatmap_mode: KEYPOINT
2025-08-22 01:18:40         generate_locref: True
2025-08-22 01:18:40         locref_std: 7.2801
2025-08-22 01:18:40       criterion:
2025-08-22 01:18:40         heatmap:
2025-08-22 01:18:40           type: WeightedMSECriterion
2025-08-22 01:18:40           weight: 1.0
2025-08-22 01:18:40         locref:
2025-08-22 01:18:40           type: WeightedHuberCriterion
2025-08-22 01:18:40           weight: 0.05
2025-08-22 01:18:40       heatmap_config:
2025-08-22 01:18:40         channels: [2048, 9]
2025-08-22 01:18:40         kernel_size: [3]
2025-08-22 01:18:40         strides: [2]
2025-08-22 01:18:40       locref_config:
2025-08-22 01:18:40         channels: [2048, 18]
2025-08-22 01:18:40         kernel_size: [3]
2025-08-22 01:18:40         strides: [2]
2025-08-22 01:18:40 net_type: resnet_50
2025-08-22 01:18:40 runner:
2025-08-22 01:18:40   type: PoseTrainingRunner
2025-08-22 01:18:40   gpus: None
2025-08-22 01:18:40   key_metric: test.mAP
2025-08-22 01:18:40   key_metric_asc: True
2025-08-22 01:18:40   eval_interval: 10
2025-08-22 01:18:40   optimizer:
2025-08-22 01:18:40     type: AdamW
2025-08-22 01:18:40     params:
2025-08-22 01:18:40       lr: 0.0001
2025-08-22 01:18:40   scheduler:
2025-08-22 01:18:40     type: LRListScheduler
2025-08-22 01:18:40     params:
2025-08-22 01:18:40       lr_list: [[1e-05], [1e-06]]
2025-08-22 01:18:40       milestones: [160, 190]
2025-08-22 01:18:40   snapshots:
2025-08-22 01:18:40     max_snapshots: 5
2025-08-22 01:18:40     save_epochs: 25
2025-08-22 01:18:40     save_optimizer_state: False
2025-08-22 01:18:40 train_settings:
2025-08-22 01:18:40   batch_size: 64
2025-08-22 01:18:40   dataloader_workers: 0
2025-08-22 01:18:40   dataloader_pin_memory: True
2025-08-22 01:18:40   display_iters: 500
2025-08-22 01:18:40   epochs: 200
2025-08-22 01:18:40   seed: 42
2025-08-22 01:18:40 init_weights: custom
2025-08-22 01:18:40 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 01:18:40 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 01:18:40 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 01:18:42 Data Transforms:
2025-08-22 01:18:42   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 01:18:42   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 01:18:43 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 01:18:43 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 01:18:43 Using 1127 images and 60 for testing
2025-08-22 01:18:43 
Starting pose model training...
--------------------------------------------------
2025-08-22 01:20:37 Training with configuration:
2025-08-22 01:20:37 data:
2025-08-22 01:20:37   colormode: RGB
2025-08-22 01:20:37   inference:
2025-08-22 01:20:37     normalize_images: True
2025-08-22 01:20:37   train:
2025-08-22 01:20:37     affine:
2025-08-22 01:20:37       p: 0.5
2025-08-22 01:20:37       rotation: 30
2025-08-22 01:20:37       scaling: [1.0, 1.0]
2025-08-22 01:20:37       translation: 0
2025-08-22 01:20:37     collate:
2025-08-22 01:20:37       type: ResizeFromDataSizeCollate
2025-08-22 01:20:37       min_scale: 0.4
2025-08-22 01:20:37       max_scale: 1.0
2025-08-22 01:20:37       min_short_side: 128
2025-08-22 01:20:37       max_short_side: 1152
2025-08-22 01:20:37       multiple_of: 32
2025-08-22 01:20:37       to_square: False
2025-08-22 01:20:37     covering: False
2025-08-22 01:20:37     gaussian_noise: 12.75
2025-08-22 01:20:37     hist_eq: False
2025-08-22 01:20:37     motion_blur: False
2025-08-22 01:20:37     normalize_images: True
2025-08-22 01:20:37 device: auto
2025-08-22 01:20:37 metadata:
2025-08-22 01:20:37   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 01:20:37   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 01:20:37   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 01:20:37   unique_bodyparts: []
2025-08-22 01:20:37   individuals: ['animal']
2025-08-22 01:20:37   with_identity: None
2025-08-22 01:20:37 method: bu
2025-08-22 01:20:37 model:
2025-08-22 01:20:37   backbone:
2025-08-22 01:20:37     type: ResNet
2025-08-22 01:20:37     model_name: resnet50_gn
2025-08-22 01:20:37     output_stride: 16
2025-08-22 01:20:37     freeze_bn_stats: True
2025-08-22 01:20:37     freeze_bn_weights: False
2025-08-22 01:20:37   backbone_output_channels: 2048
2025-08-22 01:20:37   heads:
2025-08-22 01:20:37     bodypart:
2025-08-22 01:20:37       type: HeatmapHead
2025-08-22 01:20:37       weight_init: normal
2025-08-22 01:20:37       predictor:
2025-08-22 01:20:37         type: HeatmapPredictor
2025-08-22 01:20:37         apply_sigmoid: False
2025-08-22 01:20:37         clip_scores: True
2025-08-22 01:20:37         location_refinement: True
2025-08-22 01:20:37         locref_std: 7.2801
2025-08-22 01:20:37       target_generator:
2025-08-22 01:20:37         type: HeatmapGaussianGenerator
2025-08-22 01:20:37         num_heatmaps: 9
2025-08-22 01:20:37         pos_dist_thresh: 17
2025-08-22 01:20:37         heatmap_mode: KEYPOINT
2025-08-22 01:20:37         generate_locref: True
2025-08-22 01:20:37         locref_std: 7.2801
2025-08-22 01:20:37       criterion:
2025-08-22 01:20:37         heatmap:
2025-08-22 01:20:37           type: WeightedMSECriterion
2025-08-22 01:20:37           weight: 1.0
2025-08-22 01:20:37         locref:
2025-08-22 01:20:37           type: WeightedHuberCriterion
2025-08-22 01:20:37           weight: 0.05
2025-08-22 01:20:37       heatmap_config:
2025-08-22 01:20:37         channels: [2048, 9]
2025-08-22 01:20:37         kernel_size: [3]
2025-08-22 01:20:37         strides: [2]
2025-08-22 01:20:37       locref_config:
2025-08-22 01:20:37         channels: [2048, 18]
2025-08-22 01:20:37         kernel_size: [3]
2025-08-22 01:20:37         strides: [2]
2025-08-22 01:20:37 net_type: resnet_50
2025-08-22 01:20:37 runner:
2025-08-22 01:20:37   type: PoseTrainingRunner
2025-08-22 01:20:37   gpus: None
2025-08-22 01:20:37   key_metric: test.mAP
2025-08-22 01:20:37   key_metric_asc: True
2025-08-22 01:20:37   eval_interval: 10
2025-08-22 01:20:37   optimizer:
2025-08-22 01:20:37     type: AdamW
2025-08-22 01:20:37     params:
2025-08-22 01:20:37       lr: 0.0001
2025-08-22 01:20:37   scheduler:
2025-08-22 01:20:37     type: LRListScheduler
2025-08-22 01:20:37     params:
2025-08-22 01:20:37       lr_list: [[1e-05], [1e-06]]
2025-08-22 01:20:37       milestones: [160, 190]
2025-08-22 01:20:37   snapshots:
2025-08-22 01:20:37     max_snapshots: 5
2025-08-22 01:20:37     save_epochs: 25
2025-08-22 01:20:37     save_optimizer_state: False
2025-08-22 01:20:37 train_settings:
2025-08-22 01:20:37   batch_size: 32
2025-08-22 01:20:37   dataloader_workers: 0
2025-08-22 01:20:37   dataloader_pin_memory: True
2025-08-22 01:20:37   display_iters: 500
2025-08-22 01:20:37   epochs: 200
2025-08-22 01:20:37   seed: 42
2025-08-22 01:20:37 init_weights: custom
2025-08-22 01:20:37 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 01:20:37 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 01:20:37 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 01:20:39 Data Transforms:
2025-08-22 01:20:39   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 01:20:39   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 01:20:40 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 01:20:40 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 01:20:40 Using 1127 images and 60 for testing
2025-08-22 01:20:40 
Starting pose model training...
--------------------------------------------------
2025-08-22 01:22:08 Training with configuration:
2025-08-22 01:22:08 data:
2025-08-22 01:22:08   colormode: RGB
2025-08-22 01:22:08   inference:
2025-08-22 01:22:08     normalize_images: True
2025-08-22 01:22:08   train:
2025-08-22 01:22:08     affine:
2025-08-22 01:22:08       p: 0.5
2025-08-22 01:22:08       rotation: 30
2025-08-22 01:22:08       scaling: [1.0, 1.0]
2025-08-22 01:22:08       translation: 0
2025-08-22 01:22:08     collate:
2025-08-22 01:22:08       type: ResizeFromDataSizeCollate
2025-08-22 01:22:08       min_scale: 0.4
2025-08-22 01:22:08       max_scale: 1.0
2025-08-22 01:22:08       min_short_side: 128
2025-08-22 01:22:08       max_short_side: 1152
2025-08-22 01:22:08       multiple_of: 32
2025-08-22 01:22:08       to_square: False
2025-08-22 01:22:08     covering: False
2025-08-22 01:22:08     gaussian_noise: 12.75
2025-08-22 01:22:08     hist_eq: False
2025-08-22 01:22:08     motion_blur: False
2025-08-22 01:22:08     normalize_images: True
2025-08-22 01:22:08 device: auto
2025-08-22 01:22:08 metadata:
2025-08-22 01:22:08   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-22 01:22:08   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-22 01:22:08   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-22 01:22:08   unique_bodyparts: []
2025-08-22 01:22:08   individuals: ['animal']
2025-08-22 01:22:08   with_identity: None
2025-08-22 01:22:08 method: bu
2025-08-22 01:22:08 model:
2025-08-22 01:22:08   backbone:
2025-08-22 01:22:08     type: ResNet
2025-08-22 01:22:08     model_name: resnet50_gn
2025-08-22 01:22:08     output_stride: 16
2025-08-22 01:22:08     freeze_bn_stats: True
2025-08-22 01:22:08     freeze_bn_weights: False
2025-08-22 01:22:08   backbone_output_channels: 2048
2025-08-22 01:22:08   heads:
2025-08-22 01:22:08     bodypart:
2025-08-22 01:22:08       type: HeatmapHead
2025-08-22 01:22:08       weight_init: normal
2025-08-22 01:22:08       predictor:
2025-08-22 01:22:08         type: HeatmapPredictor
2025-08-22 01:22:08         apply_sigmoid: False
2025-08-22 01:22:08         clip_scores: True
2025-08-22 01:22:08         location_refinement: True
2025-08-22 01:22:08         locref_std: 7.2801
2025-08-22 01:22:08       target_generator:
2025-08-22 01:22:08         type: HeatmapGaussianGenerator
2025-08-22 01:22:08         num_heatmaps: 9
2025-08-22 01:22:08         pos_dist_thresh: 17
2025-08-22 01:22:08         heatmap_mode: KEYPOINT
2025-08-22 01:22:08         generate_locref: True
2025-08-22 01:22:08         locref_std: 7.2801
2025-08-22 01:22:08       criterion:
2025-08-22 01:22:08         heatmap:
2025-08-22 01:22:08           type: WeightedMSECriterion
2025-08-22 01:22:08           weight: 1.0
2025-08-22 01:22:08         locref:
2025-08-22 01:22:08           type: WeightedHuberCriterion
2025-08-22 01:22:08           weight: 0.05
2025-08-22 01:22:08       heatmap_config:
2025-08-22 01:22:08         channels: [2048, 9]
2025-08-22 01:22:08         kernel_size: [3]
2025-08-22 01:22:08         strides: [2]
2025-08-22 01:22:08       locref_config:
2025-08-22 01:22:08         channels: [2048, 18]
2025-08-22 01:22:08         kernel_size: [3]
2025-08-22 01:22:08         strides: [2]
2025-08-22 01:22:08 net_type: resnet_50
2025-08-22 01:22:08 runner:
2025-08-22 01:22:08   type: PoseTrainingRunner
2025-08-22 01:22:08   gpus: None
2025-08-22 01:22:08   key_metric: test.mAP
2025-08-22 01:22:08   key_metric_asc: True
2025-08-22 01:22:08   eval_interval: 10
2025-08-22 01:22:08   optimizer:
2025-08-22 01:22:08     type: AdamW
2025-08-22 01:22:08     params:
2025-08-22 01:22:08       lr: 0.0001
2025-08-22 01:22:08   scheduler:
2025-08-22 01:22:08     type: LRListScheduler
2025-08-22 01:22:08     params:
2025-08-22 01:22:08       lr_list: [[1e-05], [1e-06]]
2025-08-22 01:22:08       milestones: [160, 190]
2025-08-22 01:22:08   snapshots:
2025-08-22 01:22:08     max_snapshots: 5
2025-08-22 01:22:08     save_epochs: 25
2025-08-22 01:22:08     save_optimizer_state: False
2025-08-22 01:22:08 train_settings:
2025-08-22 01:22:08   batch_size: 16
2025-08-22 01:22:08   dataloader_workers: 0
2025-08-22 01:22:08   dataloader_pin_memory: True
2025-08-22 01:22:08   display_iters: 500
2025-08-22 01:22:08   epochs: 200
2025-08-22 01:22:08   seed: 42
2025-08-22 01:22:08 init_weights: custom
2025-08-22 01:22:08 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle1/snapshots/snapshot-200.pt
2025-08-22 01:22:08 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-22 01:22:08 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-22 01:22:10 Data Transforms:
2025-08-22 01:22:10   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 01:22:10   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-22 01:22:12 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-22 01:22:12 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-22 01:22:12 Using 1127 images and 60 for testing
2025-08-22 01:22:12 
Starting pose model training...
--------------------------------------------------
2025-08-22 01:27:20 Epoch 1/200 (lr=0.0001), train loss 0.01209
2025-08-22 01:32:31 Epoch 2/200 (lr=0.0001), train loss 0.00654
2025-08-22 01:37:42 Epoch 3/200 (lr=0.0001), train loss 0.00518
2025-08-22 01:42:54 Epoch 4/200 (lr=0.0001), train loss 0.00433
2025-08-22 01:48:12 Epoch 5/200 (lr=0.0001), train loss 0.00385
2025-08-22 01:53:25 Epoch 6/200 (lr=0.0001), train loss 0.00360
2025-08-22 01:58:37 Epoch 7/200 (lr=0.0001), train loss 0.00323
2025-08-22 02:03:48 Epoch 8/200 (lr=0.0001), train loss 0.00310
2025-08-22 02:08:37 Epoch 9/200 (lr=0.0001), train loss 0.00300
2025-08-22 02:13:35 Training for epoch 10 done, starting evaluation
2025-08-22 02:13:45 Epoch 10 performance:
2025-08-22 02:13:45 metrics/test.rmse:  29.144
2025-08-22 02:13:45 metrics/test.rmse_pcutoff:4.242
2025-08-22 02:13:45 metrics/test.mAP:   71.958
2025-08-22 02:13:45 metrics/test.mAR:   78.833
2025-08-22 02:13:45 metrics/test.rmse_detections:29.144
2025-08-22 02:13:45 metrics/test.rmse_detections_pcutoff:4.242
2025-08-22 02:13:45 Epoch 10/200 (lr=0.0001), train loss 0.00285, valid loss 0.00389
2025-08-22 02:18:54 Epoch 11/200 (lr=0.0001), train loss 0.00270
2025-08-22 02:23:49 Epoch 12/200 (lr=0.0001), train loss 0.00259
2025-08-22 02:29:05 Epoch 13/200 (lr=0.0001), train loss 0.00245
2025-08-22 02:34:07 Epoch 14/200 (lr=0.0001), train loss 0.00237
2025-08-22 02:39:10 Epoch 15/200 (lr=0.0001), train loss 0.00229
2025-08-22 02:44:09 Epoch 16/200 (lr=0.0001), train loss 0.00229
2025-08-22 02:49:04 Epoch 17/200 (lr=0.0001), train loss 0.00223
2025-08-22 02:54:02 Epoch 18/200 (lr=0.0001), train loss 0.00209
2025-08-22 02:59:20 Epoch 19/200 (lr=0.0001), train loss 0.00206
2025-08-22 03:04:30 Training for epoch 20 done, starting evaluation
2025-08-22 03:04:39 Epoch 20 performance:
2025-08-22 03:04:39 metrics/test.rmse:  15.962
2025-08-22 03:04:39 metrics/test.rmse_pcutoff:4.767
2025-08-22 03:04:39 metrics/test.mAP:   84.332
2025-08-22 03:04:39 metrics/test.mAR:   89.000
2025-08-22 03:04:39 metrics/test.rmse_detections:15.962
2025-08-22 03:04:39 metrics/test.rmse_detections_pcutoff:4.767
2025-08-22 03:04:39 Epoch 20/200 (lr=0.0001), train loss 0.00209, valid loss 0.00348
2025-08-22 03:09:23 Epoch 21/200 (lr=0.0001), train loss 0.00201
2025-08-22 03:14:16 Epoch 22/200 (lr=0.0001), train loss 0.00201
2025-08-22 03:19:11 Epoch 23/200 (lr=0.0001), train loss 0.00186
2025-08-22 03:24:10 Epoch 24/200 (lr=0.0001), train loss 0.00182
2025-08-22 03:29:17 Epoch 25/200 (lr=0.0001), train loss 0.00182
2025-08-22 03:33:55 Epoch 26/200 (lr=0.0001), train loss 0.00171
2025-08-22 03:38:51 Epoch 27/200 (lr=0.0001), train loss 0.00167
2025-08-22 03:43:50 Epoch 28/200 (lr=0.0001), train loss 0.00164
2025-08-22 03:48:50 Epoch 29/200 (lr=0.0001), train loss 0.00164
2025-08-22 03:53:43 Training for epoch 30 done, starting evaluation
2025-08-22 03:53:52 Epoch 30 performance:
2025-08-22 03:53:52 metrics/test.rmse:  15.576
2025-08-22 03:53:52 metrics/test.rmse_pcutoff:5.125
2025-08-22 03:53:52 metrics/test.mAP:   85.680
2025-08-22 03:53:52 metrics/test.mAR:   88.833
2025-08-22 03:53:52 metrics/test.rmse_detections:15.576
2025-08-22 03:53:52 metrics/test.rmse_detections_pcutoff:5.125
2025-08-22 03:53:52 Epoch 30/200 (lr=0.0001), train loss 0.00157, valid loss 0.00338
2025-08-22 03:58:51 Epoch 31/200 (lr=0.0001), train loss 0.00156
2025-08-22 04:03:30 Epoch 32/200 (lr=0.0001), train loss 0.00148
2025-08-22 04:08:12 Epoch 33/200 (lr=0.0001), train loss 0.00146
2025-08-22 04:13:18 Epoch 34/200 (lr=0.0001), train loss 0.00151
2025-08-22 04:18:07 Epoch 35/200 (lr=0.0001), train loss 0.00146
2025-08-22 04:22:57 Epoch 36/200 (lr=0.0001), train loss 0.00149
2025-08-22 04:27:39 Epoch 37/200 (lr=0.0001), train loss 0.00136
2025-08-22 04:32:14 Epoch 38/200 (lr=0.0001), train loss 0.00135
2025-08-22 04:36:53 Epoch 39/200 (lr=0.0001), train loss 0.00131
2025-08-22 04:41:39 Training for epoch 40 done, starting evaluation
2025-08-22 04:41:47 Epoch 40 performance:
2025-08-22 04:41:47 metrics/test.rmse:  12.811
2025-08-22 04:41:47 metrics/test.rmse_pcutoff:5.803
2025-08-22 04:41:47 metrics/test.mAP:   90.010
2025-08-22 04:41:47 metrics/test.mAR:   92.333
2025-08-22 04:41:47 metrics/test.rmse_detections:12.811
2025-08-22 04:41:47 metrics/test.rmse_detections_pcutoff:5.803
2025-08-22 04:41:47 Epoch 40/200 (lr=0.0001), train loss 0.00135, valid loss 0.00316
2025-08-22 04:46:46 Epoch 41/200 (lr=0.0001), train loss 0.00134
2025-08-22 04:52:07 Epoch 42/200 (lr=0.0001), train loss 0.00129
2025-08-22 04:57:20 Epoch 43/200 (lr=0.0001), train loss 0.00125
2025-08-22 05:02:14 Epoch 44/200 (lr=0.0001), train loss 0.00120
2025-08-22 05:06:57 Epoch 45/200 (lr=0.0001), train loss 0.00124
2025-08-22 05:11:52 Epoch 46/200 (lr=0.0001), train loss 0.00122
2025-08-22 05:16:35 Epoch 47/200 (lr=0.0001), train loss 0.00125
2025-08-22 05:21:29 Epoch 48/200 (lr=0.0001), train loss 0.00125
2025-08-22 05:26:27 Epoch 49/200 (lr=0.0001), train loss 0.00119
2025-08-22 05:31:19 Training for epoch 50 done, starting evaluation
2025-08-22 05:31:27 Epoch 50 performance:
2025-08-22 05:31:27 metrics/test.rmse:  11.947
2025-08-22 05:31:27 metrics/test.rmse_pcutoff:4.887
2025-08-22 05:31:27 metrics/test.mAP:   91.284
2025-08-22 05:31:27 metrics/test.mAR:   93.333
2025-08-22 05:31:27 metrics/test.rmse_detections:11.947
2025-08-22 05:31:27 metrics/test.rmse_detections_pcutoff:4.887
2025-08-22 05:31:27 Epoch 50/200 (lr=0.0001), train loss 0.00122, valid loss 0.00311
2025-08-22 05:36:09 Epoch 51/200 (lr=0.0001), train loss 0.00112
2025-08-22 05:40:39 Epoch 52/200 (lr=0.0001), train loss 0.00106
2025-08-22 05:45:24 Epoch 53/200 (lr=0.0001), train loss 0.00108
2025-08-22 05:50:32 Epoch 54/200 (lr=0.0001), train loss 0.00106
2025-08-22 05:55:44 Epoch 55/200 (lr=0.0001), train loss 0.00109
2025-08-22 06:00:59 Epoch 56/200 (lr=0.0001), train loss 0.00103
2025-08-22 06:05:54 Epoch 57/200 (lr=0.0001), train loss 0.00106
2025-08-22 06:10:34 Epoch 58/200 (lr=0.0001), train loss 0.00101
2025-08-22 06:15:22 Epoch 59/200 (lr=0.0001), train loss 0.00103
2025-08-22 06:19:59 Training for epoch 60 done, starting evaluation
2025-08-22 06:20:07 Epoch 60 performance:
2025-08-22 06:20:07 metrics/test.rmse:  9.681
2025-08-22 06:20:07 metrics/test.rmse_pcutoff:4.271
2025-08-22 06:20:07 metrics/test.mAP:   93.315
2025-08-22 06:20:07 metrics/test.mAR:   94.833
2025-08-22 06:20:07 metrics/test.rmse_detections:9.681
2025-08-22 06:20:07 metrics/test.rmse_detections_pcutoff:4.271
2025-08-22 06:20:07 Epoch 60/200 (lr=0.0001), train loss 0.00100, valid loss 0.00328
2025-08-22 06:24:49 Epoch 61/200 (lr=0.0001), train loss 0.00108
2025-08-22 06:29:56 Epoch 62/200 (lr=0.0001), train loss 0.00102
2025-08-22 06:34:42 Epoch 63/200 (lr=0.0001), train loss 0.00097
2025-08-22 06:39:54 Epoch 64/200 (lr=0.0001), train loss 0.00099
2025-08-22 06:44:47 Epoch 65/200 (lr=0.0001), train loss 0.00099
2025-08-22 06:49:35 Epoch 66/200 (lr=0.0001), train loss 0.00091
2025-08-22 06:54:39 Epoch 67/200 (lr=0.0001), train loss 0.00092
2025-08-22 07:00:07 Epoch 68/200 (lr=0.0001), train loss 0.00093
2025-08-22 07:05:26 Epoch 69/200 (lr=0.0001), train loss 0.00093
2025-08-22 07:10:33 Training for epoch 70 done, starting evaluation
2025-08-22 07:10:42 Epoch 70 performance:
2025-08-22 07:10:42 metrics/test.rmse:  9.941
2025-08-22 07:10:42 metrics/test.rmse_pcutoff:4.731
2025-08-22 07:10:42 metrics/test.mAP:   92.167
2025-08-22 07:10:42 metrics/test.mAR:   94.167
2025-08-22 07:10:42 metrics/test.rmse_detections:9.941
2025-08-22 07:10:42 metrics/test.rmse_detections_pcutoff:4.731
2025-08-22 07:10:42 Epoch 70/200 (lr=0.0001), train loss 0.00095, valid loss 0.00316
2025-08-22 07:15:51 Epoch 71/200 (lr=0.0001), train loss 0.00090
2025-08-22 07:21:11 Epoch 72/200 (lr=0.0001), train loss 0.00086
2025-08-22 07:26:55 Epoch 73/200 (lr=0.0001), train loss 0.00085
2025-08-22 07:31:58 Epoch 74/200 (lr=0.0001), train loss 0.00086
2025-08-22 07:36:48 Epoch 75/200 (lr=0.0001), train loss 0.00087
2025-08-22 07:41:37 Epoch 76/200 (lr=0.0001), train loss 0.00083
2025-08-22 07:46:58 Epoch 77/200 (lr=0.0001), train loss 0.00084
2025-08-22 07:52:09 Epoch 78/200 (lr=0.0001), train loss 0.00087
2025-08-22 07:57:17 Epoch 79/200 (lr=0.0001), train loss 0.00082
2025-08-22 08:02:07 Training for epoch 80 done, starting evaluation
2025-08-22 08:02:16 Epoch 80 performance:
2025-08-22 08:02:16 metrics/test.rmse:  8.544
2025-08-22 08:02:16 metrics/test.rmse_pcutoff:5.365
2025-08-22 08:02:16 metrics/test.mAP:   94.364
2025-08-22 08:02:16 metrics/test.mAR:   95.667
2025-08-22 08:02:16 metrics/test.rmse_detections:8.544
2025-08-22 08:02:16 metrics/test.rmse_detections_pcutoff:5.365
2025-08-22 08:02:16 Epoch 80/200 (lr=0.0001), train loss 0.00086, valid loss 0.00315
2025-08-22 08:07:20 Epoch 81/200 (lr=0.0001), train loss 0.00074
2025-08-22 08:12:10 Epoch 82/200 (lr=0.0001), train loss 0.00076
2025-08-22 08:17:31 Epoch 83/200 (lr=0.0001), train loss 0.00076
2025-08-22 08:22:47 Epoch 84/200 (lr=0.0001), train loss 0.00079
2025-08-22 08:27:47 Epoch 85/200 (lr=0.0001), train loss 0.00079
2025-08-22 08:32:51 Epoch 86/200 (lr=0.0001), train loss 0.00082
2025-08-22 08:37:48 Epoch 87/200 (lr=0.0001), train loss 0.00078
2025-08-22 08:43:06 Epoch 88/200 (lr=0.0001), train loss 0.00076
2025-08-22 08:47:56 Epoch 89/200 (lr=0.0001), train loss 0.00077
2025-08-22 08:53:27 Training for epoch 90 done, starting evaluation
2025-08-22 08:53:36 Epoch 90 performance:
2025-08-22 08:53:36 metrics/test.rmse:  10.198
2025-08-22 08:53:36 metrics/test.rmse_pcutoff:4.446
2025-08-22 08:53:36 metrics/test.mAP:   93.140
2025-08-22 08:53:36 metrics/test.mAR:   95.333
2025-08-22 08:53:36 metrics/test.rmse_detections:10.198
2025-08-22 08:53:36 metrics/test.rmse_detections_pcutoff:4.446
2025-08-22 08:53:36 Epoch 90/200 (lr=0.0001), train loss 0.00073, valid loss 0.00315
2025-08-22 08:58:31 Epoch 91/200 (lr=0.0001), train loss 0.00075
2025-08-22 09:03:37 Epoch 92/200 (lr=0.0001), train loss 0.00070
2025-08-22 09:08:36 Epoch 93/200 (lr=0.0001), train loss 0.00070
2025-08-22 09:13:30 Epoch 94/200 (lr=0.0001), train loss 0.00071
2025-08-22 09:18:39 Epoch 95/200 (lr=0.0001), train loss 0.00073
2025-08-22 09:23:59 Epoch 96/200 (lr=0.0001), train loss 0.00073
2025-08-22 09:29:00 Epoch 97/200 (lr=0.0001), train loss 0.00067
2025-08-22 09:34:06 Epoch 98/200 (lr=0.0001), train loss 0.00067
2025-08-22 09:39:02 Epoch 99/200 (lr=0.0001), train loss 0.00071
2025-08-22 09:43:48 Training for epoch 100 done, starting evaluation
2025-08-22 09:43:56 Epoch 100 performance:
2025-08-22 09:43:56 metrics/test.rmse:  9.175
2025-08-22 09:43:56 metrics/test.rmse_pcutoff:5.149
2025-08-22 09:43:56 metrics/test.mAP:   92.700
2025-08-22 09:43:56 metrics/test.mAR:   94.667
2025-08-22 09:43:56 metrics/test.rmse_detections:9.175
2025-08-22 09:43:56 metrics/test.rmse_detections_pcutoff:5.149
2025-08-22 09:43:56 Epoch 100/200 (lr=0.0001), train loss 0.00069, valid loss 0.00321
2025-08-22 09:48:49 Epoch 101/200 (lr=0.0001), train loss 0.00070
2025-08-22 09:54:40 Epoch 102/200 (lr=0.0001), train loss 0.00067
2025-08-22 10:00:03 Epoch 103/200 (lr=0.0001), train loss 0.00066
2025-08-22 10:05:12 Epoch 104/200 (lr=0.0001), train loss 0.00069
2025-08-22 10:09:46 Epoch 105/200 (lr=0.0001), train loss 0.00069
2025-08-22 10:15:09 Epoch 106/200 (lr=0.0001), train loss 0.00068
2025-08-22 10:20:32 Epoch 107/200 (lr=0.0001), train loss 0.00069
2025-08-22 10:25:57 Epoch 108/200 (lr=0.0001), train loss 0.00065
2025-08-22 10:31:12 Epoch 109/200 (lr=0.0001), train loss 0.00064
2025-08-22 10:36:05 Training for epoch 110 done, starting evaluation
2025-08-22 10:36:13 Epoch 110 performance:
2025-08-22 10:36:13 metrics/test.rmse:  9.220
2025-08-22 10:36:13 metrics/test.rmse_pcutoff:5.552
2025-08-22 10:36:13 metrics/test.mAP:   93.268
2025-08-22 10:36:13 metrics/test.mAR:   95.167
2025-08-22 10:36:13 metrics/test.rmse_detections:9.220
2025-08-22 10:36:13 metrics/test.rmse_detections_pcutoff:5.552
2025-08-22 10:36:13 Epoch 110/200 (lr=0.0001), train loss 0.00064, valid loss 0.00316
2025-08-22 10:41:30 Epoch 111/200 (lr=0.0001), train loss 0.00065
2025-08-22 10:46:33 Epoch 112/200 (lr=0.0001), train loss 0.00064
2025-08-22 10:52:19 Epoch 113/200 (lr=0.0001), train loss 0.00063
2025-08-22 10:58:05 Epoch 114/200 (lr=0.0001), train loss 0.00059
2025-08-22 11:03:32 Epoch 115/200 (lr=0.0001), train loss 0.00060
2025-08-22 11:08:58 Epoch 116/200 (lr=0.0001), train loss 0.00063
2025-08-22 11:14:24 Epoch 117/200 (lr=0.0001), train loss 0.00061
2025-08-22 11:19:42 Epoch 118/200 (lr=0.0001), train loss 0.00060
2025-08-22 11:24:57 Epoch 119/200 (lr=0.0001), train loss 0.00061
2025-08-22 11:30:11 Training for epoch 120 done, starting evaluation
2025-08-22 11:30:20 Epoch 120 performance:
2025-08-22 11:30:20 metrics/test.rmse:  9.295
2025-08-22 11:30:20 metrics/test.rmse_pcutoff:5.170
2025-08-22 11:30:20 metrics/test.mAP:   94.458
2025-08-22 11:30:20 metrics/test.mAR:   96.167
2025-08-22 11:30:20 metrics/test.rmse_detections:9.295
2025-08-22 11:30:20 metrics/test.rmse_detections_pcutoff:5.170
2025-08-22 11:30:20 Epoch 120/200 (lr=0.0001), train loss 0.00057, valid loss 0.00324
2025-08-22 11:35:37 Epoch 121/200 (lr=0.0001), train loss 0.00056
2025-08-22 11:40:38 Epoch 122/200 (lr=0.0001), train loss 0.00060
2025-08-22 11:45:39 Epoch 123/200 (lr=0.0001), train loss 0.00058
2025-08-22 11:50:14 Epoch 124/200 (lr=0.0001), train loss 0.00059
2025-08-22 11:55:23 Epoch 125/200 (lr=0.0001), train loss 0.00061
2025-08-22 12:00:30 Epoch 126/200 (lr=0.0001), train loss 0.00056
2025-08-22 12:05:37 Epoch 127/200 (lr=0.0001), train loss 0.00058
2025-08-22 12:10:49 Epoch 128/200 (lr=0.0001), train loss 0.00058
2025-08-22 12:15:52 Epoch 129/200 (lr=0.0001), train loss 0.00058
2025-08-22 12:21:15 Training for epoch 130 done, starting evaluation
2025-08-22 12:21:23 Epoch 130 performance:
2025-08-22 12:21:23 metrics/test.rmse:  9.084
2025-08-22 12:21:23 metrics/test.rmse_pcutoff:5.402
2025-08-22 12:21:23 metrics/test.mAP:   94.305
2025-08-22 12:21:23 metrics/test.mAR:   95.833
2025-08-22 12:21:23 metrics/test.rmse_detections:9.084
2025-08-22 12:21:23 metrics/test.rmse_detections_pcutoff:5.402
2025-08-22 12:21:23 Epoch 130/200 (lr=0.0001), train loss 0.00059, valid loss 0.00305
2025-08-22 12:27:06 Epoch 131/200 (lr=0.0001), train loss 0.00058
2025-08-22 12:32:28 Epoch 132/200 (lr=0.0001), train loss 0.00059
2025-08-22 12:37:58 Epoch 133/200 (lr=0.0001), train loss 0.00057
2025-08-22 12:43:21 Epoch 134/200 (lr=0.0001), train loss 0.00053
2025-08-22 12:48:52 Epoch 135/200 (lr=0.0001), train loss 0.00050
2025-08-22 12:54:13 Epoch 136/200 (lr=0.0001), train loss 0.00050
2025-08-22 12:59:22 Epoch 137/200 (lr=0.0001), train loss 0.00051
2025-08-22 13:04:37 Epoch 138/200 (lr=0.0001), train loss 0.00053
2025-08-22 13:09:44 Epoch 139/200 (lr=0.0001), train loss 0.00055
2025-08-22 13:15:05 Training for epoch 140 done, starting evaluation
2025-08-22 13:15:13 Epoch 140 performance:
2025-08-22 13:15:13 metrics/test.rmse:  11.548
2025-08-22 13:15:13 metrics/test.rmse_pcutoff:5.571
2025-08-22 13:15:13 metrics/test.mAP:   93.161
2025-08-22 13:15:13 metrics/test.mAR:   94.667
2025-08-22 13:15:13 metrics/test.rmse_detections:11.548
2025-08-22 13:15:13 metrics/test.rmse_detections_pcutoff:5.571
2025-08-22 13:15:13 Epoch 140/200 (lr=0.0001), train loss 0.00056, valid loss 0.00323
2025-08-22 13:20:28 Epoch 141/200 (lr=0.0001), train loss 0.00055
2025-08-22 13:26:08 Epoch 142/200 (lr=0.0001), train loss 0.00052
2025-08-22 13:31:42 Epoch 143/200 (lr=0.0001), train loss 0.00052
2025-08-22 13:36:40 Epoch 144/200 (lr=0.0001), train loss 0.00051
2025-08-22 13:41:53 Epoch 145/200 (lr=0.0001), train loss 0.00051
2025-08-22 13:47:09 Epoch 146/200 (lr=0.0001), train loss 0.00050
2025-08-22 13:52:46 Epoch 147/200 (lr=0.0001), train loss 0.00053
2025-08-22 13:58:13 Epoch 148/200 (lr=0.0001), train loss 0.00050
2025-08-22 14:04:09 Epoch 149/200 (lr=0.0001), train loss 0.00052
2025-08-22 14:09:33 Training for epoch 150 done, starting evaluation
2025-08-22 14:09:42 Epoch 150 performance:
2025-08-22 14:09:42 metrics/test.rmse:  8.407
2025-08-22 14:09:42 metrics/test.rmse_pcutoff:4.792
2025-08-22 14:09:42 metrics/test.mAP:   94.906
2025-08-22 14:09:42 metrics/test.mAR:   96.167
2025-08-22 14:09:42 metrics/test.rmse_detections:8.407
2025-08-22 14:09:42 metrics/test.rmse_detections_pcutoff:4.792
2025-08-22 14:09:42 Epoch 150/200 (lr=0.0001), train loss 0.00048, valid loss 0.00320
2025-08-22 14:15:31 Epoch 151/200 (lr=0.0001), train loss 0.00049
2025-08-22 14:20:45 Epoch 152/200 (lr=0.0001), train loss 0.00053
2025-08-22 14:26:17 Epoch 153/200 (lr=0.0001), train loss 0.00051
2025-08-22 14:31:28 Epoch 154/200 (lr=0.0001), train loss 0.00049
2025-08-22 14:37:33 Epoch 155/200 (lr=0.0001), train loss 0.00047
2025-08-22 14:44:01 Epoch 156/200 (lr=0.0001), train loss 0.00046
2025-08-22 14:50:39 Epoch 157/200 (lr=0.0001), train loss 0.00046
2025-08-22 14:57:13 Epoch 158/200 (lr=0.0001), train loss 0.00050
2025-08-22 15:04:12 Epoch 159/200 (lr=0.0001), train loss 0.00049
2025-08-22 15:10:36 Training for epoch 160 done, starting evaluation
2025-08-22 15:10:46 Epoch 160 performance:
2025-08-22 15:10:46 metrics/test.rmse:  7.440
2025-08-22 15:10:46 metrics/test.rmse_pcutoff:4.824
2025-08-22 15:10:46 metrics/test.mAP:   96.250
2025-08-22 15:10:46 metrics/test.mAR:   97.167
2025-08-22 15:10:46 metrics/test.rmse_detections:7.440
2025-08-22 15:10:46 metrics/test.rmse_detections_pcutoff:4.824
2025-08-22 15:10:46 Epoch 160/200 (lr=1e-05), train loss 0.00046, valid loss 0.00313
2025-08-22 15:16:23 Epoch 161/200 (lr=1e-05), train loss 0.00041
2025-08-22 15:22:40 Epoch 162/200 (lr=1e-05), train loss 0.00037
2025-08-22 15:28:41 Epoch 163/200 (lr=1e-05), train loss 0.00037
2025-08-22 15:34:35 Epoch 164/200 (lr=1e-05), train loss 0.00036
2025-08-22 15:40:43 Epoch 165/200 (lr=1e-05), train loss 0.00035
2025-08-22 15:47:37 Epoch 166/200 (lr=1e-05), train loss 0.00036
2025-08-22 15:53:06 Epoch 167/200 (lr=1e-05), train loss 0.00034
2025-08-22 15:59:09 Epoch 168/200 (lr=1e-05), train loss 0.00034
2025-08-22 16:05:07 Epoch 169/200 (lr=1e-05), train loss 0.00031
2025-08-22 16:10:34 Training for epoch 170 done, starting evaluation
2025-08-22 16:10:43 Epoch 170 performance:
2025-08-22 16:10:43 metrics/test.rmse:  7.516
2025-08-22 16:10:43 metrics/test.rmse_pcutoff:4.763
2025-08-22 16:10:43 metrics/test.mAP:   95.766
2025-08-22 16:10:43 metrics/test.mAR:   97.000
2025-08-22 16:10:43 metrics/test.rmse_detections:7.516
2025-08-22 16:10:43 metrics/test.rmse_detections_pcutoff:4.763
2025-08-22 16:10:43 Epoch 170/200 (lr=1e-05), train loss 0.00032, valid loss 0.00310
2025-08-22 16:16:46 Epoch 171/200 (lr=1e-05), train loss 0.00034
2025-08-22 16:22:39 Epoch 172/200 (lr=1e-05), train loss 0.00032
2025-08-22 16:28:41 Epoch 173/200 (lr=1e-05), train loss 0.00031
2025-08-22 16:34:35 Epoch 174/200 (lr=1e-05), train loss 0.00033
2025-08-22 16:41:36 Epoch 175/200 (lr=1e-05), train loss 0.00033
2025-08-22 16:48:13 Epoch 176/200 (lr=1e-05), train loss 0.00032
2025-08-22 16:54:26 Epoch 177/200 (lr=1e-05), train loss 0.00034
2025-08-22 17:00:14 Epoch 178/200 (lr=1e-05), train loss 0.00031
2025-08-22 17:05:54 Epoch 179/200 (lr=1e-05), train loss 0.00033
2025-08-22 17:11:46 Training for epoch 180 done, starting evaluation
2025-08-22 17:11:55 Epoch 180 performance:
2025-08-22 17:11:55 metrics/test.rmse:  7.501
2025-08-22 17:11:55 metrics/test.rmse_pcutoff:4.566
2025-08-22 17:11:55 metrics/test.mAP:   95.838
2025-08-22 17:11:55 metrics/test.mAR:   97.000
2025-08-22 17:11:55 metrics/test.rmse_detections:7.501
2025-08-22 17:11:55 metrics/test.rmse_detections_pcutoff:4.566
2025-08-22 17:11:55 Epoch 180/200 (lr=1e-05), train loss 0.00030, valid loss 0.00309
2025-08-22 17:17:41 Epoch 181/200 (lr=1e-05), train loss 0.00032
2025-08-22 17:23:06 Epoch 182/200 (lr=1e-05), train loss 0.00032
2025-08-22 17:28:57 Epoch 183/200 (lr=1e-05), train loss 0.00032
2025-08-22 17:34:23 Epoch 184/200 (lr=1e-05), train loss 0.00033
2025-08-22 17:40:01 Epoch 185/200 (lr=1e-05), train loss 0.00031
2025-08-22 17:45:45 Epoch 186/200 (lr=1e-05), train loss 0.00032
2025-08-22 17:51:37 Epoch 187/200 (lr=1e-05), train loss 0.00029
2025-08-22 17:57:38 Epoch 188/200 (lr=1e-05), train loss 0.00031
2025-08-22 18:03:30 Epoch 189/200 (lr=1e-05), train loss 0.00030
2025-08-22 18:09:14 Training for epoch 190 done, starting evaluation
2025-08-22 18:09:23 Epoch 190 performance:
2025-08-22 18:09:23 metrics/test.rmse:  7.339
2025-08-22 18:09:23 metrics/test.rmse_pcutoff:4.619
2025-08-22 18:09:23 metrics/test.mAP:   96.071
2025-08-22 18:09:23 metrics/test.mAR:   97.167
2025-08-22 18:09:23 metrics/test.rmse_detections:7.339
2025-08-22 18:09:23 metrics/test.rmse_detections_pcutoff:4.619
2025-08-22 18:09:23 Epoch 190/200 (lr=1e-06), train loss 0.00030, valid loss 0.00312
2025-08-22 18:14:32 Epoch 191/200 (lr=1e-06), train loss 0.00033
2025-08-22 18:20:27 Epoch 192/200 (lr=1e-06), train loss 0.00031
2025-08-22 18:26:05 Epoch 193/200 (lr=1e-06), train loss 0.00030
2025-08-22 18:31:47 Epoch 194/200 (lr=1e-06), train loss 0.00029
2025-08-22 18:38:19 Epoch 195/200 (lr=1e-06), train loss 0.00030
2025-08-22 18:44:03 Epoch 196/200 (lr=1e-06), train loss 0.00028
2025-08-22 18:49:39 Epoch 197/200 (lr=1e-06), train loss 0.00031
2025-08-22 18:55:01 Epoch 198/200 (lr=1e-06), train loss 0.00030
2025-08-22 19:00:56 Epoch 199/200 (lr=1e-06), train loss 0.00029
2025-08-22 19:06:29 Training for epoch 200 done, starting evaluation
2025-08-22 19:06:38 Epoch 200 performance:
2025-08-22 19:06:38 metrics/test.rmse:  7.327
2025-08-22 19:06:38 metrics/test.rmse_pcutoff:4.606
2025-08-22 19:06:38 metrics/test.mAP:   96.068
2025-08-22 19:06:38 metrics/test.mAR:   97.167
2025-08-22 19:06:38 metrics/test.rmse_detections:7.327
2025-08-22 19:06:38 metrics/test.rmse_detections_pcutoff:4.606
2025-08-22 19:06:38 Epoch 200/200 (lr=1e-06), train loss 0.00028, valid loss 0.00311
2025-08-23 04:57:36 Training with configuration:
2025-08-23 04:57:36 data:
2025-08-23 04:57:36   colormode: RGB
2025-08-23 04:57:36   inference:
2025-08-23 04:57:36     normalize_images: True
2025-08-23 04:57:36   train:
2025-08-23 04:57:36     affine:
2025-08-23 04:57:36       p: 0.5
2025-08-23 04:57:36       rotation: 30
2025-08-23 04:57:36       scaling: [1.0, 1.0]
2025-08-23 04:57:36       translation: 0
2025-08-23 04:57:36     collate:
2025-08-23 04:57:36       type: ResizeFromDataSizeCollate
2025-08-23 04:57:36       min_scale: 0.4
2025-08-23 04:57:36       max_scale: 1.0
2025-08-23 04:57:36       min_short_side: 128
2025-08-23 04:57:36       max_short_side: 1152
2025-08-23 04:57:36       multiple_of: 32
2025-08-23 04:57:36       to_square: False
2025-08-23 04:57:36     covering: False
2025-08-23 04:57:36     gaussian_noise: 12.75
2025-08-23 04:57:36     hist_eq: False
2025-08-23 04:57:36     motion_blur: False
2025-08-23 04:57:36     normalize_images: True
2025-08-23 04:57:36 device: auto
2025-08-23 04:57:36 metadata:
2025-08-23 04:57:36   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-23 04:57:36   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-23 04:57:36   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-23 04:57:36   unique_bodyparts: []
2025-08-23 04:57:36   individuals: ['animal']
2025-08-23 04:57:36   with_identity: None
2025-08-23 04:57:36 method: bu
2025-08-23 04:57:36 model:
2025-08-23 04:57:36   backbone:
2025-08-23 04:57:36     type: ResNet
2025-08-23 04:57:36     model_name: resnet50_gn
2025-08-23 04:57:36     output_stride: 16
2025-08-23 04:57:36     freeze_bn_stats: True
2025-08-23 04:57:36     freeze_bn_weights: False
2025-08-23 04:57:36   backbone_output_channels: 2048
2025-08-23 04:57:36   heads:
2025-08-23 04:57:36     bodypart:
2025-08-23 04:57:36       type: HeatmapHead
2025-08-23 04:57:36       weight_init: normal
2025-08-23 04:57:36       predictor:
2025-08-23 04:57:36         type: HeatmapPredictor
2025-08-23 04:57:36         apply_sigmoid: False
2025-08-23 04:57:36         clip_scores: True
2025-08-23 04:57:36         location_refinement: True
2025-08-23 04:57:36         locref_std: 7.2801
2025-08-23 04:57:36       target_generator:
2025-08-23 04:57:36         type: HeatmapGaussianGenerator
2025-08-23 04:57:36         num_heatmaps: 9
2025-08-23 04:57:36         pos_dist_thresh: 17
2025-08-23 04:57:36         heatmap_mode: KEYPOINT
2025-08-23 04:57:36         generate_locref: True
2025-08-23 04:57:36         locref_std: 7.2801
2025-08-23 04:57:36       criterion:
2025-08-23 04:57:36         heatmap:
2025-08-23 04:57:36           type: WeightedMSECriterion
2025-08-23 04:57:36           weight: 1.0
2025-08-23 04:57:36         locref:
2025-08-23 04:57:36           type: WeightedHuberCriterion
2025-08-23 04:57:36           weight: 0.05
2025-08-23 04:57:36       heatmap_config:
2025-08-23 04:57:36         channels: [2048, 9]
2025-08-23 04:57:36         kernel_size: [3]
2025-08-23 04:57:36         strides: [2]
2025-08-23 04:57:36       locref_config:
2025-08-23 04:57:36         channels: [2048, 18]
2025-08-23 04:57:36         kernel_size: [3]
2025-08-23 04:57:36         strides: [2]
2025-08-23 04:57:36 net_type: resnet_50
2025-08-23 04:57:36 runner:
2025-08-23 04:57:36   type: PoseTrainingRunner
2025-08-23 04:57:36   gpus: None
2025-08-23 04:57:36   key_metric: test.mAP
2025-08-23 04:57:36   key_metric_asc: True
2025-08-23 04:57:36   eval_interval: 10
2025-08-23 04:57:36   optimizer:
2025-08-23 04:57:36     type: AdamW
2025-08-23 04:57:36     params:
2025-08-23 04:57:36       lr: 0.0001
2025-08-23 04:57:36   scheduler:
2025-08-23 04:57:36     type: LRListScheduler
2025-08-23 04:57:36     params:
2025-08-23 04:57:36       lr_list: [[1e-05], [1e-06]]
2025-08-23 04:57:36       milestones: [160, 190]
2025-08-23 04:57:36   snapshots:
2025-08-23 04:57:36     max_snapshots: 5
2025-08-23 04:57:36     save_epochs: 25
2025-08-23 04:57:36     save_optimizer_state: False
2025-08-23 04:57:36 train_settings:
2025-08-23 04:57:36   batch_size: 16
2025-08-23 04:57:36   dataloader_workers: 0
2025-08-23 04:57:36   dataloader_pin_memory: True
2025-08-23 04:57:36   display_iters: 500
2025-08-23 04:57:36   epochs: 100
2025-08-23 04:57:36   seed: 42
2025-08-23 04:57:36 init_weights: custom
2025-08-23 04:57:36 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/snapshots/snapshots_200_epochs/snapshot-200.pt
2025-08-23 04:57:36 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-23 04:57:36 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-23 04:57:38 Data Transforms:
2025-08-23 04:57:38   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 04:57:38   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 04:57:51 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-23 04:57:51 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-23 04:57:51 Using 1127 images and 60 for testing
2025-08-23 04:57:51 
Starting pose model training...
--------------------------------------------------
2025-08-23 05:02:38 Epoch 1/100 (lr=0.0001), train loss 0.01209
2025-08-23 05:07:25 Epoch 2/100 (lr=0.0001), train loss 0.00654
2025-08-23 05:12:01 Epoch 3/100 (lr=0.0001), train loss 0.00518
2025-08-23 05:16:35 Epoch 4/100 (lr=0.0001), train loss 0.00433
2025-08-23 05:20:56 Epoch 5/100 (lr=0.0001), train loss 0.00385
2025-08-23 05:25:27 Epoch 6/100 (lr=0.0001), train loss 0.00360
2025-08-23 05:29:55 Epoch 7/100 (lr=0.0001), train loss 0.00323
2025-08-23 05:34:19 Epoch 8/100 (lr=0.0001), train loss 0.00310
2025-08-23 05:38:38 Epoch 9/100 (lr=0.0001), train loss 0.00300
2025-08-23 05:43:12 Training for epoch 10 done, starting evaluation
2025-08-23 05:43:21 Epoch 10 performance:
2025-08-23 05:43:21 metrics/test.rmse:  29.144
2025-08-23 05:43:21 metrics/test.rmse_pcutoff:4.242
2025-08-23 05:43:21 metrics/test.mAP:   71.958
2025-08-23 05:43:21 metrics/test.mAR:   78.833
2025-08-23 05:43:21 metrics/test.rmse_detections:29.144
2025-08-23 05:43:21 metrics/test.rmse_detections_pcutoff:4.242
2025-08-23 05:43:21 Epoch 10/100 (lr=0.0001), train loss 0.00285, valid loss 0.00389
2025-08-23 05:48:16 Epoch 11/100 (lr=0.0001), train loss 0.00270
2025-08-23 05:52:57 Epoch 12/100 (lr=0.0001), train loss 0.00259
2025-08-23 05:57:42 Epoch 13/100 (lr=0.0001), train loss 0.00245
2025-08-23 06:02:34 Epoch 14/100 (lr=0.0001), train loss 0.00237
2025-08-23 06:07:13 Epoch 15/100 (lr=0.0001), train loss 0.00229
2025-08-23 06:11:42 Epoch 16/100 (lr=0.0001), train loss 0.00229
2025-08-23 06:15:55 Epoch 17/100 (lr=0.0001), train loss 0.00223
2025-08-23 06:20:00 Epoch 18/100 (lr=0.0001), train loss 0.00209
2025-08-23 06:24:35 Epoch 19/100 (lr=0.0001), train loss 0.00206
2025-08-23 06:28:58 Training for epoch 20 done, starting evaluation
2025-08-23 06:29:07 Epoch 20 performance:
2025-08-23 06:29:07 metrics/test.rmse:  15.962
2025-08-23 06:29:07 metrics/test.rmse_pcutoff:4.767
2025-08-23 06:29:07 metrics/test.mAP:   84.332
2025-08-23 06:29:07 metrics/test.mAR:   89.000
2025-08-23 06:29:07 metrics/test.rmse_detections:15.962
2025-08-23 06:29:07 metrics/test.rmse_detections_pcutoff:4.767
2025-08-23 06:29:07 Epoch 20/100 (lr=0.0001), train loss 0.00209, valid loss 0.00348
2025-08-23 06:33:34 Epoch 21/100 (lr=0.0001), train loss 0.00201
2025-08-23 06:38:02 Epoch 22/100 (lr=0.0001), train loss 0.00201
2025-08-23 06:42:30 Epoch 23/100 (lr=0.0001), train loss 0.00186
2025-08-23 06:47:01 Epoch 24/100 (lr=0.0001), train loss 0.00182
2025-08-23 10:51:59 Training with configuration:
2025-08-23 10:51:59 data:
2025-08-23 10:51:59   colormode: RGB
2025-08-23 10:51:59   inference:
2025-08-23 10:51:59     normalize_images: True
2025-08-23 10:51:59   train:
2025-08-23 10:51:59     affine:
2025-08-23 10:51:59       p: 0.5
2025-08-23 10:51:59       rotation: 30
2025-08-23 10:51:59       scaling: [1.0, 1.0]
2025-08-23 10:51:59       translation: 0
2025-08-23 10:51:59     collate:
2025-08-23 10:51:59       type: ResizeFromDataSizeCollate
2025-08-23 10:51:59       min_scale: 0.4
2025-08-23 10:51:59       max_scale: 1.0
2025-08-23 10:51:59       min_short_side: 128
2025-08-23 10:51:59       max_short_side: 1152
2025-08-23 10:51:59       multiple_of: 32
2025-08-23 10:51:59       to_square: False
2025-08-23 10:51:59     covering: False
2025-08-23 10:51:59     gaussian_noise: 12.75
2025-08-23 10:51:59     hist_eq: False
2025-08-23 10:51:59     motion_blur: False
2025-08-23 10:51:59     normalize_images: True
2025-08-23 10:51:59 device: auto
2025-08-23 10:51:59 metadata:
2025-08-23 10:51:59   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-23 10:51:59   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-23 10:51:59   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-23 10:51:59   unique_bodyparts: []
2025-08-23 10:51:59   individuals: ['animal']
2025-08-23 10:51:59   with_identity: None
2025-08-23 10:51:59 method: bu
2025-08-23 10:51:59 model:
2025-08-23 10:51:59   backbone:
2025-08-23 10:51:59     type: ResNet
2025-08-23 10:51:59     model_name: resnet50_gn
2025-08-23 10:51:59     output_stride: 16
2025-08-23 10:51:59     freeze_bn_stats: True
2025-08-23 10:51:59     freeze_bn_weights: False
2025-08-23 10:51:59   backbone_output_channels: 2048
2025-08-23 10:51:59   heads:
2025-08-23 10:51:59     bodypart:
2025-08-23 10:51:59       type: HeatmapHead
2025-08-23 10:51:59       weight_init: normal
2025-08-23 10:51:59       predictor:
2025-08-23 10:51:59         type: HeatmapPredictor
2025-08-23 10:51:59         apply_sigmoid: False
2025-08-23 10:51:59         clip_scores: True
2025-08-23 10:51:59         location_refinement: True
2025-08-23 10:51:59         locref_std: 7.2801
2025-08-23 10:51:59       target_generator:
2025-08-23 10:51:59         type: HeatmapGaussianGenerator
2025-08-23 10:51:59         num_heatmaps: 9
2025-08-23 10:51:59         pos_dist_thresh: 17
2025-08-23 10:51:59         heatmap_mode: KEYPOINT
2025-08-23 10:51:59         generate_locref: True
2025-08-23 10:51:59         locref_std: 7.2801
2025-08-23 10:51:59       criterion:
2025-08-23 10:51:59         heatmap:
2025-08-23 10:51:59           type: WeightedMSECriterion
2025-08-23 10:51:59           weight: 1.0
2025-08-23 10:51:59         locref:
2025-08-23 10:51:59           type: WeightedHuberCriterion
2025-08-23 10:51:59           weight: 0.05
2025-08-23 10:51:59       heatmap_config:
2025-08-23 10:51:59         channels: [2048, 9]
2025-08-23 10:51:59         kernel_size: [3]
2025-08-23 10:51:59         strides: [2]
2025-08-23 10:51:59       locref_config:
2025-08-23 10:51:59         channels: [2048, 18]
2025-08-23 10:51:59         kernel_size: [3]
2025-08-23 10:51:59         strides: [2]
2025-08-23 10:51:59 net_type: resnet_50
2025-08-23 10:51:59 runner:
2025-08-23 10:51:59   type: PoseTrainingRunner
2025-08-23 10:51:59   gpus: None
2025-08-23 10:51:59   key_metric: test.mAP
2025-08-23 10:51:59   key_metric_asc: True
2025-08-23 10:51:59   eval_interval: 10
2025-08-23 10:51:59   optimizer:
2025-08-23 10:51:59     type: AdamW
2025-08-23 10:51:59     params:
2025-08-23 10:51:59       lr: 0.0001
2025-08-23 10:51:59   scheduler:
2025-08-23 10:51:59     type: LRListScheduler
2025-08-23 10:51:59     params:
2025-08-23 10:51:59       lr_list: [[1e-05], [1e-06]]
2025-08-23 10:51:59       milestones: [160, 190]
2025-08-23 10:51:59   snapshots:
2025-08-23 10:51:59     max_snapshots: 5
2025-08-23 10:51:59     save_epochs: 25
2025-08-23 10:51:59     save_optimizer_state: False
2025-08-23 10:51:59 train_settings:
2025-08-23 10:51:59   batch_size: 16
2025-08-23 10:51:59   dataloader_workers: 0
2025-08-23 10:51:59   dataloader_pin_memory: True
2025-08-23 10:51:59   display_iters: 500
2025-08-23 10:51:59   epochs: 100
2025-08-23 10:51:59   seed: 42
2025-08-23 10:51:59 init_weights: custom
2025-08-23 10:51:59 custom_weights: /home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/snapshots/snapshots_200_epochs/snapshot-200.pt
2025-08-23 10:51:59 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-23 10:51:59 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-23 10:52:01 Data Transforms:
2025-08-23 10:52:01   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 10:52:01   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 10:52:29 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-23 10:52:29 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-23 10:52:29 Using 1127 images and 60 for testing
2025-08-23 10:52:29 
Starting pose model training...
--------------------------------------------------
2025-08-23 10:57:39 Epoch 1/100 (lr=0.0001), train loss 0.01209
2025-08-23 11:02:33 Epoch 2/100 (lr=0.0001), train loss 0.00654
2025-08-23 11:07:31 Epoch 3/100 (lr=0.0001), train loss 0.00518
2025-08-23 11:12:07 Epoch 4/100 (lr=0.0001), train loss 0.00433
2025-08-23 11:16:42 Epoch 5/100 (lr=0.0001), train loss 0.00385
2025-08-23 11:21:20 Epoch 6/100 (lr=0.0001), train loss 0.00360
2025-08-23 11:26:02 Epoch 7/100 (lr=0.0001), train loss 0.00323
2025-08-23 11:30:42 Epoch 8/100 (lr=0.0001), train loss 0.00310
2025-08-23 11:43:41 Training with configuration:
2025-08-23 11:43:41 data:
2025-08-23 11:43:41   colormode: RGB
2025-08-23 11:43:41   inference:
2025-08-23 11:43:41     normalize_images: True
2025-08-23 11:43:41   train:
2025-08-23 11:43:41     affine:
2025-08-23 11:43:41       p: 0.5
2025-08-23 11:43:41       rotation: 30
2025-08-23 11:43:41       scaling: [1.0, 1.0]
2025-08-23 11:43:41       translation: 0
2025-08-23 11:43:41     collate:
2025-08-23 11:43:41       type: ResizeFromDataSizeCollate
2025-08-23 11:43:41       min_scale: 0.4
2025-08-23 11:43:41       max_scale: 1.0
2025-08-23 11:43:41       min_short_side: 128
2025-08-23 11:43:41       max_short_side: 1152
2025-08-23 11:43:41       multiple_of: 32
2025-08-23 11:43:41       to_square: False
2025-08-23 11:43:41     covering: False
2025-08-23 11:43:41     gaussian_noise: 12.75
2025-08-23 11:43:41     hist_eq: False
2025-08-23 11:43:41     motion_blur: False
2025-08-23 11:43:41     normalize_images: True
2025-08-23 11:43:41 device: auto
2025-08-23 11:43:41 metadata:
2025-08-23 11:43:41   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-23 11:43:41   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-23 11:43:41   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-23 11:43:41   unique_bodyparts: []
2025-08-23 11:43:41   individuals: ['animal']
2025-08-23 11:43:41   with_identity: None
2025-08-23 11:43:41 method: bu
2025-08-23 11:43:41 model:
2025-08-23 11:43:41   backbone:
2025-08-23 11:43:41     type: ResNet
2025-08-23 11:43:41     model_name: resnet50_gn
2025-08-23 11:43:41     output_stride: 16
2025-08-23 11:43:41     freeze_bn_stats: True
2025-08-23 11:43:41     freeze_bn_weights: False
2025-08-23 11:43:41   backbone_output_channels: 2048
2025-08-23 11:43:41   heads:
2025-08-23 11:43:41     bodypart:
2025-08-23 11:43:41       type: HeatmapHead
2025-08-23 11:43:41       weight_init: normal
2025-08-23 11:43:41       predictor:
2025-08-23 11:43:41         type: HeatmapPredictor
2025-08-23 11:43:41         apply_sigmoid: False
2025-08-23 11:43:41         clip_scores: True
2025-08-23 11:43:41         location_refinement: True
2025-08-23 11:43:41         locref_std: 7.2801
2025-08-23 11:43:41       target_generator:
2025-08-23 11:43:41         type: HeatmapGaussianGenerator
2025-08-23 11:43:41         num_heatmaps: 9
2025-08-23 11:43:41         pos_dist_thresh: 17
2025-08-23 11:43:41         heatmap_mode: KEYPOINT
2025-08-23 11:43:41         generate_locref: True
2025-08-23 11:43:41         locref_std: 7.2801
2025-08-23 11:43:41       criterion:
2025-08-23 11:43:41         heatmap:
2025-08-23 11:43:41           type: WeightedMSECriterion
2025-08-23 11:43:41           weight: 1.0
2025-08-23 11:43:41         locref:
2025-08-23 11:43:41           type: WeightedHuberCriterion
2025-08-23 11:43:41           weight: 0.05
2025-08-23 11:43:41       heatmap_config:
2025-08-23 11:43:41         channels: [2048, 9]
2025-08-23 11:43:41         kernel_size: [3]
2025-08-23 11:43:41         strides: [2]
2025-08-23 11:43:41       locref_config:
2025-08-23 11:43:41         channels: [2048, 18]
2025-08-23 11:43:41         kernel_size: [3]
2025-08-23 11:43:41         strides: [2]
2025-08-23 11:43:41 net_type: resnet_50
2025-08-23 11:43:41 runner:
2025-08-23 11:43:41   type: PoseTrainingRunner
2025-08-23 11:43:41   gpus: None
2025-08-23 11:43:41   key_metric: test.mAP
2025-08-23 11:43:41   key_metric_asc: True
2025-08-23 11:43:41   eval_interval: 10
2025-08-23 11:43:41   optimizer:
2025-08-23 11:43:41     type: AdamW
2025-08-23 11:43:41     params:
2025-08-23 11:43:41       lr: 0.0001
2025-08-23 11:43:41   scheduler:
2025-08-23 11:43:41     type: LRListScheduler
2025-08-23 11:43:41     params:
2025-08-23 11:43:41       lr_list: [[1e-05], [1e-06]]
2025-08-23 11:43:41       milestones: [160, 190]
2025-08-23 11:43:41   snapshots:
2025-08-23 11:43:41     max_snapshots: 5
2025-08-23 11:43:41     save_epochs: 25
2025-08-23 11:43:41     save_optimizer_state: False
2025-08-23 11:43:41 train_settings:
2025-08-23 11:43:41   batch_size: 16
2025-08-23 11:43:41   dataloader_workers: 0
2025-08-23 11:43:41   dataloader_pin_memory: True
2025-08-23 11:43:41   display_iters: 500
2025-08-23 11:43:41   epochs: 200
2025-08-23 11:43:41   seed: 42
2025-08-23 11:43:41 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-23 11:43:41 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-23 11:43:44 Data Transforms:
2025-08-23 11:43:44   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 11:43:44   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 11:43:48 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-23 11:43:48 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-23 11:43:48 Using 1127 images and 60 for testing
2025-08-23 11:43:48 
Starting pose model training...
--------------------------------------------------
2025-08-23 11:44:38 Training with configuration:
2025-08-23 11:44:38 data:
2025-08-23 11:44:38   colormode: RGB
2025-08-23 11:44:38   inference:
2025-08-23 11:44:38     normalize_images: True
2025-08-23 11:44:38   train:
2025-08-23 11:44:38     affine:
2025-08-23 11:44:38       p: 0.5
2025-08-23 11:44:38       rotation: 30
2025-08-23 11:44:38       scaling: [1.0, 1.0]
2025-08-23 11:44:38       translation: 0
2025-08-23 11:44:38     collate:
2025-08-23 11:44:38       type: ResizeFromDataSizeCollate
2025-08-23 11:44:38       min_scale: 0.4
2025-08-23 11:44:38       max_scale: 1.0
2025-08-23 11:44:38       min_short_side: 128
2025-08-23 11:44:38       max_short_side: 1152
2025-08-23 11:44:38       multiple_of: 32
2025-08-23 11:44:38       to_square: False
2025-08-23 11:44:38     covering: False
2025-08-23 11:44:38     gaussian_noise: 12.75
2025-08-23 11:44:38     hist_eq: False
2025-08-23 11:44:38     motion_blur: False
2025-08-23 11:44:38     normalize_images: True
2025-08-23 11:44:38 device: auto
2025-08-23 11:44:38 metadata:
2025-08-23 11:44:38   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-23 11:44:38   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-23 11:44:38   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-23 11:44:38   unique_bodyparts: []
2025-08-23 11:44:38   individuals: ['animal']
2025-08-23 11:44:38   with_identity: None
2025-08-23 11:44:38 method: bu
2025-08-23 11:44:38 model:
2025-08-23 11:44:38   backbone:
2025-08-23 11:44:38     type: ResNet
2025-08-23 11:44:38     model_name: resnet50_gn
2025-08-23 11:44:38     output_stride: 16
2025-08-23 11:44:38     freeze_bn_stats: True
2025-08-23 11:44:38     freeze_bn_weights: False
2025-08-23 11:44:38   backbone_output_channels: 2048
2025-08-23 11:44:38   heads:
2025-08-23 11:44:38     bodypart:
2025-08-23 11:44:38       type: HeatmapHead
2025-08-23 11:44:38       weight_init: normal
2025-08-23 11:44:38       predictor:
2025-08-23 11:44:38         type: HeatmapPredictor
2025-08-23 11:44:38         apply_sigmoid: False
2025-08-23 11:44:38         clip_scores: True
2025-08-23 11:44:38         location_refinement: True
2025-08-23 11:44:38         locref_std: 7.2801
2025-08-23 11:44:38       target_generator:
2025-08-23 11:44:38         type: HeatmapGaussianGenerator
2025-08-23 11:44:38         num_heatmaps: 9
2025-08-23 11:44:38         pos_dist_thresh: 17
2025-08-23 11:44:38         heatmap_mode: KEYPOINT
2025-08-23 11:44:38         generate_locref: True
2025-08-23 11:44:38         locref_std: 7.2801
2025-08-23 11:44:38       criterion:
2025-08-23 11:44:38         heatmap:
2025-08-23 11:44:38           type: WeightedMSECriterion
2025-08-23 11:44:38           weight: 1.0
2025-08-23 11:44:38         locref:
2025-08-23 11:44:38           type: WeightedHuberCriterion
2025-08-23 11:44:38           weight: 0.05
2025-08-23 11:44:38       heatmap_config:
2025-08-23 11:44:38         channels: [2048, 9]
2025-08-23 11:44:38         kernel_size: [3]
2025-08-23 11:44:38         strides: [2]
2025-08-23 11:44:38       locref_config:
2025-08-23 11:44:38         channels: [2048, 18]
2025-08-23 11:44:38         kernel_size: [3]
2025-08-23 11:44:38         strides: [2]
2025-08-23 11:44:38 net_type: resnet_50
2025-08-23 11:44:38 runner:
2025-08-23 11:44:38   type: PoseTrainingRunner
2025-08-23 11:44:38   gpus: None
2025-08-23 11:44:38   key_metric: test.mAP
2025-08-23 11:44:38   key_metric_asc: True
2025-08-23 11:44:38   eval_interval: 10
2025-08-23 11:44:38   optimizer:
2025-08-23 11:44:38     type: AdamW
2025-08-23 11:44:38     params:
2025-08-23 11:44:38       lr: 0.0001
2025-08-23 11:44:38   scheduler:
2025-08-23 11:44:38     type: LRListScheduler
2025-08-23 11:44:38     params:
2025-08-23 11:44:38       lr_list: [[1e-05], [1e-06]]
2025-08-23 11:44:38       milestones: [160, 190]
2025-08-23 11:44:38   snapshots:
2025-08-23 11:44:38     max_snapshots: 5
2025-08-23 11:44:38     save_epochs: 25
2025-08-23 11:44:38     save_optimizer_state: False
2025-08-23 11:44:38 train_settings:
2025-08-23 11:44:38   batch_size: 16
2025-08-23 11:44:38   dataloader_workers: 0
2025-08-23 11:44:38   dataloader_pin_memory: True
2025-08-23 11:44:38   display_iters: 500
2025-08-23 11:44:38   epochs: 200
2025-08-23 11:44:38   seed: 42
2025-08-23 11:44:38 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-23 11:44:38 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-23 11:44:40 Data Transforms:
2025-08-23 11:44:40   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 11:44:40   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 11:44:41 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-23 11:44:41 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-23 11:44:41 Using 1127 images and 60 for testing
2025-08-23 11:44:41 
Starting pose model training...
--------------------------------------------------
2025-08-23 11:46:21 Training with configuration:
2025-08-23 11:46:21 data:
2025-08-23 11:46:21   colormode: RGB
2025-08-23 11:46:21   inference:
2025-08-23 11:46:21     normalize_images: True
2025-08-23 11:46:21   train:
2025-08-23 11:46:21     affine:
2025-08-23 11:46:21       p: 0.5
2025-08-23 11:46:21       rotation: 30
2025-08-23 11:46:21       scaling: [1.0, 1.0]
2025-08-23 11:46:21       translation: 0
2025-08-23 11:46:21     collate:
2025-08-23 11:46:21       type: ResizeFromDataSizeCollate
2025-08-23 11:46:21       min_scale: 0.4
2025-08-23 11:46:21       max_scale: 1.0
2025-08-23 11:46:21       min_short_side: 128
2025-08-23 11:46:21       max_short_side: 1152
2025-08-23 11:46:21       multiple_of: 32
2025-08-23 11:46:21       to_square: False
2025-08-23 11:46:21     covering: False
2025-08-23 11:46:21     gaussian_noise: 12.75
2025-08-23 11:46:21     hist_eq: False
2025-08-23 11:46:21     motion_blur: False
2025-08-23 11:46:21     normalize_images: True
2025-08-23 11:46:21 device: auto
2025-08-23 11:46:21 metadata:
2025-08-23 11:46:21   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-23 11:46:21   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-23 11:46:21   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-23 11:46:21   unique_bodyparts: []
2025-08-23 11:46:21   individuals: ['animal']
2025-08-23 11:46:21   with_identity: None
2025-08-23 11:46:21 method: bu
2025-08-23 11:46:21 model:
2025-08-23 11:46:21   backbone:
2025-08-23 11:46:21     type: ResNet
2025-08-23 11:46:21     model_name: resnet50_gn
2025-08-23 11:46:21     output_stride: 16
2025-08-23 11:46:21     freeze_bn_stats: True
2025-08-23 11:46:21     freeze_bn_weights: False
2025-08-23 11:46:21   backbone_output_channels: 2048
2025-08-23 11:46:21   heads:
2025-08-23 11:46:21     bodypart:
2025-08-23 11:46:21       type: HeatmapHead
2025-08-23 11:46:21       weight_init: normal
2025-08-23 11:46:21       predictor:
2025-08-23 11:46:21         type: HeatmapPredictor
2025-08-23 11:46:21         apply_sigmoid: False
2025-08-23 11:46:21         clip_scores: True
2025-08-23 11:46:21         location_refinement: True
2025-08-23 11:46:21         locref_std: 7.2801
2025-08-23 11:46:21       target_generator:
2025-08-23 11:46:21         type: HeatmapGaussianGenerator
2025-08-23 11:46:21         num_heatmaps: 9
2025-08-23 11:46:21         pos_dist_thresh: 17
2025-08-23 11:46:21         heatmap_mode: KEYPOINT
2025-08-23 11:46:21         generate_locref: True
2025-08-23 11:46:21         locref_std: 7.2801
2025-08-23 11:46:21       criterion:
2025-08-23 11:46:21         heatmap:
2025-08-23 11:46:21           type: WeightedMSECriterion
2025-08-23 11:46:21           weight: 1.0
2025-08-23 11:46:21         locref:
2025-08-23 11:46:21           type: WeightedHuberCriterion
2025-08-23 11:46:21           weight: 0.05
2025-08-23 11:46:21       heatmap_config:
2025-08-23 11:46:21         channels: [2048, 9]
2025-08-23 11:46:21         kernel_size: [3]
2025-08-23 11:46:21         strides: [2]
2025-08-23 11:46:21       locref_config:
2025-08-23 11:46:21         channels: [2048, 18]
2025-08-23 11:46:21         kernel_size: [3]
2025-08-23 11:46:21         strides: [2]
2025-08-23 11:46:21 net_type: resnet_50
2025-08-23 11:46:21 runner:
2025-08-23 11:46:21   type: PoseTrainingRunner
2025-08-23 11:46:21   gpus: None
2025-08-23 11:46:21   key_metric: test.mAP
2025-08-23 11:46:21   key_metric_asc: True
2025-08-23 11:46:21   eval_interval: 10
2025-08-23 11:46:21   optimizer:
2025-08-23 11:46:21     type: AdamW
2025-08-23 11:46:21     params:
2025-08-23 11:46:21       lr: 0.0001
2025-08-23 11:46:21   scheduler:
2025-08-23 11:46:21     type: LRListScheduler
2025-08-23 11:46:21     params:
2025-08-23 11:46:21       lr_list: [[1e-05], [1e-06]]
2025-08-23 11:46:21       milestones: [160, 190]
2025-08-23 11:46:21   snapshots:
2025-08-23 11:46:21     max_snapshots: 5
2025-08-23 11:46:21     save_epochs: 25
2025-08-23 11:46:21     save_optimizer_state: False
2025-08-23 11:46:21 train_settings:
2025-08-23 11:46:21   batch_size: 16
2025-08-23 11:46:21   dataloader_workers: 0
2025-08-23 11:46:21   dataloader_pin_memory: True
2025-08-23 11:46:21   display_iters: 500
2025-08-23 11:46:21   epochs: 400
2025-08-23 11:46:21   seed: 42
2025-08-23 11:46:22 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-23 11:46:22 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-23 11:46:24 Data Transforms:
2025-08-23 11:46:24   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 11:46:24   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 11:46:25 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-23 11:46:25 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-23 11:46:25 Using 1127 images and 60 for testing
2025-08-23 11:46:25 
Starting pose model training...
--------------------------------------------------
2025-08-23 11:51:09 Epoch 201/400 (lr=0.0001), train loss 0.00105
2025-08-23 11:55:53 Epoch 202/400 (lr=0.0001), train loss 0.00100
2025-08-23 12:00:35 Epoch 203/400 (lr=0.0001), train loss 0.00090
2025-08-23 12:05:03 Epoch 204/400 (lr=0.0001), train loss 0.00086
2025-08-23 12:09:41 Epoch 205/400 (lr=0.0001), train loss 0.00080
2025-08-23 12:14:36 Epoch 206/400 (lr=0.0001), train loss 0.00077
2025-08-23 12:19:10 Epoch 207/400 (lr=0.0001), train loss 0.00074
2025-08-23 12:23:59 Epoch 208/400 (lr=0.0001), train loss 0.00071
2025-08-23 12:28:42 Epoch 209/400 (lr=0.0001), train loss 0.00067
2025-08-23 12:33:25 Training for epoch 210 done, starting evaluation
2025-08-23 12:33:34 Epoch 210 performance:
2025-08-23 12:33:34 metrics/test.rmse:  6.653
2025-08-23 12:33:34 metrics/test.rmse_pcutoff:3.540
2025-08-23 12:33:34 metrics/test.mAP:   96.015
2025-08-23 12:33:34 metrics/test.mAR:   97.000
2025-08-23 12:33:34 metrics/test.rmse_detections:6.653
2025-08-23 12:33:34 metrics/test.rmse_detections_pcutoff:3.540
2025-08-23 12:33:34 Epoch 210/400 (lr=0.0001), train loss 0.00066, valid loss 0.00145
2025-08-23 12:38:23 Epoch 211/400 (lr=0.0001), train loss 0.00066
2025-08-23 12:43:06 Epoch 212/400 (lr=0.0001), train loss 0.00064
2025-08-23 12:47:46 Epoch 213/400 (lr=0.0001), train loss 0.00060
2025-08-23 12:53:02 Epoch 214/400 (lr=0.0001), train loss 0.00058
2025-08-23 12:58:02 Epoch 215/400 (lr=0.0001), train loss 0.00056
2025-08-23 13:02:49 Epoch 216/400 (lr=0.0001), train loss 0.00058
2025-08-23 13:07:03 Epoch 217/400 (lr=0.0001), train loss 0.00058
2025-08-23 13:11:23 Epoch 218/400 (lr=0.0001), train loss 0.00053
2025-08-23 13:15:51 Epoch 219/400 (lr=0.0001), train loss 0.00053
2025-08-23 13:20:23 Training for epoch 220 done, starting evaluation
2025-08-23 13:20:30 Epoch 220 performance:
2025-08-23 13:20:30 metrics/test.rmse:  4.622
2025-08-23 13:20:30 metrics/test.rmse_pcutoff:3.099
2025-08-23 13:20:30 metrics/test.mAP:   97.360
2025-08-23 13:20:30 metrics/test.mAR:   97.833
2025-08-23 13:20:30 metrics/test.rmse_detections:4.622
2025-08-23 13:20:30 metrics/test.rmse_detections_pcutoff:3.099
2025-08-23 13:20:30 Epoch 220/400 (lr=0.0001), train loss 0.00056, valid loss 0.00151
2025-08-23 13:24:58 Epoch 221/400 (lr=0.0001), train loss 0.00051
2025-08-23 13:29:50 Epoch 222/400 (lr=0.0001), train loss 0.00052
2025-08-23 13:34:32 Epoch 223/400 (lr=0.0001), train loss 0.00048
2025-08-23 13:39:03 Epoch 224/400 (lr=0.0001), train loss 0.00047
2025-08-23 13:43:34 Epoch 225/400 (lr=0.0001), train loss 0.00048
2025-08-23 13:48:19 Epoch 226/400 (lr=0.0001), train loss 0.00047
2025-08-23 13:52:58 Epoch 227/400 (lr=0.0001), train loss 0.00044
2025-08-23 13:57:39 Epoch 228/400 (lr=0.0001), train loss 0.00044
2025-08-23 14:02:18 Epoch 229/400 (lr=0.0001), train loss 0.00044
2025-08-23 14:07:04 Training for epoch 230 done, starting evaluation
2025-08-23 14:07:12 Epoch 230 performance:
2025-08-23 14:07:12 metrics/test.rmse:  4.525
2025-08-23 14:07:12 metrics/test.rmse_pcutoff:2.843
2025-08-23 14:07:12 metrics/test.mAP:   97.639
2025-08-23 14:07:12 metrics/test.mAR:   98.167
2025-08-23 14:07:12 metrics/test.rmse_detections:4.525
2025-08-23 14:07:12 metrics/test.rmse_detections_pcutoff:2.843
2025-08-23 14:07:12 Epoch 230/400 (lr=0.0001), train loss 0.00041, valid loss 0.00163
2025-08-23 14:11:54 Epoch 231/400 (lr=0.0001), train loss 0.00043
2025-08-23 14:16:53 Epoch 232/400 (lr=0.0001), train loss 0.00040
2025-08-23 14:21:29 Epoch 233/400 (lr=0.0001), train loss 0.00040
2025-08-23 14:26:23 Epoch 234/400 (lr=0.0001), train loss 0.00042
2025-08-23 14:31:29 Epoch 235/400 (lr=0.0001), train loss 0.00041
2025-08-23 14:36:21 Epoch 236/400 (lr=0.0001), train loss 0.00041
2025-08-23 14:41:03 Epoch 237/400 (lr=0.0001), train loss 0.00039
2025-08-23 14:45:59 Epoch 238/400 (lr=0.0001), train loss 0.00037
2025-08-23 14:50:40 Epoch 239/400 (lr=0.0001), train loss 0.00037
2025-08-23 14:55:11 Training for epoch 240 done, starting evaluation
2025-08-23 14:55:19 Epoch 240 performance:
2025-08-23 14:55:19 metrics/test.rmse:  5.003
2025-08-23 14:55:19 metrics/test.rmse_pcutoff:3.238
2025-08-23 14:55:19 metrics/test.mAP:   96.972
2025-08-23 14:55:19 metrics/test.mAR:   97.667
2025-08-23 14:55:19 metrics/test.rmse_detections:5.003
2025-08-23 14:55:19 metrics/test.rmse_detections_pcutoff:3.238
2025-08-23 14:55:19 Epoch 240/400 (lr=0.0001), train loss 0.00038, valid loss 0.00162
2025-08-23 14:59:55 Epoch 241/400 (lr=0.0001), train loss 0.00037
2025-08-23 15:04:24 Epoch 242/400 (lr=0.0001), train loss 0.00036
2025-08-23 15:09:10 Epoch 243/400 (lr=0.0001), train loss 0.00036
2025-08-23 15:13:50 Epoch 244/400 (lr=0.0001), train loss 0.00034
2025-08-23 15:18:11 Epoch 245/400 (lr=0.0001), train loss 0.00035
2025-08-23 15:22:53 Epoch 246/400 (lr=0.0001), train loss 0.00035
2025-08-23 15:27:37 Epoch 247/400 (lr=0.0001), train loss 0.00035
2025-08-23 15:32:17 Epoch 248/400 (lr=0.0001), train loss 0.00037
2025-08-23 15:36:51 Epoch 249/400 (lr=0.0001), train loss 0.00036
2025-08-23 15:41:06 Training for epoch 250 done, starting evaluation
2025-08-23 15:41:15 Epoch 250 performance:
2025-08-23 15:41:15 metrics/test.rmse:  4.700
2025-08-23 15:41:15 metrics/test.rmse_pcutoff:2.960
2025-08-23 15:41:15 metrics/test.mAP:   97.585
2025-08-23 15:41:15 metrics/test.mAR:   98.000
2025-08-23 15:41:15 metrics/test.rmse_detections:4.700
2025-08-23 15:41:15 metrics/test.rmse_detections_pcutoff:2.960
2025-08-23 15:41:15 Epoch 250/400 (lr=0.0001), train loss 0.00037, valid loss 0.00161
2025-08-23 15:45:46 Epoch 251/400 (lr=0.0001), train loss 0.00033
2025-08-23 15:50:04 Epoch 252/400 (lr=0.0001), train loss 0.00032
2025-08-23 15:54:27 Epoch 253/400 (lr=0.0001), train loss 0.00032
2025-08-23 15:58:55 Epoch 254/400 (lr=0.0001), train loss 0.00032
2025-08-23 16:03:21 Epoch 255/400 (lr=0.0001), train loss 0.00033
2025-08-23 16:07:52 Epoch 256/400 (lr=0.0001), train loss 0.00032
2025-08-23 16:12:12 Epoch 257/400 (lr=0.0001), train loss 0.00033
2025-08-23 16:16:24 Epoch 258/400 (lr=0.0001), train loss 0.00030
2025-08-23 16:17:31 Training with configuration:
2025-08-23 16:17:31 data:
2025-08-23 16:17:31   colormode: RGB
2025-08-23 16:17:31   inference:
2025-08-23 16:17:31     normalize_images: True
2025-08-23 16:17:31   train:
2025-08-23 16:17:31     affine:
2025-08-23 16:17:31       p: 0.5
2025-08-23 16:17:31       rotation: 30
2025-08-23 16:17:31       scaling: [1.0, 1.0]
2025-08-23 16:17:31       translation: 0
2025-08-23 16:17:31     collate:
2025-08-23 16:17:31       type: ResizeFromDataSizeCollate
2025-08-23 16:17:31       min_scale: 0.4
2025-08-23 16:17:31       max_scale: 1.0
2025-08-23 16:17:31       min_short_side: 128
2025-08-23 16:17:31       max_short_side: 1152
2025-08-23 16:17:31       multiple_of: 32
2025-08-23 16:17:31       to_square: False
2025-08-23 16:17:31     covering: False
2025-08-23 16:17:31     gaussian_noise: 12.75
2025-08-23 16:17:31     hist_eq: False
2025-08-23 16:17:31     motion_blur: False
2025-08-23 16:17:31     normalize_images: True
2025-08-23 16:17:31 device: auto
2025-08-23 16:17:31 metadata:
2025-08-23 16:17:31   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-23 16:17:31   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-23 16:17:31   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-23 16:17:31   unique_bodyparts: []
2025-08-23 16:17:31   individuals: ['animal']
2025-08-23 16:17:31   with_identity: None
2025-08-23 16:17:31 method: bu
2025-08-23 16:17:31 model:
2025-08-23 16:17:31   backbone:
2025-08-23 16:17:31     type: ResNet
2025-08-23 16:17:31     model_name: resnet50_gn
2025-08-23 16:17:31     output_stride: 16
2025-08-23 16:17:31     freeze_bn_stats: True
2025-08-23 16:17:31     freeze_bn_weights: False
2025-08-23 16:17:31   backbone_output_channels: 2048
2025-08-23 16:17:31   heads:
2025-08-23 16:17:31     bodypart:
2025-08-23 16:17:31       type: HeatmapHead
2025-08-23 16:17:31       weight_init: normal
2025-08-23 16:17:31       predictor:
2025-08-23 16:17:31         type: HeatmapPredictor
2025-08-23 16:17:31         apply_sigmoid: False
2025-08-23 16:17:31         clip_scores: True
2025-08-23 16:17:31         location_refinement: True
2025-08-23 16:17:31         locref_std: 7.2801
2025-08-23 16:17:31       target_generator:
2025-08-23 16:17:31         type: HeatmapGaussianGenerator
2025-08-23 16:17:31         num_heatmaps: 9
2025-08-23 16:17:31         pos_dist_thresh: 17
2025-08-23 16:17:31         heatmap_mode: KEYPOINT
2025-08-23 16:17:31         generate_locref: True
2025-08-23 16:17:31         locref_std: 7.2801
2025-08-23 16:17:31       criterion:
2025-08-23 16:17:31         heatmap:
2025-08-23 16:17:31           type: WeightedMSECriterion
2025-08-23 16:17:31           weight: 1.0
2025-08-23 16:17:31         locref:
2025-08-23 16:17:31           type: WeightedHuberCriterion
2025-08-23 16:17:31           weight: 0.05
2025-08-23 16:17:31       heatmap_config:
2025-08-23 16:17:31         channels: [2048, 9]
2025-08-23 16:17:31         kernel_size: [3]
2025-08-23 16:17:31         strides: [2]
2025-08-23 16:17:31       locref_config:
2025-08-23 16:17:31         channels: [2048, 18]
2025-08-23 16:17:31         kernel_size: [3]
2025-08-23 16:17:31         strides: [2]
2025-08-23 16:17:31 net_type: resnet_50
2025-08-23 16:17:31 runner:
2025-08-23 16:17:31   type: PoseTrainingRunner
2025-08-23 16:17:31   gpus: None
2025-08-23 16:17:31   key_metric: test.mAP
2025-08-23 16:17:31   key_metric_asc: True
2025-08-23 16:17:31   eval_interval: 10
2025-08-23 16:17:31   optimizer:
2025-08-23 16:17:31     type: AdamW
2025-08-23 16:17:31     params:
2025-08-23 16:17:31       lr: 0.0001
2025-08-23 16:17:31   scheduler:
2025-08-23 16:17:31     type: LRListScheduler
2025-08-23 16:17:31     params:
2025-08-23 16:17:31       lr_list: [[1e-05], [1e-06]]
2025-08-23 16:17:31       milestones: [160, 190]
2025-08-23 16:17:31   snapshots:
2025-08-23 16:17:31     max_snapshots: 5
2025-08-23 16:17:31     save_epochs: 25
2025-08-23 16:17:31     save_optimizer_state: False
2025-08-23 16:17:31 train_settings:
2025-08-23 16:17:31   batch_size: 16
2025-08-23 16:17:31   dataloader_workers: 0
2025-08-23 16:17:31   dataloader_pin_memory: True
2025-08-23 16:17:31   display_iters: 500
2025-08-23 16:17:31   epochs: 400
2025-08-23 16:17:31   seed: 42
2025-08-23 16:17:31 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-23 16:17:31 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-23 16:17:34 Data Transforms:
2025-08-23 16:17:34   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 16:17:34   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 16:17:36 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-23 16:17:36 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-23 16:17:36 Using 1127 images and 60 for testing
2025-08-23 16:17:36 
Starting pose model training...
--------------------------------------------------
2025-08-23 16:20:42 Epoch 259/400 (lr=0.0001), train loss 0.00032
2025-08-23 16:23:27 Epoch 201/400 (lr=0.0001), train loss 0.00105
2025-08-23 16:25:07 Training for epoch 260 done, starting evaluation
2025-08-23 16:25:14 Epoch 260 performance:
2025-08-23 16:25:14 metrics/test.rmse:  5.275
2025-08-23 16:25:14 metrics/test.rmse_pcutoff:3.479
2025-08-23 16:25:14 metrics/test.mAP:   96.948
2025-08-23 16:25:14 metrics/test.mAR:   97.333
2025-08-23 16:25:14 metrics/test.rmse_detections:5.275
2025-08-23 16:25:14 metrics/test.rmse_detections_pcutoff:3.479
2025-08-23 16:25:14 Epoch 260/400 (lr=0.0001), train loss 0.00033, valid loss 0.00167
2025-08-23 16:29:09 Epoch 202/400 (lr=0.0001), train loss 0.00100
2025-08-23 16:29:50 Epoch 261/400 (lr=0.0001), train loss 0.00032
2025-08-23 16:34:24 Epoch 262/400 (lr=0.0001), train loss 0.00031
2025-08-23 16:34:52 Epoch 203/400 (lr=0.0001), train loss 0.00090
2025-08-23 16:38:46 Epoch 263/400 (lr=0.0001), train loss 0.00030
2025-08-23 16:40:40 Epoch 204/400 (lr=0.0001), train loss 0.00086
2025-08-23 16:43:08 Epoch 264/400 (lr=0.0001), train loss 0.00030
2025-08-23 16:46:19 Epoch 205/400 (lr=0.0001), train loss 0.00080
2025-08-23 16:47:34 Epoch 265/400 (lr=0.0001), train loss 0.00031
2025-08-23 16:51:55 Epoch 206/400 (lr=0.0001), train loss 0.00077
2025-08-23 16:52:02 Epoch 266/400 (lr=0.0001), train loss 0.00028
2025-08-23 16:56:28 Epoch 267/400 (lr=0.0001), train loss 0.00029
2025-08-23 16:57:45 Epoch 207/400 (lr=0.0001), train loss 0.00074
2025-08-23 17:00:38 Epoch 268/400 (lr=0.0001), train loss 0.00028
2025-08-23 17:03:26 Epoch 208/400 (lr=0.0001), train loss 0.00071
2025-08-23 17:04:57 Epoch 269/400 (lr=0.0001), train loss 0.00028
2025-08-23 17:08:54 Epoch 209/400 (lr=0.0001), train loss 0.00067
2025-08-23 17:09:19 Training for epoch 270 done, starting evaluation
2025-08-23 17:09:28 Epoch 270 performance:
2025-08-23 17:09:28 metrics/test.rmse:  6.146
2025-08-23 17:09:28 metrics/test.rmse_pcutoff:2.887
2025-08-23 17:09:28 metrics/test.mAP:   96.654
2025-08-23 17:09:28 metrics/test.mAR:   97.167
2025-08-23 17:09:28 metrics/test.rmse_detections:6.146
2025-08-23 17:09:28 metrics/test.rmse_detections_pcutoff:2.887
2025-08-23 17:09:28 Epoch 270/400 (lr=0.0001), train loss 0.00030, valid loss 0.00170
2025-08-23 17:13:53 Epoch 271/400 (lr=0.0001), train loss 0.00029
2025-08-23 17:14:41 Training for epoch 210 done, starting evaluation
2025-08-23 17:14:50 Epoch 210 performance:
2025-08-23 17:14:50 metrics/test.rmse:  6.653
2025-08-23 17:14:50 metrics/test.rmse_pcutoff:3.540
2025-08-23 17:14:50 metrics/test.mAP:   96.015
2025-08-23 17:14:50 metrics/test.mAR:   97.000
2025-08-23 17:14:50 metrics/test.rmse_detections:6.653
2025-08-23 17:14:50 metrics/test.rmse_detections_pcutoff:3.540
2025-08-23 17:14:50 Epoch 210/400 (lr=0.0001), train loss 0.00066, valid loss 0.00145
2025-08-23 17:18:18 Epoch 272/400 (lr=0.0001), train loss 0.00028
2025-08-23 17:20:35 Epoch 211/400 (lr=0.0001), train loss 0.00066
2025-08-23 17:22:45 Epoch 273/400 (lr=0.0001), train loss 0.00027
2025-08-23 17:26:15 Epoch 212/400 (lr=0.0001), train loss 0.00064
2025-08-23 17:26:58 Epoch 274/400 (lr=0.0001), train loss 0.00028
2025-08-23 17:31:17 Epoch 275/400 (lr=0.0001), train loss 0.00028
2025-08-23 17:32:09 Epoch 213/400 (lr=0.0001), train loss 0.00060
2025-08-23 17:35:48 Epoch 276/400 (lr=0.0001), train loss 0.00027
2025-08-23 17:37:56 Epoch 214/400 (lr=0.0001), train loss 0.00058
2025-08-23 17:40:10 Epoch 277/400 (lr=0.0001), train loss 0.00027
2025-08-23 17:43:31 Epoch 215/400 (lr=0.0001), train loss 0.00056
2025-08-23 17:44:32 Epoch 278/400 (lr=0.0001), train loss 0.00028
2025-08-23 17:49:09 Epoch 216/400 (lr=0.0001), train loss 0.00058
2025-08-23 17:49:37 Epoch 279/400 (lr=0.0001), train loss 0.00027
2025-08-23 17:54:09 Training for epoch 280 done, starting evaluation
2025-08-23 17:54:18 Epoch 280 performance:
2025-08-23 17:54:18 metrics/test.rmse:  5.056
2025-08-23 17:54:18 metrics/test.rmse_pcutoff:3.151
2025-08-23 17:54:18 metrics/test.mAP:   97.088
2025-08-23 17:54:18 metrics/test.mAR:   97.667
2025-08-23 17:54:18 metrics/test.rmse_detections:5.056
2025-08-23 17:54:18 metrics/test.rmse_detections_pcutoff:3.151
2025-08-23 17:54:18 Epoch 280/400 (lr=0.0001), train loss 0.00029, valid loss 0.00168
2025-08-23 17:54:19 Epoch 217/400 (lr=0.0001), train loss 0.00058
2025-08-23 17:58:51 Epoch 281/400 (lr=0.0001), train loss 0.00026
2025-08-23 17:59:33 Epoch 218/400 (lr=0.0001), train loss 0.00053
2025-08-23 18:03:17 Epoch 282/400 (lr=0.0001), train loss 0.00025
2025-08-23 18:04:46 Epoch 219/400 (lr=0.0001), train loss 0.00053
2025-08-23 18:07:49 Epoch 283/400 (lr=0.0001), train loss 0.00025
2025-08-23 18:10:21 Training for epoch 220 done, starting evaluation
2025-08-23 18:10:29 Epoch 220 performance:
2025-08-23 18:10:29 metrics/test.rmse:  4.622
2025-08-23 18:10:29 metrics/test.rmse_pcutoff:3.099
2025-08-23 18:10:29 metrics/test.mAP:   97.360
2025-08-23 18:10:29 metrics/test.mAR:   97.833
2025-08-23 18:10:29 metrics/test.rmse_detections:4.622
2025-08-23 18:10:29 metrics/test.rmse_detections_pcutoff:3.099
2025-08-23 18:10:29 Epoch 220/400 (lr=0.0001), train loss 0.00056, valid loss 0.00151
2025-08-23 18:12:09 Epoch 284/400 (lr=0.0001), train loss 0.00025
2025-08-23 18:15:57 Epoch 221/400 (lr=0.0001), train loss 0.00051
2025-08-23 18:16:42 Epoch 285/400 (lr=0.0001), train loss 0.00026
2025-08-23 18:21:09 Epoch 286/400 (lr=0.0001), train loss 0.00027
2025-08-23 18:21:24 Epoch 222/400 (lr=0.0001), train loss 0.00052
2025-08-23 18:25:27 Epoch 287/400 (lr=0.0001), train loss 0.00025
2025-08-23 18:26:56 Epoch 223/400 (lr=0.0001), train loss 0.00048
2025-08-23 18:29:47 Epoch 288/400 (lr=0.0001), train loss 0.00025
2025-08-23 18:32:09 Epoch 224/400 (lr=0.0001), train loss 0.00047
2025-08-23 18:33:50 Epoch 289/400 (lr=0.0001), train loss 0.00025
2025-08-23 18:37:49 Epoch 225/400 (lr=0.0001), train loss 0.00048
2025-08-23 18:38:16 Training for epoch 290 done, starting evaluation
2025-08-23 18:38:24 Epoch 290 performance:
2025-08-23 18:38:24 metrics/test.rmse:  5.085
2025-08-23 18:38:24 metrics/test.rmse_pcutoff:3.263
2025-08-23 18:38:24 metrics/test.mAP:   97.187
2025-08-23 18:38:24 metrics/test.mAR:   97.667
2025-08-23 18:38:24 metrics/test.rmse_detections:5.085
2025-08-23 18:38:24 metrics/test.rmse_detections_pcutoff:3.263
2025-08-23 18:38:24 Epoch 290/400 (lr=0.0001), train loss 0.00025, valid loss 0.00168
2025-08-23 18:42:54 Epoch 291/400 (lr=0.0001), train loss 0.00026
2025-08-23 18:43:30 Epoch 226/400 (lr=0.0001), train loss 0.00047
2025-08-23 18:47:10 Epoch 292/400 (lr=0.0001), train loss 0.00024
2025-08-23 18:49:12 Epoch 227/400 (lr=0.0001), train loss 0.00044
2025-08-23 18:51:17 Epoch 293/400 (lr=0.0001), train loss 0.00025
2025-08-23 18:54:20 Epoch 228/400 (lr=0.0001), train loss 0.00044
2025-08-23 18:55:29 Epoch 294/400 (lr=0.0001), train loss 0.00024
2025-08-23 18:59:41 Epoch 229/400 (lr=0.0001), train loss 0.00044
2025-08-23 18:59:49 Epoch 295/400 (lr=0.0001), train loss 0.00024
2025-08-23 19:04:10 Epoch 296/400 (lr=0.0001), train loss 0.00025
2025-08-23 19:05:14 Training for epoch 230 done, starting evaluation
2025-08-23 19:05:22 Epoch 230 performance:
2025-08-23 19:05:22 metrics/test.rmse:  4.525
2025-08-23 19:05:22 metrics/test.rmse_pcutoff:2.843
2025-08-23 19:05:22 metrics/test.mAP:   97.639
2025-08-23 19:05:22 metrics/test.mAR:   98.167
2025-08-23 19:05:22 metrics/test.rmse_detections:4.525
2025-08-23 19:05:22 metrics/test.rmse_detections_pcutoff:2.843
2025-08-23 19:05:22 Epoch 230/400 (lr=0.0001), train loss 0.00041, valid loss 0.00163
2025-08-23 19:08:25 Epoch 297/400 (lr=0.0001), train loss 0.00023
2025-08-23 19:11:16 Epoch 231/400 (lr=0.0001), train loss 0.00043
2025-08-23 19:12:58 Epoch 298/400 (lr=0.0001), train loss 0.00023
2025-08-23 19:17:05 Epoch 232/400 (lr=0.0001), train loss 0.00040
2025-08-23 19:17:22 Epoch 299/400 (lr=0.0001), train loss 0.00023
2025-08-23 19:21:43 Training for epoch 300 done, starting evaluation
2025-08-23 19:21:50 Epoch 300 performance:
2025-08-23 19:21:50 metrics/test.rmse:  5.059
2025-08-23 19:21:50 metrics/test.rmse_pcutoff:3.243
2025-08-23 19:21:50 metrics/test.mAP:   97.167
2025-08-23 19:21:50 metrics/test.mAR:   97.667
2025-08-23 19:21:50 metrics/test.rmse_detections:5.059
2025-08-23 19:21:50 metrics/test.rmse_detections_pcutoff:3.243
2025-08-23 19:21:50 Epoch 300/400 (lr=0.0001), train loss 0.00023, valid loss 0.00176
2025-08-23 19:22:43 Epoch 233/400 (lr=0.0001), train loss 0.00040
2025-08-23 19:26:04 Epoch 301/400 (lr=0.0001), train loss 0.00024
2025-08-23 19:28:24 Epoch 234/400 (lr=0.0001), train loss 0.00042
2025-08-23 19:30:54 Epoch 302/400 (lr=0.0001), train loss 0.00023
2025-08-23 19:34:07 Epoch 235/400 (lr=0.0001), train loss 0.00041
2025-08-23 19:35:21 Epoch 303/400 (lr=0.0001), train loss 0.00023
2025-08-23 19:39:38 Epoch 236/400 (lr=0.0001), train loss 0.00041
2025-08-23 19:40:13 Epoch 304/400 (lr=0.0001), train loss 0.00024
2025-08-23 19:44:55 Epoch 305/400 (lr=0.0001), train loss 0.00023
2025-08-23 19:45:04 Epoch 237/400 (lr=0.0001), train loss 0.00039
2025-08-23 19:49:34 Epoch 306/400 (lr=0.0001), train loss 0.00023
2025-08-23 19:50:42 Epoch 238/400 (lr=0.0001), train loss 0.00037
2025-08-23 19:54:03 Epoch 307/400 (lr=0.0001), train loss 0.00025
2025-08-23 19:56:14 Epoch 239/400 (lr=0.0001), train loss 0.00037
2025-08-23 19:58:21 Epoch 308/400 (lr=0.0001), train loss 0.00023
2025-08-23 20:01:46 Training for epoch 240 done, starting evaluation
2025-08-23 20:01:54 Epoch 240 performance:
2025-08-23 20:01:54 metrics/test.rmse:  5.003
2025-08-23 20:01:54 metrics/test.rmse_pcutoff:3.238
2025-08-23 20:01:54 metrics/test.mAP:   96.972
2025-08-23 20:01:54 metrics/test.mAR:   97.667
2025-08-23 20:01:54 metrics/test.rmse_detections:5.003
2025-08-23 20:01:54 metrics/test.rmse_detections_pcutoff:3.238
2025-08-23 20:01:54 Epoch 240/400 (lr=0.0001), train loss 0.00038, valid loss 0.00162
2025-08-23 20:02:43 Epoch 309/400 (lr=0.0001), train loss 0.00022
2025-08-23 20:07:00 Training for epoch 310 done, starting evaluation
2025-08-23 20:07:07 Epoch 310 performance:
2025-08-23 20:07:07 metrics/test.rmse:  5.864
2025-08-23 20:07:07 metrics/test.rmse_pcutoff:3.066
2025-08-23 20:07:07 metrics/test.mAP:   96.966
2025-08-23 20:07:07 metrics/test.mAR:   97.333
2025-08-23 20:07:07 metrics/test.rmse_detections:5.864
2025-08-23 20:07:07 metrics/test.rmse_detections_pcutoff:3.066
2025-08-23 20:07:07 Epoch 310/400 (lr=0.0001), train loss 0.00022, valid loss 0.00174
2025-08-23 20:07:37 Epoch 241/400 (lr=0.0001), train loss 0.00037
2025-08-23 20:11:27 Epoch 311/400 (lr=0.0001), train loss 0.00021
2025-08-23 20:13:03 Epoch 242/400 (lr=0.0001), train loss 0.00036
2025-08-23 20:15:53 Epoch 312/400 (lr=0.0001), train loss 0.00022
2025-08-23 20:18:40 Epoch 243/400 (lr=0.0001), train loss 0.00036
2025-08-23 20:20:18 Epoch 313/400 (lr=0.0001), train loss 0.00022
2025-08-23 20:24:00 Epoch 244/400 (lr=0.0001), train loss 0.00034
2025-08-23 20:24:34 Epoch 314/400 (lr=0.0001), train loss 0.00022
2025-08-23 20:29:03 Epoch 315/400 (lr=0.0001), train loss 0.00020
2025-08-23 20:29:18 Epoch 245/400 (lr=0.0001), train loss 0.00035
2025-08-23 20:33:56 Epoch 316/400 (lr=0.0001), train loss 0.00022
2025-08-23 20:34:56 Epoch 246/400 (lr=0.0001), train loss 0.00035
2025-08-23 20:38:16 Epoch 317/400 (lr=0.0001), train loss 0.00021
2025-08-23 20:40:22 Epoch 247/400 (lr=0.0001), train loss 0.00035
2025-08-23 20:42:48 Epoch 318/400 (lr=0.0001), train loss 0.00022
2025-08-23 20:45:59 Epoch 248/400 (lr=0.0001), train loss 0.00037
2025-08-23 20:47:22 Epoch 319/400 (lr=0.0001), train loss 0.00022
2025-08-23 20:51:39 Training for epoch 320 done, starting evaluation
2025-08-23 20:51:44 Epoch 249/400 (lr=0.0001), train loss 0.00036
2025-08-23 20:51:47 Epoch 320 performance:
2025-08-23 20:51:47 metrics/test.rmse:  5.754
2025-08-23 20:51:47 metrics/test.rmse_pcutoff:3.092
2025-08-23 20:51:47 metrics/test.mAP:   97.374
2025-08-23 20:51:47 metrics/test.mAR:   97.833
2025-08-23 20:51:47 metrics/test.rmse_detections:5.754
2025-08-23 20:51:47 metrics/test.rmse_detections_pcutoff:3.092
2025-08-23 20:51:47 Epoch 320/400 (lr=0.0001), train loss 0.00021, valid loss 0.00177
2025-08-23 20:56:15 Epoch 321/400 (lr=0.0001), train loss 0.00020
2025-08-23 20:57:20 Training for epoch 250 done, starting evaluation
2025-08-23 20:57:28 Epoch 250 performance:
2025-08-23 20:57:28 metrics/test.rmse:  4.700
2025-08-23 20:57:28 metrics/test.rmse_pcutoff:2.960
2025-08-23 20:57:28 metrics/test.mAP:   97.585
2025-08-23 20:57:28 metrics/test.mAR:   98.000
2025-08-23 20:57:28 metrics/test.rmse_detections:4.700
2025-08-23 20:57:28 metrics/test.rmse_detections_pcutoff:2.960
2025-08-23 20:57:28 Epoch 250/400 (lr=0.0001), train loss 0.00037, valid loss 0.00161
2025-08-23 21:00:41 Epoch 322/400 (lr=0.0001), train loss 0.00022
2025-08-23 21:02:58 Epoch 251/400 (lr=0.0001), train loss 0.00033
2025-08-23 21:05:08 Epoch 323/400 (lr=0.0001), train loss 0.00021
2025-08-23 21:08:34 Epoch 252/400 (lr=0.0001), train loss 0.00032
2025-08-23 21:09:28 Epoch 324/400 (lr=0.0001), train loss 0.00022
2025-08-23 21:14:05 Epoch 325/400 (lr=0.0001), train loss 0.00022
2025-08-23 21:14:16 Epoch 253/400 (lr=0.0001), train loss 0.00032
2025-08-23 21:18:24 Epoch 326/400 (lr=0.0001), train loss 0.00021
2025-08-23 21:20:08 Epoch 254/400 (lr=0.0001), train loss 0.00032
2025-08-23 21:22:50 Epoch 327/400 (lr=0.0001), train loss 0.00020
2025-08-23 21:25:41 Epoch 255/400 (lr=0.0001), train loss 0.00033
2025-08-23 21:27:21 Epoch 328/400 (lr=0.0001), train loss 0.00021
2025-08-23 21:31:22 Epoch 256/400 (lr=0.0001), train loss 0.00032
2025-08-23 21:32:14 Epoch 329/400 (lr=0.0001), train loss 0.00022
2025-08-23 21:36:34 Training for epoch 330 done, starting evaluation
2025-08-23 21:36:41 Epoch 330 performance:
2025-08-23 21:36:41 metrics/test.rmse:  5.694
2025-08-23 21:36:41 metrics/test.rmse_pcutoff:2.957
2025-08-23 21:36:41 metrics/test.mAP:   97.353
2025-08-23 21:36:41 metrics/test.mAR:   97.833
2025-08-23 21:36:41 metrics/test.rmse_detections:5.694
2025-08-23 21:36:41 metrics/test.rmse_detections_pcutoff:2.957
2025-08-23 21:36:41 Epoch 330/400 (lr=0.0001), train loss 0.00022, valid loss 0.00171
2025-08-23 21:36:54 Epoch 257/400 (lr=0.0001), train loss 0.00033
2025-08-23 21:41:22 Epoch 331/400 (lr=0.0001), train loss 0.00021
2025-08-23 21:42:20 Epoch 258/400 (lr=0.0001), train loss 0.00030
2025-08-23 21:45:39 Epoch 332/400 (lr=0.0001), train loss 0.00020
2025-08-23 21:48:00 Epoch 259/400 (lr=0.0001), train loss 0.00032
2025-08-23 21:50:21 Epoch 333/400 (lr=0.0001), train loss 0.00021
2025-08-23 21:53:44 Training for epoch 260 done, starting evaluation
2025-08-23 21:53:53 Epoch 260 performance:
2025-08-23 21:53:53 metrics/test.rmse:  5.275
2025-08-23 21:53:53 metrics/test.rmse_pcutoff:3.479
2025-08-23 21:53:53 metrics/test.mAP:   96.948
2025-08-23 21:53:53 metrics/test.mAR:   97.333
2025-08-23 21:53:53 metrics/test.rmse_detections:5.275
2025-08-23 21:53:53 metrics/test.rmse_detections_pcutoff:3.479
2025-08-23 21:53:53 Epoch 260/400 (lr=0.0001), train loss 0.00033, valid loss 0.00167
2025-08-23 21:54:44 Epoch 334/400 (lr=0.0001), train loss 0.00021
2025-08-23 21:59:15 Epoch 335/400 (lr=0.0001), train loss 0.00020
2025-08-23 21:59:33 Epoch 261/400 (lr=0.0001), train loss 0.00032
2025-08-23 22:03:38 Epoch 336/400 (lr=0.0001), train loss 0.00019
2025-08-23 22:05:14 Epoch 262/400 (lr=0.0001), train loss 0.00031
2025-08-23 22:08:00 Epoch 337/400 (lr=0.0001), train loss 0.00020
2025-08-23 22:10:50 Epoch 263/400 (lr=0.0001), train loss 0.00030
2025-08-23 22:12:28 Epoch 338/400 (lr=0.0001), train loss 0.00021
2025-08-23 22:16:24 Epoch 264/400 (lr=0.0001), train loss 0.00030
2025-08-23 22:17:05 Epoch 339/400 (lr=0.0001), train loss 0.00020
2025-08-23 22:21:34 Training for epoch 340 done, starting evaluation
2025-08-23 22:21:41 Epoch 340 performance:
2025-08-23 22:21:41 metrics/test.rmse:  6.780
2025-08-23 22:21:41 metrics/test.rmse_pcutoff:3.061
2025-08-23 22:21:41 metrics/test.mAP:   96.972
2025-08-23 22:21:41 metrics/test.mAR:   97.333
2025-08-23 22:21:41 metrics/test.rmse_detections:6.780
2025-08-23 22:21:41 metrics/test.rmse_detections_pcutoff:3.061
2025-08-23 22:21:41 Epoch 340/400 (lr=0.0001), train loss 0.00021, valid loss 0.00178
2025-08-23 22:21:51 Epoch 265/400 (lr=0.0001), train loss 0.00031
2025-08-23 22:26:22 Epoch 341/400 (lr=0.0001), train loss 0.00020
2025-08-23 22:27:36 Epoch 266/400 (lr=0.0001), train loss 0.00028
2025-08-23 22:30:57 Epoch 342/400 (lr=0.0001), train loss 0.00019
2025-08-23 22:33:06 Epoch 267/400 (lr=0.0001), train loss 0.00029
2025-08-23 22:35:29 Epoch 343/400 (lr=0.0001), train loss 0.00020
2025-08-23 22:38:46 Epoch 268/400 (lr=0.0001), train loss 0.00028
2025-08-23 22:39:42 Epoch 344/400 (lr=0.0001), train loss 0.00019
2025-08-23 22:44:07 Epoch 345/400 (lr=0.0001), train loss 0.00019
2025-08-23 22:44:28 Epoch 269/400 (lr=0.0001), train loss 0.00028
2025-08-23 22:48:45 Epoch 346/400 (lr=0.0001), train loss 0.00019
2025-08-23 22:50:09 Training for epoch 270 done, starting evaluation
2025-08-23 22:50:17 Epoch 270 performance:
2025-08-23 22:50:17 metrics/test.rmse:  6.146
2025-08-23 22:50:17 metrics/test.rmse_pcutoff:2.887
2025-08-23 22:50:17 metrics/test.mAP:   96.654
2025-08-23 22:50:17 metrics/test.mAR:   97.167
2025-08-23 22:50:17 metrics/test.rmse_detections:6.146
2025-08-23 22:50:17 metrics/test.rmse_detections_pcutoff:2.887
2025-08-23 22:50:17 Epoch 270/400 (lr=0.0001), train loss 0.00030, valid loss 0.00170
2025-08-23 22:53:19 Epoch 347/400 (lr=0.0001), train loss 0.00019
2025-08-23 22:58:02 Epoch 348/400 (lr=0.0001), train loss 0.00018
2025-08-23 23:02:25 Epoch 349/400 (lr=0.0001), train loss 0.00020
2025-08-23 23:06:30 Training for epoch 350 done, starting evaluation
2025-08-23 23:06:37 Epoch 350 performance:
2025-08-23 23:06:37 metrics/test.rmse:  4.930
2025-08-23 23:06:37 metrics/test.rmse_pcutoff:3.066
2025-08-23 23:06:37 metrics/test.mAP:   97.504
2025-08-23 23:06:37 metrics/test.mAR:   97.833
2025-08-23 23:06:37 metrics/test.rmse_detections:4.930
2025-08-23 23:06:37 metrics/test.rmse_detections_pcutoff:3.066
2025-08-23 23:06:37 Epoch 350/400 (lr=0.0001), train loss 0.00019, valid loss 0.00173
2025-08-23 23:10:51 Training with configuration:
2025-08-23 23:10:51 data:
2025-08-23 23:10:51   colormode: RGB
2025-08-23 23:10:51   inference:
2025-08-23 23:10:51     normalize_images: True
2025-08-23 23:10:51   train:
2025-08-23 23:10:51     affine:
2025-08-23 23:10:51       p: 0.5
2025-08-23 23:10:51       rotation: 30
2025-08-23 23:10:51       scaling: [1.0, 1.0]
2025-08-23 23:10:51       translation: 0
2025-08-23 23:10:51     collate:
2025-08-23 23:10:51       type: ResizeFromDataSizeCollate
2025-08-23 23:10:51       min_scale: 0.4
2025-08-23 23:10:51       max_scale: 1.0
2025-08-23 23:10:51       min_short_side: 128
2025-08-23 23:10:51       max_short_side: 1152
2025-08-23 23:10:51       multiple_of: 32
2025-08-23 23:10:51       to_square: False
2025-08-23 23:10:51     covering: False
2025-08-23 23:10:51     gaussian_noise: 12.75
2025-08-23 23:10:51     hist_eq: False
2025-08-23 23:10:51     motion_blur: False
2025-08-23 23:10:51     normalize_images: True
2025-08-23 23:10:51 device: auto
2025-08-23 23:10:51 metadata:
2025-08-23 23:10:51   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-23 23:10:51   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-23 23:10:51   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-23 23:10:51   unique_bodyparts: []
2025-08-23 23:10:51   individuals: ['animal']
2025-08-23 23:10:51   with_identity: None
2025-08-23 23:10:51 method: bu
2025-08-23 23:10:51 model:
2025-08-23 23:10:51   backbone:
2025-08-23 23:10:51     type: ResNet
2025-08-23 23:10:51     model_name: resnet50_gn
2025-08-23 23:10:51     output_stride: 16
2025-08-23 23:10:51     freeze_bn_stats: True
2025-08-23 23:10:51     freeze_bn_weights: False
2025-08-23 23:10:51   backbone_output_channels: 2048
2025-08-23 23:10:51   heads:
2025-08-23 23:10:51     bodypart:
2025-08-23 23:10:51       type: HeatmapHead
2025-08-23 23:10:51       weight_init: normal
2025-08-23 23:10:51       predictor:
2025-08-23 23:10:51         type: HeatmapPredictor
2025-08-23 23:10:51         apply_sigmoid: False
2025-08-23 23:10:51         clip_scores: True
2025-08-23 23:10:51         location_refinement: True
2025-08-23 23:10:51         locref_std: 7.2801
2025-08-23 23:10:51       target_generator:
2025-08-23 23:10:51         type: HeatmapGaussianGenerator
2025-08-23 23:10:51         num_heatmaps: 9
2025-08-23 23:10:51         pos_dist_thresh: 17
2025-08-23 23:10:51         heatmap_mode: KEYPOINT
2025-08-23 23:10:51         generate_locref: True
2025-08-23 23:10:51         locref_std: 7.2801
2025-08-23 23:10:51       criterion:
2025-08-23 23:10:51         heatmap:
2025-08-23 23:10:51           type: WeightedMSECriterion
2025-08-23 23:10:51           weight: 1.0
2025-08-23 23:10:51         locref:
2025-08-23 23:10:51           type: WeightedHuberCriterion
2025-08-23 23:10:51           weight: 0.05
2025-08-23 23:10:51       heatmap_config:
2025-08-23 23:10:51         channels: [2048, 9]
2025-08-23 23:10:51         kernel_size: [3]
2025-08-23 23:10:51         strides: [2]
2025-08-23 23:10:51       locref_config:
2025-08-23 23:10:51         channels: [2048, 18]
2025-08-23 23:10:51         kernel_size: [3]
2025-08-23 23:10:51         strides: [2]
2025-08-23 23:10:51 net_type: resnet_50
2025-08-23 23:10:51 runner:
2025-08-23 23:10:51   type: PoseTrainingRunner
2025-08-23 23:10:51   gpus: None
2025-08-23 23:10:51   key_metric: test.mAP
2025-08-23 23:10:51   key_metric_asc: True
2025-08-23 23:10:51   eval_interval: 10
2025-08-23 23:10:51   optimizer:
2025-08-23 23:10:51     type: AdamW
2025-08-23 23:10:51     params:
2025-08-23 23:10:51       lr: 0.0001
2025-08-23 23:10:51   scheduler:
2025-08-23 23:10:51     type: LRListScheduler
2025-08-23 23:10:51     params:
2025-08-23 23:10:51       lr_list: [[1e-06], [5e-07]]
2025-08-23 23:10:51       milestones: [360, 390]
2025-08-23 23:10:51   snapshots:
2025-08-23 23:10:51     max_snapshots: 5
2025-08-23 23:10:51     save_epochs: 25
2025-08-23 23:10:51     save_optimizer_state: False
2025-08-23 23:10:51 train_settings:
2025-08-23 23:10:51   batch_size: 16
2025-08-23 23:10:51   dataloader_workers: 0
2025-08-23 23:10:51   dataloader_pin_memory: True
2025-08-23 23:10:51   display_iters: 500
2025-08-23 23:10:51   epochs: 400
2025-08-23 23:10:51   seed: 42
2025-08-23 23:10:51 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-23 23:10:51 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-23 23:10:53 Data Transforms:
2025-08-23 23:10:53   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 23:10:53   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 23:10:55 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-23 23:10:55 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-23 23:10:55 Using 1127 images and 60 for testing
2025-08-23 23:10:55 
Starting pose model training...
--------------------------------------------------
2025-08-23 23:10:57 Epoch 351/400 (lr=0.0001), train loss 0.00019
2025-08-23 23:15:22 Epoch 352/400 (lr=0.0001), train loss 0.00020
2025-08-23 23:16:46 Epoch 201/400 (lr=0.0001), train loss 0.00105
2025-08-23 23:19:38 Epoch 353/400 (lr=0.0001), train loss 0.00020
2025-08-23 23:22:24 Epoch 202/400 (lr=0.0001), train loss 0.00100
2025-08-23 23:24:04 Epoch 354/400 (lr=0.0001), train loss 0.00019
2025-08-23 23:25:59 Training with configuration:
2025-08-23 23:25:59 data:
2025-08-23 23:25:59   colormode: RGB
2025-08-23 23:25:59   inference:
2025-08-23 23:25:59     normalize_images: True
2025-08-23 23:25:59   train:
2025-08-23 23:25:59     affine:
2025-08-23 23:25:59       p: 0.5
2025-08-23 23:25:59       rotation: 30
2025-08-23 23:25:59       scaling: [1.0, 1.0]
2025-08-23 23:25:59       translation: 0
2025-08-23 23:25:59     collate:
2025-08-23 23:25:59       type: ResizeFromDataSizeCollate
2025-08-23 23:25:59       min_scale: 0.4
2025-08-23 23:25:59       max_scale: 1.0
2025-08-23 23:25:59       min_short_side: 128
2025-08-23 23:25:59       max_short_side: 1152
2025-08-23 23:25:59       multiple_of: 32
2025-08-23 23:25:59       to_square: False
2025-08-23 23:25:59     covering: False
2025-08-23 23:25:59     gaussian_noise: 12.75
2025-08-23 23:25:59     hist_eq: False
2025-08-23 23:25:59     motion_blur: False
2025-08-23 23:25:59     normalize_images: True
2025-08-23 23:25:59 device: auto
2025-08-23 23:25:59 metadata:
2025-08-23 23:25:59   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-23 23:25:59   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-23 23:25:59   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-23 23:25:59   unique_bodyparts: []
2025-08-23 23:25:59   individuals: ['animal']
2025-08-23 23:25:59   with_identity: None
2025-08-23 23:25:59 method: bu
2025-08-23 23:25:59 model:
2025-08-23 23:25:59   backbone:
2025-08-23 23:25:59     type: ResNet
2025-08-23 23:25:59     model_name: resnet50_gn
2025-08-23 23:25:59     output_stride: 16
2025-08-23 23:25:59     freeze_bn_stats: True
2025-08-23 23:25:59     freeze_bn_weights: False
2025-08-23 23:25:59   backbone_output_channels: 2048
2025-08-23 23:25:59   heads:
2025-08-23 23:25:59     bodypart:
2025-08-23 23:25:59       type: HeatmapHead
2025-08-23 23:25:59       weight_init: normal
2025-08-23 23:25:59       predictor:
2025-08-23 23:25:59         type: HeatmapPredictor
2025-08-23 23:25:59         apply_sigmoid: False
2025-08-23 23:25:59         clip_scores: True
2025-08-23 23:25:59         location_refinement: True
2025-08-23 23:25:59         locref_std: 7.2801
2025-08-23 23:25:59       target_generator:
2025-08-23 23:25:59         type: HeatmapGaussianGenerator
2025-08-23 23:25:59         num_heatmaps: 9
2025-08-23 23:25:59         pos_dist_thresh: 17
2025-08-23 23:25:59         heatmap_mode: KEYPOINT
2025-08-23 23:25:59         generate_locref: True
2025-08-23 23:25:59         locref_std: 7.2801
2025-08-23 23:25:59       criterion:
2025-08-23 23:25:59         heatmap:
2025-08-23 23:25:59           type: WeightedMSECriterion
2025-08-23 23:25:59           weight: 1.0
2025-08-23 23:25:59         locref:
2025-08-23 23:25:59           type: WeightedHuberCriterion
2025-08-23 23:25:59           weight: 0.05
2025-08-23 23:25:59       heatmap_config:
2025-08-23 23:25:59         channels: [2048, 9]
2025-08-23 23:25:59         kernel_size: [3]
2025-08-23 23:25:59         strides: [2]
2025-08-23 23:25:59       locref_config:
2025-08-23 23:25:59         channels: [2048, 18]
2025-08-23 23:25:59         kernel_size: [3]
2025-08-23 23:25:59         strides: [2]
2025-08-23 23:25:59 net_type: resnet_50
2025-08-23 23:25:59 runner:
2025-08-23 23:25:59   type: PoseTrainingRunner
2025-08-23 23:25:59   gpus: None
2025-08-23 23:25:59   key_metric: test.mAP
2025-08-23 23:25:59   key_metric_asc: True
2025-08-23 23:25:59   eval_interval: 10
2025-08-23 23:25:59   optimizer:
2025-08-23 23:25:59     type: AdamW
2025-08-23 23:25:59     params:
2025-08-23 23:25:59       lr: 1e-06
2025-08-23 23:25:59   scheduler:
2025-08-23 23:25:59     type: LRListScheduler
2025-08-23 23:25:59     params:
2025-08-23 23:25:59       lr_list: [[5e-07], [1e-07]]
2025-08-23 23:25:59       milestones: [360, 390]
2025-08-23 23:25:59   snapshots:
2025-08-23 23:25:59     max_snapshots: 5
2025-08-23 23:25:59     save_epochs: 25
2025-08-23 23:25:59     save_optimizer_state: False
2025-08-23 23:25:59 train_settings:
2025-08-23 23:25:59   batch_size: 16
2025-08-23 23:25:59   dataloader_workers: 0
2025-08-23 23:25:59   dataloader_pin_memory: True
2025-08-23 23:25:59   display_iters: 500
2025-08-23 23:25:59   epochs: 400
2025-08-23 23:25:59   seed: 42
2025-08-23 23:25:59 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-23 23:26:00 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-23 23:26:02 Data Transforms:
2025-08-23 23:26:02   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 23:26:02   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-23 23:26:06 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-23 23:26:06 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-23 23:26:06 Using 1127 images and 60 for testing
2025-08-23 23:26:06 
Starting pose model training...
--------------------------------------------------
2025-08-23 23:32:02 Epoch 201/400 (lr=1e-06), train loss 0.00106
2025-08-23 23:37:46 Epoch 202/400 (lr=1e-06), train loss 0.00110
2025-08-23 23:43:15 Epoch 203/400 (lr=1e-06), train loss 0.00103
2025-08-23 23:48:47 Epoch 204/400 (lr=1e-06), train loss 0.00106
2025-08-23 23:54:17 Epoch 205/400 (lr=1e-06), train loss 0.00101
2025-08-23 23:59:44 Epoch 206/400 (lr=1e-06), train loss 0.00103
2025-08-24 00:05:08 Epoch 207/400 (lr=1e-06), train loss 0.00102
2025-08-24 00:10:32 Epoch 208/400 (lr=1e-06), train loss 0.00100
2025-08-24 00:13:04 Training with configuration:
2025-08-24 00:13:04 data:
2025-08-24 00:13:04   colormode: RGB
2025-08-24 00:13:04   inference:
2025-08-24 00:13:04     normalize_images: True
2025-08-24 00:13:04   train:
2025-08-24 00:13:04     affine:
2025-08-24 00:13:04       p: 0.5
2025-08-24 00:13:04       rotation: 30
2025-08-24 00:13:04       scaling: [1.0, 1.0]
2025-08-24 00:13:04       translation: 0
2025-08-24 00:13:04     collate:
2025-08-24 00:13:04       type: ResizeFromDataSizeCollate
2025-08-24 00:13:04       min_scale: 0.4
2025-08-24 00:13:04       max_scale: 1.0
2025-08-24 00:13:04       min_short_side: 128
2025-08-24 00:13:04       max_short_side: 1152
2025-08-24 00:13:04       multiple_of: 32
2025-08-24 00:13:04       to_square: False
2025-08-24 00:13:04     covering: False
2025-08-24 00:13:04     gaussian_noise: 12.75
2025-08-24 00:13:04     hist_eq: False
2025-08-24 00:13:04     motion_blur: False
2025-08-24 00:13:04     normalize_images: True
2025-08-24 00:13:04 device: auto
2025-08-24 00:13:04 metadata:
2025-08-24 00:13:04   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-24 00:13:04   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-24 00:13:04   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-24 00:13:04   unique_bodyparts: []
2025-08-24 00:13:04   individuals: ['animal']
2025-08-24 00:13:04   with_identity: None
2025-08-24 00:13:04 method: bu
2025-08-24 00:13:04 model:
2025-08-24 00:13:04   backbone:
2025-08-24 00:13:04     type: ResNet
2025-08-24 00:13:04     model_name: resnet50_gn
2025-08-24 00:13:04     output_stride: 16
2025-08-24 00:13:04     freeze_bn_stats: True
2025-08-24 00:13:04     freeze_bn_weights: False
2025-08-24 00:13:04   backbone_output_channels: 2048
2025-08-24 00:13:04   heads:
2025-08-24 00:13:04     bodypart:
2025-08-24 00:13:04       type: HeatmapHead
2025-08-24 00:13:04       weight_init: normal
2025-08-24 00:13:04       predictor:
2025-08-24 00:13:04         type: HeatmapPredictor
2025-08-24 00:13:04         apply_sigmoid: False
2025-08-24 00:13:04         clip_scores: True
2025-08-24 00:13:04         location_refinement: True
2025-08-24 00:13:04         locref_std: 7.2801
2025-08-24 00:13:04       target_generator:
2025-08-24 00:13:04         type: HeatmapGaussianGenerator
2025-08-24 00:13:04         num_heatmaps: 9
2025-08-24 00:13:04         pos_dist_thresh: 17
2025-08-24 00:13:04         heatmap_mode: KEYPOINT
2025-08-24 00:13:04         generate_locref: True
2025-08-24 00:13:04         locref_std: 7.2801
2025-08-24 00:13:04       criterion:
2025-08-24 00:13:04         heatmap:
2025-08-24 00:13:04           type: WeightedMSECriterion
2025-08-24 00:13:04           weight: 1.0
2025-08-24 00:13:04         locref:
2025-08-24 00:13:04           type: WeightedHuberCriterion
2025-08-24 00:13:04           weight: 0.05
2025-08-24 00:13:04       heatmap_config:
2025-08-24 00:13:04         channels: [2048, 9]
2025-08-24 00:13:04         kernel_size: [3]
2025-08-24 00:13:04         strides: [2]
2025-08-24 00:13:04       locref_config:
2025-08-24 00:13:04         channels: [2048, 18]
2025-08-24 00:13:04         kernel_size: [3]
2025-08-24 00:13:04         strides: [2]
2025-08-24 00:13:04 net_type: resnet_50
2025-08-24 00:13:04 runner:
2025-08-24 00:13:04   type: PoseTrainingRunner
2025-08-24 00:13:04   gpus: None
2025-08-24 00:13:04   key_metric: test.mAP
2025-08-24 00:13:04   key_metric_asc: True
2025-08-24 00:13:04   eval_interval: 10
2025-08-24 00:13:04   optimizer:
2025-08-24 00:13:04     type: AdamW
2025-08-24 00:13:04     params:
2025-08-24 00:13:04       lr: 1e-06
2025-08-24 00:13:04   scheduler:
2025-08-24 00:13:04     type: LRListScheduler
2025-08-24 00:13:04     params:
2025-08-24 00:13:04       lr_list: [[5e-07], [1e-07]]
2025-08-24 00:13:04       milestones: [360, 390]
2025-08-24 00:13:04   snapshots:
2025-08-24 00:13:04     max_snapshots: 5
2025-08-24 00:13:04     save_epochs: 25
2025-08-24 00:13:04     save_optimizer_state: False
2025-08-24 00:13:04 train_settings:
2025-08-24 00:13:04   batch_size: 16
2025-08-24 00:13:04   dataloader_workers: 0
2025-08-24 00:13:04   dataloader_pin_memory: True
2025-08-24 00:13:04   display_iters: 500
2025-08-24 00:13:04   epochs: 400
2025-08-24 00:13:04   seed: 42
2025-08-24 00:13:04 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-24 00:13:05 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-24 00:13:07 Data Transforms:
2025-08-24 00:13:07   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-24 00:13:07   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-24 00:13:10 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-24 00:13:10 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-24 00:13:10 Using 1127 images and 60 for testing
2025-08-24 00:13:10 
Starting pose model training...
--------------------------------------------------
2025-08-24 00:18:54 Epoch 201/400 (lr=1e-06), train loss 0.00106
2025-08-24 00:24:41 Epoch 202/400 (lr=1e-06), train loss 0.00110
2025-08-24 00:30:24 Epoch 203/400 (lr=1e-06), train loss 0.00103
2025-08-24 00:35:32 Epoch 204/400 (lr=1e-06), train loss 0.00106
2025-08-24 00:40:38 Epoch 205/400 (lr=1e-06), train loss 0.00101
2025-08-24 00:45:50 Epoch 206/400 (lr=1e-06), train loss 0.00103
2025-08-24 00:51:08 Epoch 207/400 (lr=1e-06), train loss 0.00102
2025-08-24 00:56:14 Epoch 208/400 (lr=1e-06), train loss 0.00100
2025-08-24 01:01:10 Epoch 209/400 (lr=1e-06), train loss 0.00097
2025-08-24 01:06:18 Training for epoch 210 done, starting evaluation
2025-08-24 01:06:28 Epoch 210 performance:
2025-08-24 01:06:28 metrics/test.rmse:  7.390
2025-08-24 01:06:28 metrics/test.rmse_pcutoff:2.984
2025-08-24 01:06:28 metrics/test.mAP:   95.029
2025-08-24 01:06:28 metrics/test.mAR:   96.000
2025-08-24 01:06:28 metrics/test.rmse_detections:7.390
2025-08-24 01:06:28 metrics/test.rmse_detections_pcutoff:2.984
2025-08-24 01:06:28 Epoch 210/400 (lr=1e-06), train loss 0.00099, valid loss 0.00141
2025-08-24 01:11:43 Epoch 211/400 (lr=1e-06), train loss 0.00101
2025-08-24 01:16:46 Epoch 212/400 (lr=1e-06), train loss 0.00099
2025-08-24 01:22:00 Epoch 213/400 (lr=1e-06), train loss 0.00099
2025-08-24 01:27:08 Epoch 214/400 (lr=1e-06), train loss 0.00098
2025-08-24 01:32:16 Epoch 215/400 (lr=1e-06), train loss 0.00094
2025-08-24 01:37:24 Epoch 216/400 (lr=1e-06), train loss 0.00100
2025-08-24 01:42:28 Epoch 217/400 (lr=1e-06), train loss 0.00099
2025-08-24 01:47:45 Epoch 218/400 (lr=1e-06), train loss 0.00095
2025-08-24 01:53:03 Epoch 219/400 (lr=1e-06), train loss 0.00096
2025-08-24 01:58:06 Training for epoch 220 done, starting evaluation
2025-08-24 01:58:15 Epoch 220 performance:
2025-08-24 01:58:15 metrics/test.rmse:  6.655
2025-08-24 01:58:15 metrics/test.rmse_pcutoff:3.005
2025-08-24 01:58:15 metrics/test.mAP:   95.424
2025-08-24 01:58:15 metrics/test.mAR:   96.333
2025-08-24 01:58:15 metrics/test.rmse_detections:6.655
2025-08-24 01:58:15 metrics/test.rmse_detections_pcutoff:3.005
2025-08-24 01:58:15 Epoch 220/400 (lr=1e-06), train loss 0.00103, valid loss 0.00139
2025-08-24 02:03:33 Epoch 221/400 (lr=1e-06), train loss 0.00098
2025-08-24 02:09:03 Epoch 222/400 (lr=1e-06), train loss 0.00098
2025-08-24 02:14:00 Epoch 223/400 (lr=1e-06), train loss 0.00094
2025-08-24 02:19:10 Epoch 224/400 (lr=1e-06), train loss 0.00095
2025-08-24 02:24:28 Epoch 225/400 (lr=1e-06), train loss 0.00097
2025-08-24 02:30:03 Epoch 226/400 (lr=1e-06), train loss 0.00096
2025-08-24 02:35:23 Epoch 227/400 (lr=1e-06), train loss 0.00094
2025-08-24 02:40:41 Epoch 228/400 (lr=1e-06), train loss 0.00094
2025-08-24 02:46:05 Epoch 229/400 (lr=1e-06), train loss 0.00092
2025-08-24 02:51:24 Training for epoch 230 done, starting evaluation
2025-08-24 02:51:35 Epoch 230 performance:
2025-08-24 02:51:35 metrics/test.rmse:  5.480
2025-08-24 02:51:35 metrics/test.rmse_pcutoff:3.348
2025-08-24 02:51:35 metrics/test.mAP:   95.693
2025-08-24 02:51:35 metrics/test.mAR:   96.667
2025-08-24 02:51:35 metrics/test.rmse_detections:5.480
2025-08-24 02:51:35 metrics/test.rmse_detections_pcutoff:3.348
2025-08-24 02:51:35 Epoch 230/400 (lr=1e-06), train loss 0.00093, valid loss 0.00138
2025-08-24 02:56:55 Epoch 231/400 (lr=1e-06), train loss 0.00095
2025-08-24 03:02:28 Epoch 232/400 (lr=1e-06), train loss 0.00094
2025-08-24 03:07:46 Epoch 233/400 (lr=1e-06), train loss 0.00092
2025-08-24 03:13:03 Epoch 234/400 (lr=1e-06), train loss 0.00098
2025-08-24 03:18:17 Epoch 235/400 (lr=1e-06), train loss 0.00099
2025-08-24 03:23:24 Epoch 236/400 (lr=1e-06), train loss 0.00095
2025-08-24 03:28:27 Epoch 237/400 (lr=1e-06), train loss 0.00095
2025-08-24 03:33:41 Epoch 238/400 (lr=1e-06), train loss 0.00092
2025-08-24 03:38:49 Epoch 239/400 (lr=1e-06), train loss 0.00093
2025-08-24 03:43:48 Training for epoch 240 done, starting evaluation
2025-08-24 03:43:57 Epoch 240 performance:
2025-08-24 03:43:57 metrics/test.rmse:  5.487
2025-08-24 03:43:57 metrics/test.rmse_pcutoff:3.360
2025-08-24 03:43:57 metrics/test.mAP:   95.688
2025-08-24 03:43:57 metrics/test.mAR:   96.667
2025-08-24 03:43:57 metrics/test.rmse_detections:5.487
2025-08-24 03:43:57 metrics/test.rmse_detections_pcutoff:3.360
2025-08-24 03:43:57 Epoch 240/400 (lr=1e-06), train loss 0.00095, valid loss 0.00137
2025-08-24 03:49:17 Epoch 241/400 (lr=1e-06), train loss 0.00096
2025-08-24 03:54:46 Epoch 242/400 (lr=1e-06), train loss 0.00090
2025-08-24 04:00:21 Epoch 243/400 (lr=1e-06), train loss 0.00094
2025-08-24 04:05:33 Epoch 244/400 (lr=1e-06), train loss 0.00092
2025-08-24 04:10:57 Epoch 245/400 (lr=1e-06), train loss 0.00094
2025-08-24 04:16:16 Epoch 246/400 (lr=1e-06), train loss 0.00093
2025-08-24 04:21:22 Epoch 247/400 (lr=1e-06), train loss 0.00092
2025-08-24 04:26:53 Epoch 248/400 (lr=1e-06), train loss 0.00096
2025-08-24 04:32:30 Epoch 249/400 (lr=1e-06), train loss 0.00093
2025-08-24 04:37:44 Training for epoch 250 done, starting evaluation
2025-08-24 04:37:53 Epoch 250 performance:
2025-08-24 04:37:53 metrics/test.rmse:  5.477
2025-08-24 04:37:53 metrics/test.rmse_pcutoff:3.366
2025-08-24 04:37:53 metrics/test.mAP:   95.709
2025-08-24 04:37:53 metrics/test.mAR:   96.667
2025-08-24 04:37:53 metrics/test.rmse_detections:5.477
2025-08-24 04:37:53 metrics/test.rmse_detections_pcutoff:3.366
2025-08-24 04:37:53 Epoch 250/400 (lr=1e-06), train loss 0.00094, valid loss 0.00136
2025-08-24 04:42:43 Epoch 251/400 (lr=1e-06), train loss 0.00091
2025-08-24 04:47:47 Epoch 252/400 (lr=1e-06), train loss 0.00088
2025-08-24 04:52:46 Epoch 253/400 (lr=1e-06), train loss 0.00090
2025-08-24 04:58:07 Epoch 254/400 (lr=1e-06), train loss 0.00093
2025-08-24 05:03:21 Epoch 255/400 (lr=1e-06), train loss 0.00091
2025-08-24 05:08:36 Epoch 256/400 (lr=1e-06), train loss 0.00094
2025-08-24 05:13:33 Epoch 257/400 (lr=1e-06), train loss 0.00091
2025-08-24 05:18:43 Epoch 258/400 (lr=1e-06), train loss 0.00091
2025-08-24 05:23:49 Epoch 259/400 (lr=1e-06), train loss 0.00096
2025-08-24 05:28:59 Training for epoch 260 done, starting evaluation
2025-08-24 05:29:08 Epoch 260 performance:
2025-08-24 05:29:08 metrics/test.rmse:  5.400
2025-08-24 05:29:08 metrics/test.rmse_pcutoff:3.357
2025-08-24 05:29:08 metrics/test.mAP:   95.716
2025-08-24 05:29:08 metrics/test.mAR:   96.667
2025-08-24 05:29:08 metrics/test.rmse_detections:5.400
2025-08-24 05:29:08 metrics/test.rmse_detections_pcutoff:3.357
2025-08-24 05:29:08 Epoch 260/400 (lr=1e-06), train loss 0.00091, valid loss 0.00136
2025-08-24 05:34:32 Epoch 261/400 (lr=1e-06), train loss 0.00092
2025-08-24 05:40:04 Epoch 262/400 (lr=1e-06), train loss 0.00093
2025-08-24 05:45:39 Epoch 263/400 (lr=1e-06), train loss 0.00091
2025-08-24 05:50:56 Epoch 264/400 (lr=1e-06), train loss 0.00094
2025-08-24 05:56:14 Epoch 265/400 (lr=1e-06), train loss 0.00092
2025-08-24 06:01:48 Epoch 266/400 (lr=1e-06), train loss 0.00088
2025-08-24 06:06:36 Epoch 267/400 (lr=1e-06), train loss 0.00092
2025-08-24 06:11:22 Epoch 268/400 (lr=1e-06), train loss 0.00093
2025-08-24 06:16:38 Epoch 269/400 (lr=1e-06), train loss 0.00092
2025-08-24 06:22:10 Training for epoch 270 done, starting evaluation
2025-08-24 06:22:19 Epoch 270 performance:
2025-08-24 06:22:19 metrics/test.rmse:  5.402
2025-08-24 06:22:19 metrics/test.rmse_pcutoff:3.365
2025-08-24 06:22:19 metrics/test.mAP:   95.715
2025-08-24 06:22:19 metrics/test.mAR:   96.667
2025-08-24 06:22:19 metrics/test.rmse_detections:5.402
2025-08-24 06:22:19 metrics/test.rmse_detections_pcutoff:3.365
2025-08-24 06:22:19 Epoch 270/400 (lr=1e-06), train loss 0.00089, valid loss 0.00135
2025-08-24 06:27:52 Epoch 271/400 (lr=1e-06), train loss 0.00091
2025-08-24 06:32:50 Epoch 272/400 (lr=1e-06), train loss 0.00093
2025-08-24 06:38:10 Epoch 273/400 (lr=1e-06), train loss 0.00088
2025-08-24 06:42:59 Epoch 274/400 (lr=1e-06), train loss 0.00091
2025-08-24 06:48:23 Epoch 275/400 (lr=1e-06), train loss 0.00093
2025-08-24 06:53:38 Epoch 276/400 (lr=1e-06), train loss 0.00089
2025-08-24 06:58:43 Epoch 277/400 (lr=1e-06), train loss 0.00091
2025-08-24 07:03:53 Epoch 278/400 (lr=1e-06), train loss 0.00091
2025-08-24 07:09:13 Epoch 279/400 (lr=1e-06), train loss 0.00088
2025-08-24 07:14:23 Training for epoch 280 done, starting evaluation
2025-08-24 07:14:32 Epoch 280 performance:
2025-08-24 07:14:32 metrics/test.rmse:  5.400
2025-08-24 07:14:32 metrics/test.rmse_pcutoff:3.364
2025-08-24 07:14:32 metrics/test.mAP:   95.696
2025-08-24 07:14:32 metrics/test.mAR:   96.667
2025-08-24 07:14:32 metrics/test.rmse_detections:5.400
2025-08-24 07:14:32 metrics/test.rmse_detections_pcutoff:3.364
2025-08-24 07:14:32 Epoch 280/400 (lr=1e-06), train loss 0.00091, valid loss 0.00135
2025-08-24 07:19:52 Epoch 281/400 (lr=1e-06), train loss 0.00088
2025-08-24 07:25:10 Epoch 282/400 (lr=1e-06), train loss 0.00086
2025-08-24 07:29:48 Epoch 283/400 (lr=1e-06), train loss 0.00087
2025-08-24 07:34:31 Epoch 284/400 (lr=1e-06), train loss 0.00089
2025-08-24 07:39:47 Epoch 285/400 (lr=1e-06), train loss 0.00087
2025-08-24 07:44:53 Epoch 286/400 (lr=1e-06), train loss 0.00087
2025-08-24 07:50:16 Epoch 287/400 (lr=1e-06), train loss 0.00088
2025-08-24 07:55:29 Epoch 288/400 (lr=1e-06), train loss 0.00087
2025-08-24 08:01:09 Epoch 289/400 (lr=1e-06), train loss 0.00086
2025-08-24 08:06:19 Training for epoch 290 done, starting evaluation
2025-08-24 08:06:27 Epoch 290 performance:
2025-08-24 08:06:27 metrics/test.rmse:  5.405
2025-08-24 08:06:27 metrics/test.rmse_pcutoff:3.370
2025-08-24 08:06:27 metrics/test.mAP:   95.750
2025-08-24 08:06:27 metrics/test.mAR:   96.667
2025-08-24 08:06:27 metrics/test.rmse_detections:5.405
2025-08-24 08:06:27 metrics/test.rmse_detections_pcutoff:3.370
2025-08-24 08:06:27 Epoch 290/400 (lr=1e-06), train loss 0.00085, valid loss 0.00135
2025-08-24 08:11:44 Epoch 291/400 (lr=1e-06), train loss 0.00088
2025-08-24 08:16:55 Epoch 292/400 (lr=1e-06), train loss 0.00083
2025-08-24 08:22:04 Epoch 293/400 (lr=1e-06), train loss 0.00086
2025-08-24 08:27:42 Epoch 294/400 (lr=1e-06), train loss 0.00090
2025-08-24 08:33:02 Epoch 295/400 (lr=1e-06), train loss 0.00087
2025-08-24 08:38:08 Epoch 296/400 (lr=1e-06), train loss 0.00089
2025-08-24 08:43:12 Epoch 297/400 (lr=1e-06), train loss 0.00083
2025-08-24 08:48:11 Epoch 298/400 (lr=1e-06), train loss 0.00089
2025-08-24 08:53:30 Epoch 299/400 (lr=1e-06), train loss 0.00090
2025-08-24 08:58:42 Training for epoch 300 done, starting evaluation
2025-08-24 08:58:51 Epoch 300 performance:
2025-08-24 08:58:51 metrics/test.rmse:  4.969
2025-08-24 08:58:51 metrics/test.rmse_pcutoff:3.375
2025-08-24 08:58:51 metrics/test.mAP:   96.020
2025-08-24 08:58:51 metrics/test.mAR:   97.000
2025-08-24 08:58:51 metrics/test.rmse_detections:4.969
2025-08-24 08:58:51 metrics/test.rmse_detections_pcutoff:3.375
2025-08-24 08:58:51 Epoch 300/400 (lr=1e-06), train loss 0.00089, valid loss 0.00134
2025-08-24 09:03:47 Epoch 301/400 (lr=1e-06), train loss 0.00087
2025-08-24 09:09:12 Epoch 302/400 (lr=1e-06), train loss 0.00085
2025-08-24 09:13:58 Epoch 303/400 (lr=1e-06), train loss 0.00087
2025-08-24 09:19:16 Epoch 304/400 (lr=1e-06), train loss 0.00088
2025-08-24 09:24:15 Epoch 305/400 (lr=1e-06), train loss 0.00087
2025-08-24 09:29:16 Epoch 306/400 (lr=1e-06), train loss 0.00085
2025-08-24 09:34:21 Epoch 307/400 (lr=1e-06), train loss 0.00090
2025-08-24 09:39:47 Epoch 308/400 (lr=1e-06), train loss 0.00087
2025-08-24 09:45:05 Epoch 309/400 (lr=1e-06), train loss 0.00086
2025-08-24 09:50:18 Training for epoch 310 done, starting evaluation
2025-08-24 09:50:27 Epoch 310 performance:
2025-08-24 09:50:27 metrics/test.rmse:  4.910
2025-08-24 09:50:27 metrics/test.rmse_pcutoff:3.385
2025-08-24 09:50:27 metrics/test.mAP:   96.058
2025-08-24 09:50:27 metrics/test.mAR:   97.000
2025-08-24 09:50:27 metrics/test.rmse_detections:4.910
2025-08-24 09:50:27 metrics/test.rmse_detections_pcutoff:3.385
2025-08-24 09:50:27 Epoch 310/400 (lr=1e-06), train loss 0.00086, valid loss 0.00134
2025-08-24 09:55:52 Epoch 311/400 (lr=1e-06), train loss 0.00087
2025-08-24 10:01:51 Epoch 312/400 (lr=1e-06), train loss 0.00084
2025-08-24 10:07:25 Epoch 313/400 (lr=1e-06), train loss 0.00087
2025-08-24 10:12:41 Epoch 314/400 (lr=1e-06), train loss 0.00084
2025-08-24 10:17:35 Epoch 315/400 (lr=1e-06), train loss 0.00081
2025-08-24 10:23:10 Epoch 316/400 (lr=1e-06), train loss 0.00087
2025-08-24 10:28:29 Epoch 317/400 (lr=1e-06), train loss 0.00087
2025-08-24 10:33:45 Epoch 318/400 (lr=1e-06), train loss 0.00088
2025-08-24 10:39:10 Epoch 319/400 (lr=1e-06), train loss 0.00088
2025-08-24 10:44:11 Training for epoch 320 done, starting evaluation
2025-08-24 10:44:20 Epoch 320 performance:
2025-08-24 10:44:20 metrics/test.rmse:  4.922
2025-08-24 10:44:20 metrics/test.rmse_pcutoff:3.394
2025-08-24 10:44:20 metrics/test.mAP:   96.046
2025-08-24 10:44:20 metrics/test.mAR:   97.000
2025-08-24 10:44:20 metrics/test.rmse_detections:4.922
2025-08-24 10:44:20 metrics/test.rmse_detections_pcutoff:3.394
2025-08-24 10:44:20 Epoch 320/400 (lr=1e-06), train loss 0.00085, valid loss 0.00134
2025-08-24 10:49:27 Epoch 321/400 (lr=1e-06), train loss 0.00084
2025-08-24 10:54:50 Epoch 322/400 (lr=1e-06), train loss 0.00090
2025-08-24 11:00:21 Epoch 323/400 (lr=1e-06), train loss 0.00085
2025-08-24 11:05:53 Epoch 324/400 (lr=1e-06), train loss 0.00084
2025-08-24 11:11:28 Epoch 325/400 (lr=1e-06), train loss 0.00087
2025-08-24 11:16:45 Epoch 326/400 (lr=1e-06), train loss 0.00085
2025-08-24 11:22:06 Epoch 327/400 (lr=1e-06), train loss 0.00087
2025-08-24 11:27:29 Epoch 328/400 (lr=1e-06), train loss 0.00091
2025-08-24 11:32:58 Epoch 329/400 (lr=1e-06), train loss 0.00087
2025-08-24 11:38:33 Training for epoch 330 done, starting evaluation
2025-08-24 11:38:42 Epoch 330 performance:
2025-08-24 11:38:42 metrics/test.rmse:  4.918
2025-08-24 11:38:42 metrics/test.rmse_pcutoff:3.404
2025-08-24 11:38:42 metrics/test.mAP:   96.034
2025-08-24 11:38:42 metrics/test.mAR:   97.000
2025-08-24 11:38:42 metrics/test.rmse_detections:4.918
2025-08-24 11:38:42 metrics/test.rmse_detections_pcutoff:3.404
2025-08-24 11:38:42 Epoch 330/400 (lr=1e-06), train loss 0.00083, valid loss 0.00134
2025-08-24 11:44:01 Epoch 331/400 (lr=1e-06), train loss 0.00086
2025-08-24 11:49:23 Epoch 332/400 (lr=1e-06), train loss 0.00084
2025-08-24 11:54:53 Epoch 333/400 (lr=1e-06), train loss 0.00085
2025-08-24 12:00:04 Epoch 334/400 (lr=1e-06), train loss 0.00083
2025-08-24 12:05:43 Epoch 335/400 (lr=1e-06), train loss 0.00082
2025-08-24 12:11:07 Epoch 336/400 (lr=1e-06), train loss 0.00082
2025-08-24 12:16:11 Epoch 337/400 (lr=1e-06), train loss 0.00084
2025-08-24 12:20:59 Epoch 338/400 (lr=1e-06), train loss 0.00083
2025-08-24 12:26:22 Epoch 339/400 (lr=1e-06), train loss 0.00084
2025-08-24 12:31:55 Training for epoch 340 done, starting evaluation
2025-08-24 12:32:04 Epoch 340 performance:
2025-08-24 12:32:04 metrics/test.rmse:  4.934
2025-08-24 12:32:04 metrics/test.rmse_pcutoff:3.416
2025-08-24 12:32:04 metrics/test.mAP:   96.031
2025-08-24 12:32:04 metrics/test.mAR:   97.000
2025-08-24 12:32:04 metrics/test.rmse_detections:4.934
2025-08-24 12:32:04 metrics/test.rmse_detections_pcutoff:3.416
2025-08-24 12:32:04 Epoch 340/400 (lr=1e-06), train loss 0.00087, valid loss 0.00134
2025-08-24 12:36:55 Epoch 341/400 (lr=1e-06), train loss 0.00085
2025-08-24 12:41:55 Epoch 342/400 (lr=1e-06), train loss 0.00085
2025-08-24 12:47:05 Epoch 343/400 (lr=1e-06), train loss 0.00084
2025-08-24 12:52:11 Epoch 344/400 (lr=1e-06), train loss 0.00083
2025-08-24 12:57:32 Epoch 345/400 (lr=1e-06), train loss 0.00082
2025-08-24 13:02:27 Epoch 346/400 (lr=1e-06), train loss 0.00083
2025-08-24 13:07:36 Epoch 347/400 (lr=1e-06), train loss 0.00087
2025-08-24 13:12:51 Epoch 348/400 (lr=1e-06), train loss 0.00082
2025-08-24 13:18:12 Epoch 349/400 (lr=1e-06), train loss 0.00085
2025-08-24 13:23:12 Training for epoch 350 done, starting evaluation
2025-08-24 13:23:21 Epoch 350 performance:
2025-08-24 13:23:21 metrics/test.rmse:  4.935
2025-08-24 13:23:21 metrics/test.rmse_pcutoff:3.418
2025-08-24 13:23:21 metrics/test.mAP:   96.013
2025-08-24 13:23:21 metrics/test.mAR:   97.000
2025-08-24 13:23:21 metrics/test.rmse_detections:4.935
2025-08-24 13:23:21 metrics/test.rmse_detections_pcutoff:3.418
2025-08-24 13:23:21 Epoch 350/400 (lr=1e-06), train loss 0.00082, valid loss 0.00134
2025-08-24 13:28:41 Epoch 351/400 (lr=1e-06), train loss 0.00083
2025-08-24 13:34:18 Epoch 352/400 (lr=1e-06), train loss 0.00086
2025-08-24 13:39:05 Epoch 353/400 (lr=1e-06), train loss 0.00085
2025-08-24 13:44:12 Epoch 354/400 (lr=1e-06), train loss 0.00081
2025-08-24 13:49:45 Epoch 355/400 (lr=1e-06), train loss 0.00082
2025-08-24 13:55:06 Epoch 356/400 (lr=1e-06), train loss 0.00080
2025-08-24 14:00:09 Epoch 357/400 (lr=1e-06), train loss 0.00084
2025-08-24 14:05:18 Epoch 358/400 (lr=1e-06), train loss 0.00083
2025-08-24 14:10:33 Epoch 359/400 (lr=1e-06), train loss 0.00086
2025-08-24 14:15:52 Training for epoch 360 done, starting evaluation
2025-08-24 14:16:02 Epoch 360 performance:
2025-08-24 14:16:02 metrics/test.rmse:  4.942
2025-08-24 14:16:02 metrics/test.rmse_pcutoff:3.429
2025-08-24 14:16:02 metrics/test.mAP:   96.042
2025-08-24 14:16:02 metrics/test.mAR:   97.000
2025-08-24 14:16:02 metrics/test.rmse_detections:4.942
2025-08-24 14:16:02 metrics/test.rmse_detections_pcutoff:3.429
2025-08-24 14:16:02 Epoch 360/400 (lr=1e-06), train loss 0.00079, valid loss 0.00134
2025-08-24 14:21:28 Epoch 361/400 (lr=1e-06), train loss 0.00082
2025-08-24 14:26:39 Epoch 362/400 (lr=1e-06), train loss 0.00081
2025-08-24 14:31:42 Epoch 363/400 (lr=1e-06), train loss 0.00087
2025-08-24 14:36:49 Epoch 364/400 (lr=1e-06), train loss 0.00082
2025-08-24 14:41:53 Epoch 365/400 (lr=1e-06), train loss 0.00081
2025-08-24 14:47:15 Epoch 366/400 (lr=1e-06), train loss 0.00088
2025-08-24 14:52:39 Epoch 367/400 (lr=1e-06), train loss 0.00083
2025-08-24 14:57:44 Epoch 368/400 (lr=1e-06), train loss 0.00081
2025-08-24 15:03:11 Epoch 369/400 (lr=1e-06), train loss 0.00082
2025-08-24 15:08:21 Training for epoch 370 done, starting evaluation
2025-08-24 15:08:30 Epoch 370 performance:
2025-08-24 15:08:30 metrics/test.rmse:  4.948
2025-08-24 15:08:30 metrics/test.rmse_pcutoff:3.429
2025-08-24 15:08:30 metrics/test.mAP:   96.024
2025-08-24 15:08:30 metrics/test.mAR:   97.000
2025-08-24 15:08:30 metrics/test.rmse_detections:4.948
2025-08-24 15:08:30 metrics/test.rmse_detections_pcutoff:3.429
2025-08-24 15:08:30 Epoch 370/400 (lr=1e-06), train loss 0.00079, valid loss 0.00134
2025-08-24 15:13:35 Epoch 371/400 (lr=1e-06), train loss 0.00082
2025-08-24 15:18:48 Epoch 372/400 (lr=1e-06), train loss 0.00082
2025-08-24 15:24:01 Epoch 373/400 (lr=1e-06), train loss 0.00083
2025-08-24 15:29:15 Epoch 374/400 (lr=1e-06), train loss 0.00086
2025-08-24 15:34:34 Epoch 375/400 (lr=1e-06), train loss 0.00082
2025-08-24 15:39:39 Epoch 376/400 (lr=1e-06), train loss 0.00083
2025-08-24 15:44:32 Epoch 377/400 (lr=1e-06), train loss 0.00083
2025-08-24 15:49:49 Epoch 378/400 (lr=1e-06), train loss 0.00084
2025-08-24 15:55:08 Epoch 379/400 (lr=1e-06), train loss 0.00082
2025-08-24 16:00:33 Training for epoch 380 done, starting evaluation
2025-08-24 16:00:42 Epoch 380 performance:
2025-08-24 16:00:42 metrics/test.rmse:  4.963
2025-08-24 16:00:42 metrics/test.rmse_pcutoff:3.437
2025-08-24 16:00:42 metrics/test.mAP:   96.009
2025-08-24 16:00:42 metrics/test.mAR:   97.000
2025-08-24 16:00:42 metrics/test.rmse_detections:4.963
2025-08-24 16:00:42 metrics/test.rmse_detections_pcutoff:3.437
2025-08-24 16:00:42 Epoch 380/400 (lr=1e-06), train loss 0.00080, valid loss 0.00134
2025-08-24 16:05:34 Epoch 381/400 (lr=1e-06), train loss 0.00082
2025-08-24 16:10:07 Epoch 382/400 (lr=1e-06), train loss 0.00081
2025-08-24 16:15:14 Epoch 383/400 (lr=1e-06), train loss 0.00083
2025-08-24 16:20:29 Epoch 384/400 (lr=1e-06), train loss 0.00081
2025-08-24 16:25:45 Epoch 385/400 (lr=1e-06), train loss 0.00083
2025-08-24 16:31:05 Epoch 386/400 (lr=1e-06), train loss 0.00081
2025-08-24 16:36:27 Epoch 387/400 (lr=1e-06), train loss 0.00078
2025-08-24 16:41:49 Epoch 388/400 (lr=1e-06), train loss 0.00081
2025-08-24 16:47:17 Epoch 389/400 (lr=1e-06), train loss 0.00078
2025-08-24 16:52:38 Training for epoch 390 done, starting evaluation
2025-08-24 16:52:46 Epoch 390 performance:
2025-08-24 16:52:46 metrics/test.rmse:  4.971
2025-08-24 16:52:46 metrics/test.rmse_pcutoff:3.448
2025-08-24 16:52:46 metrics/test.mAP:   96.028
2025-08-24 16:52:46 metrics/test.mAR:   97.000
2025-08-24 16:52:46 metrics/test.rmse_detections:4.971
2025-08-24 16:52:46 metrics/test.rmse_detections_pcutoff:3.448
2025-08-24 16:52:46 Epoch 390/400 (lr=1e-06), train loss 0.00081, valid loss 0.00134
2025-08-24 16:57:32 Epoch 391/400 (lr=1e-06), train loss 0.00080
2025-08-24 17:02:43 Epoch 392/400 (lr=1e-06), train loss 0.00082
2025-08-24 17:07:42 Epoch 393/400 (lr=1e-06), train loss 0.00078
2025-08-24 17:13:17 Epoch 394/400 (lr=1e-06), train loss 0.00079
2025-08-24 17:18:31 Epoch 395/400 (lr=1e-06), train loss 0.00082
2025-08-24 17:24:06 Epoch 396/400 (lr=1e-06), train loss 0.00079
2025-08-24 17:28:51 Epoch 397/400 (lr=1e-06), train loss 0.00084
2025-08-24 17:33:42 Epoch 398/400 (lr=1e-06), train loss 0.00082
2025-08-24 17:39:20 Epoch 399/400 (lr=1e-06), train loss 0.00082
2025-08-24 17:44:56 Training for epoch 400 done, starting evaluation
2025-08-24 17:45:05 Epoch 400 performance:
2025-08-24 17:45:05 metrics/test.rmse:  4.974
2025-08-24 17:45:05 metrics/test.rmse_pcutoff:3.451
2025-08-24 17:45:05 metrics/test.mAP:   96.014
2025-08-24 17:45:05 metrics/test.mAR:   97.000
2025-08-24 17:45:05 metrics/test.rmse_detections:4.974
2025-08-24 17:45:05 metrics/test.rmse_detections_pcutoff:3.451
2025-08-24 17:45:05 Epoch 400/400 (lr=1e-06), train loss 0.00080, valid loss 0.00134
2025-08-25 02:26:03 Training with configuration:
2025-08-25 02:26:04 data:
2025-08-25 02:26:04   colormode: RGB
2025-08-25 02:26:04   inference:
2025-08-25 02:26:04     normalize_images: True
2025-08-25 02:26:04   train:
2025-08-25 02:26:04     affine:
2025-08-25 02:26:04       p: 0.5
2025-08-25 02:26:04       rotation: 30
2025-08-25 02:26:04       scaling: [1.0, 1.0]
2025-08-25 02:26:04       translation: 0
2025-08-25 02:26:04     collate:
2025-08-25 02:26:04       type: ResizeFromDataSizeCollate
2025-08-25 02:26:04       min_scale: 0.4
2025-08-25 02:26:04       max_scale: 1.0
2025-08-25 02:26:04       min_short_side: 128
2025-08-25 02:26:04       max_short_side: 1152
2025-08-25 02:26:04       multiple_of: 32
2025-08-25 02:26:04       to_square: False
2025-08-25 02:26:04     covering: False
2025-08-25 02:26:04     gaussian_noise: 12.75
2025-08-25 02:26:04     hist_eq: False
2025-08-25 02:26:04     motion_blur: False
2025-08-25 02:26:04     normalize_images: True
2025-08-25 02:26:04 device: auto
2025-08-25 02:26:04 metadata:
2025-08-25 02:26:04   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-08-25 02:26:04   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-08-25 02:26:04   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-08-25 02:26:04   unique_bodyparts: []
2025-08-25 02:26:04   individuals: ['animal']
2025-08-25 02:26:04   with_identity: None
2025-08-25 02:26:04 method: bu
2025-08-25 02:26:04 model:
2025-08-25 02:26:04   backbone:
2025-08-25 02:26:04     type: ResNet
2025-08-25 02:26:04     model_name: resnet50_gn
2025-08-25 02:26:04     output_stride: 16
2025-08-25 02:26:04     freeze_bn_stats: True
2025-08-25 02:26:04     freeze_bn_weights: False
2025-08-25 02:26:04   backbone_output_channels: 2048
2025-08-25 02:26:04   heads:
2025-08-25 02:26:04     bodypart:
2025-08-25 02:26:04       type: HeatmapHead
2025-08-25 02:26:04       weight_init: normal
2025-08-25 02:26:04       predictor:
2025-08-25 02:26:04         type: HeatmapPredictor
2025-08-25 02:26:04         apply_sigmoid: False
2025-08-25 02:26:04         clip_scores: True
2025-08-25 02:26:04         location_refinement: True
2025-08-25 02:26:04         locref_std: 7.2801
2025-08-25 02:26:04       target_generator:
2025-08-25 02:26:04         type: HeatmapGaussianGenerator
2025-08-25 02:26:04         num_heatmaps: 9
2025-08-25 02:26:04         pos_dist_thresh: 17
2025-08-25 02:26:04         heatmap_mode: KEYPOINT
2025-08-25 02:26:04         generate_locref: True
2025-08-25 02:26:04         locref_std: 7.2801
2025-08-25 02:26:04       criterion:
2025-08-25 02:26:04         heatmap:
2025-08-25 02:26:04           type: WeightedMSECriterion
2025-08-25 02:26:04           weight: 1.0
2025-08-25 02:26:04         locref:
2025-08-25 02:26:04           type: WeightedHuberCriterion
2025-08-25 02:26:04           weight: 0.05
2025-08-25 02:26:04       heatmap_config:
2025-08-25 02:26:04         channels: [2048, 9]
2025-08-25 02:26:04         kernel_size: [3]
2025-08-25 02:26:04         strides: [2]
2025-08-25 02:26:04       locref_config:
2025-08-25 02:26:04         channels: [2048, 18]
2025-08-25 02:26:04         kernel_size: [3]
2025-08-25 02:26:04         strides: [2]
2025-08-25 02:26:04 net_type: resnet_50
2025-08-25 02:26:04 runner:
2025-08-25 02:26:04   type: PoseTrainingRunner
2025-08-25 02:26:04   gpus: None
2025-08-25 02:26:04   key_metric: test.mAP
2025-08-25 02:26:04   key_metric_asc: True
2025-08-25 02:26:04   eval_interval: 10
2025-08-25 02:26:04   optimizer:
2025-08-25 02:26:04     type: AdamW
2025-08-25 02:26:04     params:
2025-08-25 02:26:04       lr: 0.0001
2025-08-25 02:26:04   scheduler:
2025-08-25 02:26:04     type: StepLR
2025-08-25 02:26:04     params:
2025-08-25 02:26:04       step_size: 50
2025-08-25 02:26:04       gamma: 0.5
2025-08-25 02:26:04   snapshots:
2025-08-25 02:26:04     max_snapshots: 5
2025-08-25 02:26:04     save_epochs: 25
2025-08-25 02:26:04     save_optimizer_state: False
2025-08-25 02:26:04 train_settings:
2025-08-25 02:26:04   batch_size: 16
2025-08-25 02:26:04   dataloader_workers: 0
2025-08-25 02:26:04   dataloader_pin_memory: True
2025-08-25 02:26:04   display_iters: 500
2025-08-25 02:26:04   epochs: 400
2025-08-25 02:26:04   seed: 42
2025-08-25 02:26:04 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-08-25 02:26:04 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-08-25 02:26:06 Data Transforms:
2025-08-25 02:26:06   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-25 02:26:06   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-08-25 02:26:33 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-08-25 02:26:33 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-08-25 02:26:33 Using 1127 images and 60 for testing
2025-08-25 02:26:33 
Starting pose model training...
--------------------------------------------------
2025-08-25 02:32:27 Epoch 201/400 (lr=0.0001), train loss 0.00105
2025-08-25 02:38:00 Epoch 202/400 (lr=0.0001), train loss 0.00100
2025-08-25 02:43:26 Epoch 203/400 (lr=0.0001), train loss 0.00090
2025-08-25 02:49:04 Epoch 204/400 (lr=0.0001), train loss 0.00086
2025-08-25 02:54:33 Epoch 205/400 (lr=0.0001), train loss 0.00080
2025-08-25 02:59:50 Epoch 206/400 (lr=0.0001), train loss 0.00077
2025-08-25 03:05:28 Epoch 207/400 (lr=0.0001), train loss 0.00074
2025-08-25 03:10:59 Epoch 208/400 (lr=0.0001), train loss 0.00071
2025-08-25 03:16:32 Epoch 209/400 (lr=0.0001), train loss 0.00067
2025-08-25 03:22:07 Training for epoch 210 done, starting evaluation
2025-08-25 03:22:17 Epoch 210 performance:
2025-08-25 03:22:17 metrics/test.rmse:  6.653
2025-08-25 03:22:17 metrics/test.rmse_pcutoff:3.540
2025-08-25 03:22:17 metrics/test.mAP:   96.015
2025-08-25 03:22:17 metrics/test.mAR:   97.000
2025-08-25 03:22:17 metrics/test.rmse_detections:6.653
2025-08-25 03:22:17 metrics/test.rmse_detections_pcutoff:3.540
2025-08-25 03:22:17 Epoch 210/400 (lr=0.0001), train loss 0.00066, valid loss 0.00145
2025-08-25 03:27:51 Epoch 211/400 (lr=0.0001), train loss 0.00066
2025-08-25 03:33:16 Epoch 212/400 (lr=0.0001), train loss 0.00064
2025-08-25 03:38:48 Epoch 213/400 (lr=0.0001), train loss 0.00060
2025-08-25 03:44:15 Epoch 214/400 (lr=0.0001), train loss 0.00058
2025-08-25 03:49:39 Epoch 215/400 (lr=0.0001), train loss 0.00056
2025-08-25 03:55:11 Epoch 216/400 (lr=0.0001), train loss 0.00058
2025-08-25 04:00:31 Epoch 217/400 (lr=0.0001), train loss 0.00058
2025-08-25 04:05:33 Epoch 218/400 (lr=0.0001), train loss 0.00053
2025-08-25 04:10:58 Epoch 219/400 (lr=0.0001), train loss 0.00053
2025-08-25 04:16:31 Training for epoch 220 done, starting evaluation
2025-08-25 04:16:41 Epoch 220 performance:
2025-08-25 04:16:41 metrics/test.rmse:  4.622
2025-08-25 04:16:41 metrics/test.rmse_pcutoff:3.099
2025-08-25 04:16:41 metrics/test.mAP:   97.360
2025-08-25 04:16:41 metrics/test.mAR:   97.833
2025-08-25 04:16:41 metrics/test.rmse_detections:4.622
2025-08-25 04:16:41 metrics/test.rmse_detections_pcutoff:3.099
2025-08-25 04:16:41 Epoch 220/400 (lr=0.0001), train loss 0.00056, valid loss 0.00151
2025-08-25 04:22:24 Epoch 221/400 (lr=0.0001), train loss 0.00051
2025-08-25 04:28:05 Epoch 222/400 (lr=0.0001), train loss 0.00052
2025-08-25 04:33:46 Epoch 223/400 (lr=0.0001), train loss 0.00048
2025-08-25 04:39:09 Epoch 224/400 (lr=0.0001), train loss 0.00047
2025-08-25 04:44:43 Epoch 225/400 (lr=0.0001), train loss 0.00048
2025-08-25 04:50:15 Epoch 226/400 (lr=0.0001), train loss 0.00047
2025-08-25 04:55:50 Epoch 227/400 (lr=0.0001), train loss 0.00044
2025-08-25 05:01:09 Epoch 228/400 (lr=0.0001), train loss 0.00044
2025-08-25 05:06:53 Epoch 229/400 (lr=0.0001), train loss 0.00044
2025-08-25 05:12:38 Training for epoch 230 done, starting evaluation
2025-08-25 05:12:47 Epoch 230 performance:
2025-08-25 05:12:47 metrics/test.rmse:  4.525
2025-08-25 05:12:47 metrics/test.rmse_pcutoff:2.843
2025-08-25 05:12:47 metrics/test.mAP:   97.639
2025-08-25 05:12:47 metrics/test.mAR:   98.167
2025-08-25 05:12:47 metrics/test.rmse_detections:4.525
2025-08-25 05:12:47 metrics/test.rmse_detections_pcutoff:2.843
2025-08-25 05:12:47 Epoch 230/400 (lr=0.0001), train loss 0.00041, valid loss 0.00163
2025-08-25 05:18:30 Epoch 231/400 (lr=0.0001), train loss 0.00043
2025-08-25 05:24:10 Epoch 232/400 (lr=0.0001), train loss 0.00040
2025-08-25 05:29:43 Epoch 233/400 (lr=0.0001), train loss 0.00040
2025-08-25 05:35:30 Epoch 234/400 (lr=0.0001), train loss 0.00042
2025-08-25 05:41:11 Epoch 235/400 (lr=0.0001), train loss 0.00041
2025-08-25 05:46:55 Epoch 236/400 (lr=0.0001), train loss 0.00041
2025-08-25 05:52:10 Epoch 237/400 (lr=0.0001), train loss 0.00039
2025-08-25 05:57:44 Epoch 238/400 (lr=0.0001), train loss 0.00037
2025-08-25 06:03:07 Epoch 239/400 (lr=0.0001), train loss 0.00037
2025-08-25 06:08:33 Training for epoch 240 done, starting evaluation
2025-08-25 06:08:42 Epoch 240 performance:
2025-08-25 06:08:42 metrics/test.rmse:  5.003
2025-08-25 06:08:42 metrics/test.rmse_pcutoff:3.238
2025-08-25 06:08:42 metrics/test.mAP:   96.972
2025-08-25 06:08:42 metrics/test.mAR:   97.667
2025-08-25 06:08:42 metrics/test.rmse_detections:5.003
2025-08-25 06:08:42 metrics/test.rmse_detections_pcutoff:3.238
2025-08-25 06:08:42 Epoch 240/400 (lr=0.0001), train loss 0.00038, valid loss 0.00162
2025-08-25 06:14:18 Epoch 241/400 (lr=0.0001), train loss 0.00037
2025-08-25 06:19:45 Epoch 242/400 (lr=0.0001), train loss 0.00036
2025-08-25 06:25:19 Epoch 243/400 (lr=0.0001), train loss 0.00036
2025-08-25 06:30:35 Epoch 244/400 (lr=0.0001), train loss 0.00034
2025-08-25 06:35:42 Epoch 245/400 (lr=0.0001), train loss 0.00035
2025-08-25 06:41:15 Epoch 246/400 (lr=0.0001), train loss 0.00035
2025-08-25 06:46:40 Epoch 247/400 (lr=0.0001), train loss 0.00035
2025-08-25 06:52:02 Epoch 248/400 (lr=0.0001), train loss 0.00037
2025-08-25 06:57:21 Epoch 249/400 (lr=0.0001), train loss 0.00036
2025-08-25 07:02:35 Training for epoch 250 done, starting evaluation
2025-08-25 07:02:44 Epoch 250 performance:
2025-08-25 07:02:44 metrics/test.rmse:  4.700
2025-08-25 07:02:44 metrics/test.rmse_pcutoff:2.960
2025-08-25 07:02:44 metrics/test.mAP:   97.585
2025-08-25 07:02:44 metrics/test.mAR:   98.000
2025-08-25 07:02:44 metrics/test.rmse_detections:4.700
2025-08-25 07:02:44 metrics/test.rmse_detections_pcutoff:2.960
2025-08-25 07:02:44 Epoch 250/400 (lr=5e-05), train loss 0.00037, valid loss 0.00161
2025-08-25 07:08:14 Epoch 251/400 (lr=5e-05), train loss 0.00031
2025-08-25 07:13:43 Epoch 252/400 (lr=5e-05), train loss 0.00029
2025-08-25 07:18:51 Epoch 253/400 (lr=5e-05), train loss 0.00030
2025-08-25 07:24:30 Epoch 254/400 (lr=5e-05), train loss 0.00029
2025-08-25 07:29:40 Epoch 255/400 (lr=5e-05), train loss 0.00030
2025-08-25 07:35:12 Epoch 256/400 (lr=5e-05), train loss 0.00029
2025-08-25 07:40:33 Epoch 257/400 (lr=5e-05), train loss 0.00030
2025-08-25 07:45:53 Epoch 258/400 (lr=5e-05), train loss 0.00028
2025-08-25 07:51:07 Epoch 259/400 (lr=5e-05), train loss 0.00029
2025-08-25 07:56:15 Training for epoch 260 done, starting evaluation
2025-08-25 07:56:24 Epoch 260 performance:
2025-08-25 07:56:24 metrics/test.rmse:  4.996
2025-08-25 07:56:24 metrics/test.rmse_pcutoff:3.149
2025-08-25 07:56:24 metrics/test.mAP:   97.220
2025-08-25 07:56:24 metrics/test.mAR:   97.667
2025-08-25 07:56:24 metrics/test.rmse_detections:4.996
2025-08-25 07:56:24 metrics/test.rmse_detections_pcutoff:3.149
2025-08-25 07:56:24 Epoch 260/400 (lr=5e-05), train loss 0.00029, valid loss 0.00166
2025-08-25 08:01:54 Epoch 261/400 (lr=5e-05), train loss 0.00029
2025-08-25 08:07:36 Epoch 262/400 (lr=5e-05), train loss 0.00028
2025-08-25 08:12:50 Epoch 263/400 (lr=5e-05), train loss 0.00027
2025-08-25 08:18:13 Epoch 264/400 (lr=5e-05), train loss 0.00027
2025-08-25 08:23:26 Epoch 265/400 (lr=5e-05), train loss 0.00029
2025-08-25 08:29:07 Epoch 266/400 (lr=5e-05), train loss 0.00026
2025-08-25 08:34:22 Epoch 267/400 (lr=5e-05), train loss 0.00027
2025-08-25 08:39:40 Epoch 268/400 (lr=5e-05), train loss 0.00026
2025-08-25 08:45:16 Epoch 269/400 (lr=5e-05), train loss 0.00027
2025-08-25 08:50:40 Training for epoch 270 done, starting evaluation
2025-08-25 08:50:49 Epoch 270 performance:
2025-08-25 08:50:49 metrics/test.rmse:  4.949
2025-08-25 08:50:49 metrics/test.rmse_pcutoff:3.028
2025-08-25 08:50:49 metrics/test.mAP:   97.217
2025-08-25 08:50:49 metrics/test.mAR:   97.667
2025-08-25 08:50:49 metrics/test.rmse_detections:4.949
2025-08-25 08:50:49 metrics/test.rmse_detections_pcutoff:3.028
2025-08-25 08:50:49 Epoch 270/400 (lr=5e-05), train loss 0.00028, valid loss 0.00166
2025-08-25 08:56:01 Epoch 271/400 (lr=5e-05), train loss 0.00026
2025-08-25 09:01:21 Epoch 272/400 (lr=5e-05), train loss 0.00026
2025-08-25 09:06:29 Epoch 273/400 (lr=5e-05), train loss 0.00025
2025-08-25 09:11:30 Epoch 274/400 (lr=5e-05), train loss 0.00026
2025-08-25 09:16:37 Epoch 275/400 (lr=5e-05), train loss 0.00026
2025-08-25 09:21:43 Epoch 276/400 (lr=5e-05), train loss 0.00025
2025-08-25 09:27:12 Epoch 277/400 (lr=5e-05), train loss 0.00025
2025-08-25 09:32:18 Epoch 278/400 (lr=5e-05), train loss 0.00027
2025-08-25 09:37:10 Epoch 279/400 (lr=5e-05), train loss 0.00025
2025-08-25 09:42:20 Training for epoch 280 done, starting evaluation
2025-08-25 09:42:28 Epoch 280 performance:
2025-08-25 09:42:28 metrics/test.rmse:  4.956
2025-08-25 09:42:28 metrics/test.rmse_pcutoff:2.962
2025-08-25 09:42:28 metrics/test.mAP:   97.181
2025-08-25 09:42:28 metrics/test.mAR:   97.667
2025-08-25 09:42:28 metrics/test.rmse_detections:4.956
2025-08-25 09:42:28 metrics/test.rmse_detections_pcutoff:2.962
2025-08-25 09:42:28 Epoch 280/400 (lr=5e-05), train loss 0.00027, valid loss 0.00168
2025-08-25 09:47:31 Epoch 281/400 (lr=5e-05), train loss 0.00024
2025-08-25 09:52:59 Epoch 282/400 (lr=5e-05), train loss 0.00024
2025-08-25 09:58:29 Epoch 283/400 (lr=5e-05), train loss 0.00024
2025-08-25 10:03:43 Epoch 284/400 (lr=5e-05), train loss 0.00024
2025-08-25 10:09:18 Epoch 285/400 (lr=5e-05), train loss 0.00024
2025-08-25 10:14:51 Epoch 286/400 (lr=5e-05), train loss 0.00026
2025-08-25 10:20:38 Epoch 287/400 (lr=5e-05), train loss 0.00024
2025-08-25 10:26:19 Epoch 288/400 (lr=5e-05), train loss 0.00024
2025-08-25 10:31:24 Epoch 289/400 (lr=5e-05), train loss 0.00024
2025-08-25 10:36:43 Training for epoch 290 done, starting evaluation
2025-08-25 10:36:52 Epoch 290 performance:
2025-08-25 10:36:52 metrics/test.rmse:  4.827
2025-08-25 10:36:52 metrics/test.rmse_pcutoff:2.773
2025-08-25 10:36:52 metrics/test.mAP:   97.639
2025-08-25 10:36:52 metrics/test.mAR:   98.000
2025-08-25 10:36:52 metrics/test.rmse_detections:4.827
2025-08-25 10:36:52 metrics/test.rmse_detections_pcutoff:2.773
2025-08-25 10:36:52 Epoch 290/400 (lr=5e-05), train loss 0.00024, valid loss 0.00166
2025-08-25 10:42:10 Epoch 291/400 (lr=5e-05), train loss 0.00025
2025-08-25 10:47:30 Epoch 292/400 (lr=5e-05), train loss 0.00023
2025-08-25 10:52:38 Epoch 293/400 (lr=5e-05), train loss 0.00023
2025-08-25 10:58:00 Epoch 294/400 (lr=5e-05), train loss 0.00023
2025-08-25 11:03:40 Epoch 295/400 (lr=5e-05), train loss 0.00023
2025-08-25 11:09:15 Epoch 296/400 (lr=5e-05), train loss 0.00024
2025-08-25 11:14:52 Epoch 297/400 (lr=5e-05), train loss 0.00022
2025-08-25 11:20:31 Epoch 298/400 (lr=5e-05), train loss 0.00022
2025-08-25 11:25:54 Epoch 299/400 (lr=5e-05), train loss 0.00023
2025-08-25 11:31:29 Training for epoch 300 done, starting evaluation
2025-08-25 11:31:38 Epoch 300 performance:
2025-08-25 11:31:38 metrics/test.rmse:  4.606
2025-08-25 11:31:38 metrics/test.rmse_pcutoff:2.703
2025-08-25 11:31:38 metrics/test.mAP:   97.763
2025-08-25 11:31:38 metrics/test.mAR:   98.167
2025-08-25 11:31:38 metrics/test.rmse_detections:4.606
2025-08-25 11:31:38 metrics/test.rmse_detections_pcutoff:2.703
2025-08-25 11:31:39 Epoch 300/400 (lr=2.5e-05), train loss 0.00023, valid loss 0.00173
2025-08-25 11:37:18 Epoch 301/400 (lr=2.5e-05), train loss 0.00022
2025-08-25 11:42:56 Epoch 302/400 (lr=2.5e-05), train loss 0.00021
2025-08-25 11:48:35 Epoch 303/400 (lr=2.5e-05), train loss 0.00021
2025-08-25 11:54:09 Epoch 304/400 (lr=2.5e-05), train loss 0.00021
2025-08-25 11:59:46 Epoch 305/400 (lr=2.5e-05), train loss 0.00021
2025-08-25 12:05:19 Epoch 306/400 (lr=2.5e-05), train loss 0.00021
2025-08-25 12:10:58 Epoch 307/400 (lr=2.5e-05), train loss 0.00023
2025-08-25 12:16:27 Epoch 308/400 (lr=2.5e-05), train loss 0.00021
2025-08-25 12:22:21 Epoch 309/400 (lr=2.5e-05), train loss 0.00021
2025-08-25 12:28:14 Training for epoch 310 done, starting evaluation
2025-08-25 12:28:24 Epoch 310 performance:
2025-08-25 12:28:24 metrics/test.rmse:  4.521
2025-08-25 12:28:24 metrics/test.rmse_pcutoff:2.726
2025-08-25 12:28:24 metrics/test.mAP:   97.792
2025-08-25 12:28:24 metrics/test.mAR:   98.167
2025-08-25 12:28:24 metrics/test.rmse_detections:4.521
2025-08-25 12:28:24 metrics/test.rmse_detections_pcutoff:2.726
2025-08-25 12:28:24 Epoch 310/400 (lr=2.5e-05), train loss 0.00021, valid loss 0.00173
2025-08-25 12:34:11 Epoch 311/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 12:39:57 Epoch 312/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 12:45:28 Epoch 313/400 (lr=2.5e-05), train loss 0.00021
2025-08-25 12:51:16 Epoch 314/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 12:56:51 Epoch 315/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 13:02:27 Epoch 316/400 (lr=2.5e-05), train loss 0.00021
2025-08-25 13:08:02 Epoch 317/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 13:13:45 Epoch 318/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 13:19:04 Epoch 319/400 (lr=2.5e-05), train loss 0.00021
2025-08-25 13:24:26 Training for epoch 320 done, starting evaluation
2025-08-25 13:24:35 Epoch 320 performance:
2025-08-25 13:24:35 metrics/test.rmse:  5.626
2025-08-25 13:24:35 metrics/test.rmse_pcutoff:2.721
2025-08-25 13:24:35 metrics/test.mAP:   97.330
2025-08-25 13:24:35 metrics/test.mAR:   97.833
2025-08-25 13:24:35 metrics/test.rmse_detections:5.626
2025-08-25 13:24:35 metrics/test.rmse_detections_pcutoff:2.721
2025-08-25 13:24:35 Epoch 320/400 (lr=2.5e-05), train loss 0.00020, valid loss 0.00173
2025-08-25 13:30:07 Epoch 321/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 13:35:55 Epoch 322/400 (lr=2.5e-05), train loss 0.00021
2025-08-25 13:41:38 Epoch 323/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 13:47:12 Epoch 324/400 (lr=2.5e-05), train loss 0.00021
2025-08-25 13:52:35 Epoch 325/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 13:57:42 Epoch 326/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 14:02:57 Epoch 327/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 14:08:33 Epoch 328/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 14:14:08 Epoch 329/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 14:19:44 Training for epoch 330 done, starting evaluation
2025-08-25 14:19:53 Epoch 330 performance:
2025-08-25 14:19:53 metrics/test.rmse:  4.349
2025-08-25 14:19:53 metrics/test.rmse_pcutoff:2.943
2025-08-25 14:19:53 metrics/test.mAP:   97.950
2025-08-25 14:19:53 metrics/test.mAR:   98.333
2025-08-25 14:19:53 metrics/test.rmse_detections:4.349
2025-08-25 14:19:53 metrics/test.rmse_detections_pcutoff:2.943
2025-08-25 14:19:53 Epoch 330/400 (lr=2.5e-05), train loss 0.00020, valid loss 0.00172
2025-08-25 14:25:09 Epoch 331/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 14:30:21 Epoch 332/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 14:35:33 Epoch 333/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 14:40:31 Epoch 334/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 14:45:47 Epoch 335/400 (lr=2.5e-05), train loss 0.00018
2025-08-25 14:50:56 Epoch 336/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 14:55:37 Epoch 337/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 15:00:48 Epoch 338/400 (lr=2.5e-05), train loss 0.00020
2025-08-25 15:05:51 Epoch 339/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 15:10:57 Training for epoch 340 done, starting evaluation
2025-08-25 15:11:06 Epoch 340 performance:
2025-08-25 15:11:06 metrics/test.rmse:  6.049
2025-08-25 15:11:06 metrics/test.rmse_pcutoff:3.192
2025-08-25 15:11:06 metrics/test.mAP:   96.853
2025-08-25 15:11:06 metrics/test.mAR:   97.333
2025-08-25 15:11:06 metrics/test.rmse_detections:6.049
2025-08-25 15:11:06 metrics/test.rmse_detections_pcutoff:3.192
2025-08-25 15:11:06 Epoch 340/400 (lr=2.5e-05), train loss 0.00021, valid loss 0.00172
2025-08-25 15:16:27 Epoch 341/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 15:21:55 Epoch 342/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 15:27:26 Epoch 343/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 15:32:58 Epoch 344/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 15:38:23 Epoch 345/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 15:43:50 Epoch 346/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 15:49:19 Epoch 347/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 15:54:55 Epoch 348/400 (lr=2.5e-05), train loss 0.00018
2025-08-25 16:00:32 Epoch 349/400 (lr=2.5e-05), train loss 0.00019
2025-08-25 16:05:44 Training for epoch 350 done, starting evaluation
2025-08-25 16:05:53 Epoch 350 performance:
2025-08-25 16:05:53 metrics/test.rmse:  4.966
2025-08-25 16:05:53 metrics/test.rmse_pcutoff:3.048
2025-08-25 16:05:53 metrics/test.mAP:   97.232
2025-08-25 16:05:53 metrics/test.mAR:   97.667
2025-08-25 16:05:53 metrics/test.rmse_detections:4.966
2025-08-25 16:05:53 metrics/test.rmse_detections_pcutoff:3.048
2025-08-25 16:05:53 Epoch 350/400 (lr=1.25e-05), train loss 0.00018, valid loss 0.00174
2025-08-25 16:11:14 Epoch 351/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 16:16:57 Epoch 352/400 (lr=1.25e-05), train loss 0.00019
2025-08-25 16:22:21 Epoch 353/400 (lr=1.25e-05), train loss 0.00019
2025-08-25 16:27:46 Epoch 354/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 16:33:10 Epoch 355/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 16:38:26 Epoch 356/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 16:43:56 Epoch 357/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 16:49:33 Epoch 358/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 16:55:11 Epoch 359/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 17:00:53 Training for epoch 360 done, starting evaluation
2025-08-25 17:01:02 Epoch 360 performance:
2025-08-25 17:01:02 metrics/test.rmse:  4.957
2025-08-25 17:01:02 metrics/test.rmse_pcutoff:3.192
2025-08-25 17:01:02 metrics/test.mAP:   97.197
2025-08-25 17:01:02 metrics/test.mAR:   97.667
2025-08-25 17:01:02 metrics/test.rmse_detections:4.957
2025-08-25 17:01:02 metrics/test.rmse_detections_pcutoff:3.192
2025-08-25 17:01:02 Epoch 360/400 (lr=1.25e-05), train loss 0.00018, valid loss 0.00174
2025-08-25 17:06:52 Epoch 361/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 17:12:30 Epoch 362/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 17:18:00 Epoch 363/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 17:23:29 Epoch 364/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 17:28:59 Epoch 365/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 17:34:51 Epoch 366/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 17:40:33 Epoch 367/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 17:45:52 Epoch 368/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 17:51:34 Epoch 369/400 (lr=1.25e-05), train loss 0.00016
2025-08-25 17:57:03 Training for epoch 370 done, starting evaluation
2025-08-25 17:57:12 Epoch 370 performance:
2025-08-25 17:57:12 metrics/test.rmse:  4.517
2025-08-25 17:57:12 metrics/test.rmse_pcutoff:2.738
2025-08-25 17:57:12 metrics/test.mAP:   97.812
2025-08-25 17:57:12 metrics/test.mAR:   98.167
2025-08-25 17:57:12 metrics/test.rmse_detections:4.517
2025-08-25 17:57:12 metrics/test.rmse_detections_pcutoff:2.738
2025-08-25 17:57:12 Epoch 370/400 (lr=1.25e-05), train loss 0.00017, valid loss 0.00174
2025-08-25 18:02:49 Epoch 371/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 18:08:05 Epoch 372/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 18:13:37 Epoch 373/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 18:19:12 Epoch 374/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 18:24:45 Epoch 375/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 18:30:26 Epoch 376/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 18:36:00 Epoch 377/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 18:41:46 Epoch 378/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 18:47:09 Epoch 379/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 18:52:53 Training for epoch 380 done, starting evaluation
2025-08-25 18:53:03 Epoch 380 performance:
2025-08-25 18:53:03 metrics/test.rmse:  4.519
2025-08-25 18:53:03 metrics/test.rmse_pcutoff:2.747
2025-08-25 18:53:03 metrics/test.mAP:   97.803
2025-08-25 18:53:03 metrics/test.mAR:   98.167
2025-08-25 18:53:03 metrics/test.rmse_detections:4.519
2025-08-25 18:53:03 metrics/test.rmse_detections_pcutoff:2.747
2025-08-25 18:53:03 Epoch 380/400 (lr=1.25e-05), train loss 0.00016, valid loss 0.00173
2025-08-25 18:58:34 Epoch 381/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 19:04:22 Epoch 382/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 19:09:48 Epoch 383/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 19:14:56 Epoch 384/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 19:20:48 Epoch 385/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 19:26:26 Epoch 386/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 19:31:54 Epoch 387/400 (lr=1.25e-05), train loss 0.00016
2025-08-25 19:37:04 Epoch 388/400 (lr=1.25e-05), train loss 0.00018
2025-08-25 19:42:07 Epoch 389/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 19:47:23 Training for epoch 390 done, starting evaluation
2025-08-25 19:47:32 Epoch 390 performance:
2025-08-25 19:47:32 metrics/test.rmse:  4.539
2025-08-25 19:47:32 metrics/test.rmse_pcutoff:2.697
2025-08-25 19:47:32 metrics/test.mAP:   97.806
2025-08-25 19:47:32 metrics/test.mAR:   98.167
2025-08-25 19:47:32 metrics/test.rmse_detections:4.539
2025-08-25 19:47:32 metrics/test.rmse_detections_pcutoff:2.697
2025-08-25 19:47:32 Epoch 390/400 (lr=1.25e-05), train loss 0.00017, valid loss 0.00175
2025-08-25 19:53:01 Epoch 391/400 (lr=1.25e-05), train loss 0.00019
2025-08-25 19:58:33 Epoch 392/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 20:03:48 Epoch 393/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 20:09:37 Epoch 394/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 20:15:06 Epoch 395/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 20:20:54 Epoch 396/400 (lr=1.25e-05), train loss 0.00015
2025-08-25 20:26:34 Epoch 397/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 20:32:04 Epoch 398/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 20:37:21 Epoch 399/400 (lr=1.25e-05), train loss 0.00017
2025-08-25 20:42:34 Training for epoch 400 done, starting evaluation
2025-08-25 20:42:42 Epoch 400 performance:
2025-08-25 20:42:42 metrics/test.rmse:  5.625
2025-08-25 20:42:42 metrics/test.rmse_pcutoff:2.750
2025-08-25 20:42:42 metrics/test.mAP:   97.380
2025-08-25 20:42:42 metrics/test.mAR:   97.833
2025-08-25 20:42:42 metrics/test.rmse_detections:5.625
2025-08-25 20:42:42 metrics/test.rmse_detections_pcutoff:2.750
2025-08-25 20:42:43 Epoch 400/400 (lr=6.25e-06), train loss 0.00016, valid loss 0.00175
2025-10-03 21:02:57 Training with configuration:
2025-10-03 21:02:57 data:
2025-10-03 21:02:57   colormode: RGB
2025-10-03 21:02:57   inference:
2025-10-03 21:02:57     normalize_images: True
2025-10-03 21:02:57   train:
2025-10-03 21:02:57     affine:
2025-10-03 21:02:57       p: 0.5
2025-10-03 21:02:57       rotation: 30
2025-10-03 21:02:57       scaling: [1.0, 1.0]
2025-10-03 21:02:57       translation: 0
2025-10-03 21:02:57     collate:
2025-10-03 21:02:57       type: ResizeFromDataSizeCollate
2025-10-03 21:02:57       min_scale: 0.4
2025-10-03 21:02:57       max_scale: 1.0
2025-10-03 21:02:57       min_short_side: 128
2025-10-03 21:02:57       max_short_side: 1152
2025-10-03 21:02:57       multiple_of: 32
2025-10-03 21:02:57       to_square: False
2025-10-03 21:02:57     covering: False
2025-10-03 21:02:57     gaussian_noise: 12.75
2025-10-03 21:02:57     hist_eq: False
2025-10-03 21:02:57     motion_blur: False
2025-10-03 21:02:57     normalize_images: True
2025-10-03 21:02:57 device: auto
2025-10-03 21:02:57 metadata:
2025-10-03 21:02:57   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-10-03 21:02:57   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-10-03 21:02:57   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-10-03 21:02:57   unique_bodyparts: []
2025-10-03 21:02:57   individuals: ['animal']
2025-10-03 21:02:57   with_identity: None
2025-10-03 21:02:57 method: bu
2025-10-03 21:02:57 model:
2025-10-03 21:02:57   backbone:
2025-10-03 21:02:57     type: ResNet
2025-10-03 21:02:57     model_name: resnet50_gn
2025-10-03 21:02:57     output_stride: 16
2025-10-03 21:02:57     freeze_bn_stats: True
2025-10-03 21:02:57     freeze_bn_weights: False
2025-10-03 21:02:57   backbone_output_channels: 2048
2025-10-03 21:02:57   heads:
2025-10-03 21:02:57     bodypart:
2025-10-03 21:02:57       type: HeatmapHead
2025-10-03 21:02:57       weight_init: normal
2025-10-03 21:02:57       predictor:
2025-10-03 21:02:57         type: HeatmapPredictor
2025-10-03 21:02:57         apply_sigmoid: False
2025-10-03 21:02:57         clip_scores: True
2025-10-03 21:02:57         location_refinement: True
2025-10-03 21:02:57         locref_std: 7.2801
2025-10-03 21:02:57       target_generator:
2025-10-03 21:02:57         type: HeatmapGaussianGenerator
2025-10-03 21:02:57         num_heatmaps: 9
2025-10-03 21:02:57         pos_dist_thresh: 17
2025-10-03 21:02:57         heatmap_mode: KEYPOINT
2025-10-03 21:02:57         generate_locref: True
2025-10-03 21:02:57         locref_std: 7.2801
2025-10-03 21:02:57       criterion:
2025-10-03 21:02:57         heatmap:
2025-10-03 21:02:57           type: WeightedMSECriterion
2025-10-03 21:02:57           weight: 1.0
2025-10-03 21:02:57         locref:
2025-10-03 21:02:57           type: WeightedHuberCriterion
2025-10-03 21:02:57           weight: 0.05
2025-10-03 21:02:57       heatmap_config:
2025-10-03 21:02:57         channels: [2048, 9]
2025-10-03 21:02:57         kernel_size: [3]
2025-10-03 21:02:57         strides: [2]
2025-10-03 21:02:57       locref_config:
2025-10-03 21:02:57         channels: [2048, 18]
2025-10-03 21:02:57         kernel_size: [3]
2025-10-03 21:02:57         strides: [2]
2025-10-03 21:02:57 net_type: resnet_50
2025-10-03 21:02:57 runner:
2025-10-03 21:02:57   type: PoseTrainingRunner
2025-10-03 21:02:57   gpus: None
2025-10-03 21:02:57   key_metric: test.mAP
2025-10-03 21:02:57   key_metric_asc: True
2025-10-03 21:02:57   eval_interval: 10
2025-10-03 21:02:57   optimizer:
2025-10-03 21:02:57     type: AdamW
2025-10-03 21:02:57     params:
2025-10-03 21:02:57       lr: 0.0001
2025-10-03 21:02:57   scheduler:
2025-10-03 21:02:57     type: StepLR
2025-10-03 21:02:57     params:
2025-10-03 21:02:57       step_size: 50
2025-10-03 21:02:57       gamma: 0.5
2025-10-03 21:02:57   snapshots:
2025-10-03 21:02:57     max_snapshots: 5
2025-10-03 21:02:57     save_epochs: 25
2025-10-03 21:02:57     save_optimizer_state: False
2025-10-03 21:02:57 train_settings:
2025-10-03 21:02:57   batch_size: 16
2025-10-03 21:02:57   dataloader_workers: 0
2025-10-03 21:02:57   dataloader_pin_memory: True
2025-10-03 21:02:57   display_iters: 500
2025-10-03 21:02:57   epochs: 400
2025-10-03 21:02:57   seed: 42
2025-10-03 21:02:57 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-10-03 21:02:57 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-10-03 21:03:00 Data Transforms:
2025-10-03 21:03:00   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-03 21:03:00   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-03 21:03:27 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-10-03 21:03:27 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-10-03 21:03:27 Using 1127 images and 60 for testing
2025-10-03 21:03:27 
Starting pose model training...
--------------------------------------------------
2025-10-03 21:04:12 Training with configuration:
2025-10-03 21:04:12 data:
2025-10-03 21:04:12   colormode: RGB
2025-10-03 21:04:12   inference:
2025-10-03 21:04:12     normalize_images: True
2025-10-03 21:04:12   train:
2025-10-03 21:04:12     affine:
2025-10-03 21:04:12       p: 0.5
2025-10-03 21:04:12       rotation: 30
2025-10-03 21:04:12       scaling: [1.0, 1.0]
2025-10-03 21:04:12       translation: 0
2025-10-03 21:04:12     collate:
2025-10-03 21:04:12       type: ResizeFromDataSizeCollate
2025-10-03 21:04:12       min_scale: 0.4
2025-10-03 21:04:12       max_scale: 1.0
2025-10-03 21:04:12       min_short_side: 128
2025-10-03 21:04:12       max_short_side: 1152
2025-10-03 21:04:12       multiple_of: 32
2025-10-03 21:04:12       to_square: False
2025-10-03 21:04:12     covering: False
2025-10-03 21:04:12     gaussian_noise: 12.75
2025-10-03 21:04:12     hist_eq: False
2025-10-03 21:04:12     motion_blur: False
2025-10-03 21:04:12     normalize_images: True
2025-10-03 21:04:12 device: auto
2025-10-03 21:04:12 metadata:
2025-10-03 21:04:12   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-10-03 21:04:12   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-10-03 21:04:12   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-10-03 21:04:12   unique_bodyparts: []
2025-10-03 21:04:12   individuals: ['animal']
2025-10-03 21:04:12   with_identity: None
2025-10-03 21:04:12 method: bu
2025-10-03 21:04:12 model:
2025-10-03 21:04:12   backbone:
2025-10-03 21:04:12     type: ResNet
2025-10-03 21:04:12     model_name: resnet50_gn
2025-10-03 21:04:12     output_stride: 16
2025-10-03 21:04:12     freeze_bn_stats: True
2025-10-03 21:04:12     freeze_bn_weights: False
2025-10-03 21:04:12   backbone_output_channels: 2048
2025-10-03 21:04:12   heads:
2025-10-03 21:04:12     bodypart:
2025-10-03 21:04:12       type: HeatmapHead
2025-10-03 21:04:12       weight_init: normal
2025-10-03 21:04:12       predictor:
2025-10-03 21:04:12         type: HeatmapPredictor
2025-10-03 21:04:12         apply_sigmoid: False
2025-10-03 21:04:12         clip_scores: True
2025-10-03 21:04:12         location_refinement: True
2025-10-03 21:04:12         locref_std: 7.2801
2025-10-03 21:04:12       target_generator:
2025-10-03 21:04:12         type: HeatmapGaussianGenerator
2025-10-03 21:04:12         num_heatmaps: 9
2025-10-03 21:04:12         pos_dist_thresh: 17
2025-10-03 21:04:12         heatmap_mode: KEYPOINT
2025-10-03 21:04:12         generate_locref: True
2025-10-03 21:04:12         locref_std: 7.2801
2025-10-03 21:04:12       criterion:
2025-10-03 21:04:12         heatmap:
2025-10-03 21:04:12           type: WeightedMSECriterion
2025-10-03 21:04:12           weight: 1.0
2025-10-03 21:04:12         locref:
2025-10-03 21:04:12           type: WeightedHuberCriterion
2025-10-03 21:04:12           weight: 0.05
2025-10-03 21:04:12       heatmap_config:
2025-10-03 21:04:12         channels: [2048, 9]
2025-10-03 21:04:12         kernel_size: [3]
2025-10-03 21:04:12         strides: [2]
2025-10-03 21:04:12       locref_config:
2025-10-03 21:04:12         channels: [2048, 18]
2025-10-03 21:04:12         kernel_size: [3]
2025-10-03 21:04:12         strides: [2]
2025-10-03 21:04:12 net_type: resnet_50
2025-10-03 21:04:12 runner:
2025-10-03 21:04:12   type: PoseTrainingRunner
2025-10-03 21:04:12   gpus: None
2025-10-03 21:04:12   key_metric: test.mAP
2025-10-03 21:04:12   key_metric_asc: True
2025-10-03 21:04:12   eval_interval: 10
2025-10-03 21:04:12   optimizer:
2025-10-03 21:04:12     type: AdamW
2025-10-03 21:04:12     params:
2025-10-03 21:04:12       lr: 0.0001
2025-10-03 21:04:12   scheduler:
2025-10-03 21:04:12     type: StepLR
2025-10-03 21:04:12     params:
2025-10-03 21:04:12       step_size: 50
2025-10-03 21:04:12       gamma: 0.5
2025-10-03 21:04:12   snapshots:
2025-10-03 21:04:12     max_snapshots: 5
2025-10-03 21:04:12     save_epochs: 25
2025-10-03 21:04:12     save_optimizer_state: False
2025-10-03 21:04:12 train_settings:
2025-10-03 21:04:12   batch_size: 16
2025-10-03 21:04:12   dataloader_workers: 0
2025-10-03 21:04:12   dataloader_pin_memory: True
2025-10-03 21:04:12   display_iters: 500
2025-10-03 21:04:12   epochs: 400
2025-10-03 21:04:12   seed: 42
2025-10-03 21:04:12 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-10-03 21:04:12 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-10-03 21:04:14 Data Transforms:
2025-10-03 21:04:14   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-03 21:04:14   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-03 21:04:16 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-10-03 21:04:16 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-10-03 21:04:16 Using 1127 images and 60 for testing
2025-10-03 21:04:16 
Starting pose model training...
--------------------------------------------------
2025-10-03 21:04:43 Training with configuration:
2025-10-03 21:04:43 data:
2025-10-03 21:04:43   colormode: RGB
2025-10-03 21:04:43   inference:
2025-10-03 21:04:43     normalize_images: True
2025-10-03 21:04:43   train:
2025-10-03 21:04:43     affine:
2025-10-03 21:04:43       p: 0.5
2025-10-03 21:04:43       rotation: 30
2025-10-03 21:04:43       scaling: [1.0, 1.0]
2025-10-03 21:04:43       translation: 0
2025-10-03 21:04:43     collate:
2025-10-03 21:04:43       type: ResizeFromDataSizeCollate
2025-10-03 21:04:43       min_scale: 0.4
2025-10-03 21:04:43       max_scale: 1.0
2025-10-03 21:04:43       min_short_side: 128
2025-10-03 21:04:43       max_short_side: 1152
2025-10-03 21:04:43       multiple_of: 32
2025-10-03 21:04:43       to_square: False
2025-10-03 21:04:43     covering: False
2025-10-03 21:04:43     gaussian_noise: 12.75
2025-10-03 21:04:43     hist_eq: False
2025-10-03 21:04:43     motion_blur: False
2025-10-03 21:04:43     normalize_images: True
2025-10-03 21:04:43 device: auto
2025-10-03 21:04:43 metadata:
2025-10-03 21:04:43   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-10-03 21:04:43   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-10-03 21:04:43   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-10-03 21:04:43   unique_bodyparts: []
2025-10-03 21:04:43   individuals: ['animal']
2025-10-03 21:04:43   with_identity: None
2025-10-03 21:04:43 method: bu
2025-10-03 21:04:43 model:
2025-10-03 21:04:43   backbone:
2025-10-03 21:04:43     type: ResNet
2025-10-03 21:04:43     model_name: resnet50_gn
2025-10-03 21:04:43     output_stride: 16
2025-10-03 21:04:43     freeze_bn_stats: True
2025-10-03 21:04:43     freeze_bn_weights: False
2025-10-03 21:04:43   backbone_output_channels: 2048
2025-10-03 21:04:43   heads:
2025-10-03 21:04:43     bodypart:
2025-10-03 21:04:43       type: HeatmapHead
2025-10-03 21:04:43       weight_init: normal
2025-10-03 21:04:43       predictor:
2025-10-03 21:04:43         type: HeatmapPredictor
2025-10-03 21:04:43         apply_sigmoid: False
2025-10-03 21:04:43         clip_scores: True
2025-10-03 21:04:43         location_refinement: True
2025-10-03 21:04:43         locref_std: 7.2801
2025-10-03 21:04:43       target_generator:
2025-10-03 21:04:43         type: HeatmapGaussianGenerator
2025-10-03 21:04:43         num_heatmaps: 9
2025-10-03 21:04:43         pos_dist_thresh: 17
2025-10-03 21:04:43         heatmap_mode: KEYPOINT
2025-10-03 21:04:43         generate_locref: True
2025-10-03 21:04:43         locref_std: 7.2801
2025-10-03 21:04:43       criterion:
2025-10-03 21:04:43         heatmap:
2025-10-03 21:04:43           type: WeightedMSECriterion
2025-10-03 21:04:43           weight: 1.0
2025-10-03 21:04:43         locref:
2025-10-03 21:04:43           type: WeightedHuberCriterion
2025-10-03 21:04:43           weight: 0.05
2025-10-03 21:04:43       heatmap_config:
2025-10-03 21:04:43         channels: [2048, 9]
2025-10-03 21:04:43         kernel_size: [3]
2025-10-03 21:04:43         strides: [2]
2025-10-03 21:04:43       locref_config:
2025-10-03 21:04:43         channels: [2048, 18]
2025-10-03 21:04:43         kernel_size: [3]
2025-10-03 21:04:43         strides: [2]
2025-10-03 21:04:43 net_type: resnet_50
2025-10-03 21:04:43 runner:
2025-10-03 21:04:43   type: PoseTrainingRunner
2025-10-03 21:04:43   gpus: None
2025-10-03 21:04:43   key_metric: test.mAP
2025-10-03 21:04:43   key_metric_asc: True
2025-10-03 21:04:43   eval_interval: 10
2025-10-03 21:04:43   optimizer:
2025-10-03 21:04:43     type: AdamW
2025-10-03 21:04:43     params:
2025-10-03 21:04:43       lr: 0.0001
2025-10-03 21:04:43   scheduler:
2025-10-03 21:04:43     type: StepLR
2025-10-03 21:04:43     params:
2025-10-03 21:04:43       step_size: 50
2025-10-03 21:04:43       gamma: 0.5
2025-10-03 21:04:43   snapshots:
2025-10-03 21:04:43     max_snapshots: 5
2025-10-03 21:04:43     save_epochs: 25
2025-10-03 21:04:43     save_optimizer_state: False
2025-10-03 21:04:43 train_settings:
2025-10-03 21:04:43   batch_size: 16
2025-10-03 21:04:43   dataloader_workers: 0
2025-10-03 21:04:43   dataloader_pin_memory: True
2025-10-03 21:04:43   display_iters: 500
2025-10-03 21:04:43   epochs: 400
2025-10-03 21:04:43   seed: 42
2025-10-03 21:04:44 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-10-03 21:04:44 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-10-03 21:04:46 Data Transforms:
2025-10-03 21:04:46   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-03 21:04:46   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-03 21:04:47 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-10-03 21:04:47 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-10-03 21:04:47 Using 1127 images and 60 for testing
2025-10-03 21:04:47 
Starting pose model training...
--------------------------------------------------
2025-10-03 21:05:12 Training with configuration:
2025-10-03 21:05:12 data:
2025-10-03 21:05:12   colormode: RGB
2025-10-03 21:05:12   inference:
2025-10-03 21:05:12     normalize_images: True
2025-10-03 21:05:12   train:
2025-10-03 21:05:12     affine:
2025-10-03 21:05:12       p: 0.5
2025-10-03 21:05:12       rotation: 30
2025-10-03 21:05:12       scaling: [1.0, 1.0]
2025-10-03 21:05:12       translation: 0
2025-10-03 21:05:12     collate:
2025-10-03 21:05:12       type: ResizeFromDataSizeCollate
2025-10-03 21:05:12       min_scale: 0.4
2025-10-03 21:05:12       max_scale: 1.0
2025-10-03 21:05:12       min_short_side: 128
2025-10-03 21:05:12       max_short_side: 1152
2025-10-03 21:05:12       multiple_of: 32
2025-10-03 21:05:12       to_square: False
2025-10-03 21:05:12     covering: False
2025-10-03 21:05:12     gaussian_noise: 12.75
2025-10-03 21:05:12     hist_eq: False
2025-10-03 21:05:12     motion_blur: False
2025-10-03 21:05:12     normalize_images: True
2025-10-03 21:05:12 device: auto
2025-10-03 21:05:12 metadata:
2025-10-03 21:05:12   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-10-03 21:05:12   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-10-03 21:05:12   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-10-03 21:05:12   unique_bodyparts: []
2025-10-03 21:05:12   individuals: ['animal']
2025-10-03 21:05:12   with_identity: None
2025-10-03 21:05:12 method: bu
2025-10-03 21:05:12 model:
2025-10-03 21:05:12   backbone:
2025-10-03 21:05:12     type: ResNet
2025-10-03 21:05:12     model_name: resnet50_gn
2025-10-03 21:05:12     output_stride: 16
2025-10-03 21:05:12     freeze_bn_stats: True
2025-10-03 21:05:12     freeze_bn_weights: False
2025-10-03 21:05:12   backbone_output_channels: 2048
2025-10-03 21:05:12   heads:
2025-10-03 21:05:12     bodypart:
2025-10-03 21:05:12       type: HeatmapHead
2025-10-03 21:05:12       weight_init: normal
2025-10-03 21:05:12       predictor:
2025-10-03 21:05:12         type: HeatmapPredictor
2025-10-03 21:05:12         apply_sigmoid: False
2025-10-03 21:05:12         clip_scores: True
2025-10-03 21:05:12         location_refinement: True
2025-10-03 21:05:12         locref_std: 7.2801
2025-10-03 21:05:12       target_generator:
2025-10-03 21:05:12         type: HeatmapGaussianGenerator
2025-10-03 21:05:12         num_heatmaps: 9
2025-10-03 21:05:12         pos_dist_thresh: 17
2025-10-03 21:05:12         heatmap_mode: KEYPOINT
2025-10-03 21:05:12         generate_locref: True
2025-10-03 21:05:12         locref_std: 7.2801
2025-10-03 21:05:12       criterion:
2025-10-03 21:05:12         heatmap:
2025-10-03 21:05:12           type: WeightedMSECriterion
2025-10-03 21:05:12           weight: 1.0
2025-10-03 21:05:12         locref:
2025-10-03 21:05:12           type: WeightedHuberCriterion
2025-10-03 21:05:12           weight: 0.05
2025-10-03 21:05:12       heatmap_config:
2025-10-03 21:05:12         channels: [2048, 9]
2025-10-03 21:05:12         kernel_size: [3]
2025-10-03 21:05:12         strides: [2]
2025-10-03 21:05:12       locref_config:
2025-10-03 21:05:12         channels: [2048, 18]
2025-10-03 21:05:12         kernel_size: [3]
2025-10-03 21:05:12         strides: [2]
2025-10-03 21:05:12 net_type: resnet_50
2025-10-03 21:05:12 runner:
2025-10-03 21:05:12   type: PoseTrainingRunner
2025-10-03 21:05:12   gpus: None
2025-10-03 21:05:12   key_metric: test.mAP
2025-10-03 21:05:12   key_metric_asc: True
2025-10-03 21:05:12   eval_interval: 10
2025-10-03 21:05:12   optimizer:
2025-10-03 21:05:12     type: AdamW
2025-10-03 21:05:12     params:
2025-10-03 21:05:12       lr: 0.0001
2025-10-03 21:05:12   scheduler:
2025-10-03 21:05:12     type: StepLR
2025-10-03 21:05:12     params:
2025-10-03 21:05:12       step_size: 50
2025-10-03 21:05:12       gamma: 0.5
2025-10-03 21:05:12   snapshots:
2025-10-03 21:05:12     max_snapshots: 5
2025-10-03 21:05:12     save_epochs: 25
2025-10-03 21:05:12     save_optimizer_state: False
2025-10-03 21:05:12 train_settings:
2025-10-03 21:05:12   batch_size: 16
2025-10-03 21:05:12   dataloader_workers: 0
2025-10-03 21:05:12   dataloader_pin_memory: True
2025-10-03 21:05:12   display_iters: 500
2025-10-03 21:05:12   epochs: 400
2025-10-03 21:05:12   seed: 42
2025-10-03 21:05:13 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-10-03 21:05:13 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-10-03 21:05:15 Data Transforms:
2025-10-03 21:05:15   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-03 21:05:15   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-03 21:05:16 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-10-03 21:05:16 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-10-03 21:05:16 Using 1127 images and 60 for testing
2025-10-03 21:05:16 
Starting pose model training...
--------------------------------------------------
2025-10-03 21:05:46 Training with configuration:
2025-10-03 21:05:46 data:
2025-10-03 21:05:46   colormode: RGB
2025-10-03 21:05:46   inference:
2025-10-03 21:05:46     normalize_images: True
2025-10-03 21:05:46   train:
2025-10-03 21:05:46     affine:
2025-10-03 21:05:46       p: 0.5
2025-10-03 21:05:46       rotation: 30
2025-10-03 21:05:46       scaling: [1.0, 1.0]
2025-10-03 21:05:46       translation: 0
2025-10-03 21:05:46     collate:
2025-10-03 21:05:46       type: ResizeFromDataSizeCollate
2025-10-03 21:05:46       min_scale: 0.4
2025-10-03 21:05:46       max_scale: 1.0
2025-10-03 21:05:46       min_short_side: 128
2025-10-03 21:05:46       max_short_side: 1152
2025-10-03 21:05:46       multiple_of: 32
2025-10-03 21:05:46       to_square: False
2025-10-03 21:05:46     covering: False
2025-10-03 21:05:46     gaussian_noise: 12.75
2025-10-03 21:05:46     hist_eq: False
2025-10-03 21:05:46     motion_blur: False
2025-10-03 21:05:46     normalize_images: True
2025-10-03 21:05:46 device: auto
2025-10-03 21:05:46 metadata:
2025-10-03 21:05:46   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-10-03 21:05:46   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-10-03 21:05:46   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-10-03 21:05:46   unique_bodyparts: []
2025-10-03 21:05:46   individuals: ['animal']
2025-10-03 21:05:46   with_identity: None
2025-10-03 21:05:46 method: bu
2025-10-03 21:05:46 model:
2025-10-03 21:05:46   backbone:
2025-10-03 21:05:46     type: ResNet
2025-10-03 21:05:46     model_name: resnet50_gn
2025-10-03 21:05:46     output_stride: 16
2025-10-03 21:05:46     freeze_bn_stats: True
2025-10-03 21:05:46     freeze_bn_weights: False
2025-10-03 21:05:46   backbone_output_channels: 2048
2025-10-03 21:05:46   heads:
2025-10-03 21:05:46     bodypart:
2025-10-03 21:05:46       type: HeatmapHead
2025-10-03 21:05:46       weight_init: normal
2025-10-03 21:05:46       predictor:
2025-10-03 21:05:46         type: HeatmapPredictor
2025-10-03 21:05:46         apply_sigmoid: False
2025-10-03 21:05:46         clip_scores: True
2025-10-03 21:05:46         location_refinement: True
2025-10-03 21:05:46         locref_std: 7.2801
2025-10-03 21:05:46       target_generator:
2025-10-03 21:05:46         type: HeatmapGaussianGenerator
2025-10-03 21:05:46         num_heatmaps: 9
2025-10-03 21:05:46         pos_dist_thresh: 17
2025-10-03 21:05:46         heatmap_mode: KEYPOINT
2025-10-03 21:05:46         generate_locref: True
2025-10-03 21:05:46         locref_std: 7.2801
2025-10-03 21:05:46       criterion:
2025-10-03 21:05:46         heatmap:
2025-10-03 21:05:46           type: WeightedMSECriterion
2025-10-03 21:05:46           weight: 1.0
2025-10-03 21:05:46         locref:
2025-10-03 21:05:46           type: WeightedHuberCriterion
2025-10-03 21:05:46           weight: 0.05
2025-10-03 21:05:46       heatmap_config:
2025-10-03 21:05:46         channels: [2048, 9]
2025-10-03 21:05:46         kernel_size: [3]
2025-10-03 21:05:46         strides: [2]
2025-10-03 21:05:46       locref_config:
2025-10-03 21:05:46         channels: [2048, 18]
2025-10-03 21:05:46         kernel_size: [3]
2025-10-03 21:05:46         strides: [2]
2025-10-03 21:05:46 net_type: resnet_50
2025-10-03 21:05:46 runner:
2025-10-03 21:05:46   type: PoseTrainingRunner
2025-10-03 21:05:46   gpus: None
2025-10-03 21:05:46   key_metric: test.mAP
2025-10-03 21:05:46   key_metric_asc: True
2025-10-03 21:05:46   eval_interval: 10
2025-10-03 21:05:46   optimizer:
2025-10-03 21:05:46     type: AdamW
2025-10-03 21:05:46     params:
2025-10-03 21:05:46       lr: 0.0001
2025-10-03 21:05:46   scheduler:
2025-10-03 21:05:46     type: StepLR
2025-10-03 21:05:46     params:
2025-10-03 21:05:46       step_size: 50
2025-10-03 21:05:46       gamma: 0.5
2025-10-03 21:05:46   snapshots:
2025-10-03 21:05:46     max_snapshots: 5
2025-10-03 21:05:46     save_epochs: 25
2025-10-03 21:05:46     save_optimizer_state: False
2025-10-03 21:05:46 train_settings:
2025-10-03 21:05:46   batch_size: 16
2025-10-03 21:05:46   dataloader_workers: 0
2025-10-03 21:05:46   dataloader_pin_memory: True
2025-10-03 21:05:46   display_iters: 500
2025-10-03 21:05:46   epochs: 400
2025-10-03 21:05:46   seed: 42
2025-10-03 21:05:46 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-10-03 21:05:46 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-10-03 21:05:48 Data Transforms:
2025-10-03 21:05:48   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-03 21:05:48   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-03 21:05:50 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-10-03 21:05:50 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-10-03 21:05:50 Using 1127 images and 60 for testing
2025-10-03 21:05:50 
Starting pose model training...
--------------------------------------------------
2025-10-03 21:06:18 Training with configuration:
2025-10-03 21:06:18 data:
2025-10-03 21:06:18   colormode: RGB
2025-10-03 21:06:18   inference:
2025-10-03 21:06:18     normalize_images: True
2025-10-03 21:06:18   train:
2025-10-03 21:06:18     affine:
2025-10-03 21:06:18       p: 0.5
2025-10-03 21:06:18       rotation: 30
2025-10-03 21:06:18       scaling: [1.0, 1.0]
2025-10-03 21:06:18       translation: 0
2025-10-03 21:06:18     collate:
2025-10-03 21:06:18       type: ResizeFromDataSizeCollate
2025-10-03 21:06:18       min_scale: 0.4
2025-10-03 21:06:18       max_scale: 1.0
2025-10-03 21:06:18       min_short_side: 128
2025-10-03 21:06:18       max_short_side: 1152
2025-10-03 21:06:18       multiple_of: 32
2025-10-03 21:06:18       to_square: False
2025-10-03 21:06:18     covering: False
2025-10-03 21:06:18     gaussian_noise: 12.75
2025-10-03 21:06:18     hist_eq: False
2025-10-03 21:06:18     motion_blur: False
2025-10-03 21:06:18     normalize_images: True
2025-10-03 21:06:18 device: auto
2025-10-03 21:06:18 metadata:
2025-10-03 21:06:18   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-10-03 21:06:18   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-10-03 21:06:18   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-10-03 21:06:18   unique_bodyparts: []
2025-10-03 21:06:18   individuals: ['animal']
2025-10-03 21:06:18   with_identity: None
2025-10-03 21:06:18 method: bu
2025-10-03 21:06:18 model:
2025-10-03 21:06:18   backbone:
2025-10-03 21:06:18     type: ResNet
2025-10-03 21:06:18     model_name: resnet50_gn
2025-10-03 21:06:18     output_stride: 16
2025-10-03 21:06:18     freeze_bn_stats: True
2025-10-03 21:06:18     freeze_bn_weights: False
2025-10-03 21:06:18   backbone_output_channels: 2048
2025-10-03 21:06:18   heads:
2025-10-03 21:06:18     bodypart:
2025-10-03 21:06:18       type: HeatmapHead
2025-10-03 21:06:18       weight_init: normal
2025-10-03 21:06:18       predictor:
2025-10-03 21:06:18         type: HeatmapPredictor
2025-10-03 21:06:18         apply_sigmoid: False
2025-10-03 21:06:18         clip_scores: True
2025-10-03 21:06:18         location_refinement: True
2025-10-03 21:06:18         locref_std: 7.2801
2025-10-03 21:06:18       target_generator:
2025-10-03 21:06:18         type: HeatmapGaussianGenerator
2025-10-03 21:06:18         num_heatmaps: 9
2025-10-03 21:06:18         pos_dist_thresh: 17
2025-10-03 21:06:18         heatmap_mode: KEYPOINT
2025-10-03 21:06:18         generate_locref: True
2025-10-03 21:06:18         locref_std: 7.2801
2025-10-03 21:06:18       criterion:
2025-10-03 21:06:18         heatmap:
2025-10-03 21:06:18           type: WeightedMSECriterion
2025-10-03 21:06:18           weight: 1.0
2025-10-03 21:06:18         locref:
2025-10-03 21:06:18           type: WeightedHuberCriterion
2025-10-03 21:06:18           weight: 0.05
2025-10-03 21:06:18       heatmap_config:
2025-10-03 21:06:18         channels: [2048, 9]
2025-10-03 21:06:18         kernel_size: [3]
2025-10-03 21:06:18         strides: [2]
2025-10-03 21:06:18       locref_config:
2025-10-03 21:06:18         channels: [2048, 18]
2025-10-03 21:06:18         kernel_size: [3]
2025-10-03 21:06:18         strides: [2]
2025-10-03 21:06:18 net_type: resnet_50
2025-10-03 21:06:18 runner:
2025-10-03 21:06:18   type: PoseTrainingRunner
2025-10-03 21:06:18   gpus: None
2025-10-03 21:06:18   key_metric: test.mAP
2025-10-03 21:06:18   key_metric_asc: True
2025-10-03 21:06:18   eval_interval: 10
2025-10-03 21:06:18   optimizer:
2025-10-03 21:06:18     type: AdamW
2025-10-03 21:06:18     params:
2025-10-03 21:06:18       lr: 0.0001
2025-10-03 21:06:18   scheduler:
2025-10-03 21:06:18     type: StepLR
2025-10-03 21:06:18     params:
2025-10-03 21:06:18       step_size: 50
2025-10-03 21:06:18       gamma: 0.5
2025-10-03 21:06:18   snapshots:
2025-10-03 21:06:18     max_snapshots: 5
2025-10-03 21:06:18     save_epochs: 25
2025-10-03 21:06:18     save_optimizer_state: False
2025-10-03 21:06:18 train_settings:
2025-10-03 21:06:18   batch_size: 16
2025-10-03 21:06:18   dataloader_workers: 0
2025-10-03 21:06:18   dataloader_pin_memory: True
2025-10-03 21:06:18   display_iters: 500
2025-10-03 21:06:18   epochs: 400
2025-10-03 21:06:18   seed: 42
2025-10-03 21:06:18 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-10-03 21:06:18 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-10-03 21:06:20 Data Transforms:
2025-10-03 21:06:20   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-03 21:06:20   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-03 21:06:22 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2025-10-03 21:06:22 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2025-10-03 21:06:22 Using 1127 images and 60 for testing
2025-10-03 21:06:22 
Starting pose model training...
--------------------------------------------------
2025-10-04 00:12:11 Training with configuration:
2025-10-04 00:12:11 data:
2025-10-04 00:12:11   colormode: RGB
2025-10-04 00:12:11   inference:
2025-10-04 00:12:11     normalize_images: True
2025-10-04 00:12:11   train:
2025-10-04 00:12:11     affine:
2025-10-04 00:12:11       p: 0.5
2025-10-04 00:12:11       rotation: 30
2025-10-04 00:12:11       scaling: [1.0, 1.0]
2025-10-04 00:12:11       translation: 0
2025-10-04 00:12:11     collate:
2025-10-04 00:12:11       type: ResizeFromDataSizeCollate
2025-10-04 00:12:11       min_scale: 0.4
2025-10-04 00:12:11       max_scale: 1.0
2025-10-04 00:12:11       min_short_side: 128
2025-10-04 00:12:11       max_short_side: 1152
2025-10-04 00:12:11       multiple_of: 32
2025-10-04 00:12:11       to_square: False
2025-10-04 00:12:11     covering: False
2025-10-04 00:12:11     gaussian_noise: 12.75
2025-10-04 00:12:11     hist_eq: False
2025-10-04 00:12:11     motion_blur: False
2025-10-04 00:12:11     normalize_images: True
2025-10-04 00:12:11 device: auto
2025-10-04 00:12:11 metadata:
2025-10-04 00:12:11   project_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07
2025-10-04 00:12:11   pose_config_path: /sfs/gpfs/tardis/home/jhs8cue/foot_fault-Jaden-2025-06-07/dlc-models-pytorch/iteration-0/foot_faultJun7-trainset95shuffle2/train/pose_cfg.yaml
2025-10-04 00:12:11   bodyparts: ['front_left_paw', 'front_right_paw', 'back_left_paw', 'back_right_paw', 'nose', 'neck', 'tail_base', 'tail_tip', 'centroid']
2025-10-04 00:12:11   unique_bodyparts: []
2025-10-04 00:12:11   individuals: ['animal']
2025-10-04 00:12:11   with_identity: None
2025-10-04 00:12:11 method: bu
2025-10-04 00:12:11 model:
2025-10-04 00:12:11   backbone:
2025-10-04 00:12:11     type: ResNet
2025-10-04 00:12:11     model_name: resnet50_gn
2025-10-04 00:12:11     output_stride: 16
2025-10-04 00:12:11     freeze_bn_stats: True
2025-10-04 00:12:11     freeze_bn_weights: False
2025-10-04 00:12:11   backbone_output_channels: 2048
2025-10-04 00:12:11   heads:
2025-10-04 00:12:11     bodypart:
2025-10-04 00:12:11       type: HeatmapHead
2025-10-04 00:12:11       weight_init: normal
2025-10-04 00:12:11       predictor:
2025-10-04 00:12:11         type: HeatmapPredictor
2025-10-04 00:12:11         apply_sigmoid: False
2025-10-04 00:12:11         clip_scores: True
2025-10-04 00:12:11         location_refinement: True
2025-10-04 00:12:11         locref_std: 7.2801
2025-10-04 00:12:11       target_generator:
2025-10-04 00:12:11         type: HeatmapGaussianGenerator
2025-10-04 00:12:11         num_heatmaps: 9
2025-10-04 00:12:11         pos_dist_thresh: 17
2025-10-04 00:12:11         heatmap_mode: KEYPOINT
2025-10-04 00:12:11         generate_locref: True
2025-10-04 00:12:11         locref_std: 7.2801
2025-10-04 00:12:11       criterion:
2025-10-04 00:12:11         heatmap:
2025-10-04 00:12:11           type: WeightedMSECriterion
2025-10-04 00:12:11           weight: 1.0
2025-10-04 00:12:11         locref:
2025-10-04 00:12:11           type: WeightedHuberCriterion
2025-10-04 00:12:11           weight: 0.05
2025-10-04 00:12:11       heatmap_config:
2025-10-04 00:12:11         channels: [2048, 9]
2025-10-04 00:12:11         kernel_size: [3]
2025-10-04 00:12:11         strides: [2]
2025-10-04 00:12:11       locref_config:
2025-10-04 00:12:11         channels: [2048, 18]
2025-10-04 00:12:11         kernel_size: [3]
2025-10-04 00:12:11         strides: [2]
2025-10-04 00:12:11 net_type: resnet_50
2025-10-04 00:12:11 runner:
2025-10-04 00:12:11   type: PoseTrainingRunner
2025-10-04 00:12:11   gpus: None
2025-10-04 00:12:11   key_metric: test.mAP
2025-10-04 00:12:11   key_metric_asc: True
2025-10-04 00:12:11   eval_interval: 10
2025-10-04 00:12:11   optimizer:
2025-10-04 00:12:11     type: AdamW
2025-10-04 00:12:11     params:
2025-10-04 00:12:11       lr: 0.0001
2025-10-04 00:12:11   scheduler:
2025-10-04 00:12:11     type: StepLR
2025-10-04 00:12:11     params:
2025-10-04 00:12:11       step_size: 50
2025-10-04 00:12:11       gamma: 0.5
2025-10-04 00:12:11   snapshots:
2025-10-04 00:12:11     max_snapshots: 5
2025-10-04 00:12:11     save_epochs: 25
2025-10-04 00:12:11     save_optimizer_state: False
2025-10-04 00:12:11 train_settings:
2025-10-04 00:12:11   batch_size: 16
2025-10-04 00:12:11   dataloader_workers: 0
2025-10-04 00:12:11   dataloader_pin_memory: True
2025-10-04 00:12:11   display_iters: 500
2025-10-04 00:12:11   epochs: 400
2025-10-04 00:12:11   seed: 42
2025-10-04 00:12:11 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-10-04 00:12:11 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-10-04 00:12:14 Data Transforms:
2025-10-04 00:12:14   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-10-04 00:12:14   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
